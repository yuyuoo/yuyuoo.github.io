{"title":"pytorch笔记五：文本预处理","date":"2020-02-16T03:03:52.000Z","date_formatted":{"ll":"Feb 16, 2020","L":"02/16/2020","MM-DD":"02-16"},"thumbnail":"https://s2.ax1x.com/2020/02/16/3ShyXF.png","link":"2020/02/16/pytorch笔记五：文本预处理","comments":true,"tags":["pytorch"],"categories":["Notes"],"updated":"2020-03-07T06:41:04.675Z","content":"<h3 id=\"1-读入文本\">1. 读入文本<a href=\"#1-读入文本\" title=\"1. 读入文本\"></a></h3><figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> collections</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">read_time_machine</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(<span class=\"string\">'/home/kesci/input/timemachine7163/timemachine.txt'</span>, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        lines = [re.sub(<span class=\"string\">'[^a-z]+'</span>, <span class=\"string\">' '</span>, line.strip().lower()) <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> f]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> lines</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">lines = read_time_machine()</span><br><span class=\"line\">print(<span class=\"string\">'# sentences %d'</span> % len(lines))\t<span class=\"comment\"># sentences 3221</span></span><br></pre></td></tr></table></figure>\n\n<ul><li><code>re.sub(&#39;[^a-z]+&#39;, &#39; &#39;, line.strip().lower())</code>：Python strip () 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。Python lower () 方法转换字符串中所有大写字符为小写。先去掉每一行头尾的空白字符，再把大写字母全部换成小写，再把所有非字母的字符以空格代替。</li></ul><h3 id=\"2-分词\">2. 分词<a href=\"#2-分词\" title=\"2. 分词\"></a></h3><p>我们对每个句子进行分词，也就是将一个句子划分成若干个词（token），转换为一个词的序列。</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">tokenize</span><span class=\"params\">(sentences, token=<span class=\"string\">'word'</span>)</span>:</span>\t<span class=\"comment\">#缺省按word分割</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"Split sentences into word or char tokens\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> token == <span class=\"string\">'word'</span>:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [sentence.split(<span class=\"string\">' '</span>) <span class=\"keyword\">for</span> sentence <span class=\"keyword\">in</span> sentences]</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> token == <span class=\"string\">'char'</span>:\t<span class=\"comment\">#按字符分割</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [list(sentence) <span class=\"keyword\">for</span> sentence <span class=\"keyword\">in</span> sentences]</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        print(<span class=\"string\">'ERROR: unkown token type '</span>+token)</span><br><span class=\"line\"></span><br><span class=\"line\">tokens = tokenize(lines)</span><br><span class=\"line\">tokens[<span class=\"number\">0</span>:<span class=\"number\">2</span>]\t<span class=\"comment\">#看前两行的分词结果</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[[<span class=\"string\">'the'</span>, <span class=\"string\">'time'</span>, <span class=\"string\">'machine'</span>, <span class=\"string\">'by'</span>, <span class=\"string\">'h'</span>, <span class=\"string\">'g'</span>, <span class=\"string\">'wells'</span>, <span class=\"string\">''</span>], [<span class=\"string\">''</span>]]\t<span class=\"comment\">#第二行本来就是空的</span></span><br></pre></td></tr></table></figure>\n\n<h3 id=\"3-建立字典\">3. 建立字典<a href=\"#3-建立字典\" title=\"3. 建立字典\"></a></h3><p>为了方便模型处理，我们需要将字符串转换为数字。因此我们需要先构建一个字典（vocabulary），将每个词映射到一个唯一的索引编号。</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Vocab</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, tokens, min_freq=<span class=\"number\">0</span>, use_special_tokens=False)</span>:</span></span><br><span class=\"line\">        counter = count_corpus(tokens)  <span class=\"comment\"># &lt;key,value&gt;:&lt;词，词频&gt; </span></span><br><span class=\"line\">        self.token_freqs = list(counter.items())</span><br><span class=\"line\">        self.idx_to_token = []</span><br><span class=\"line\">        <span class=\"keyword\">if</span> use_special_tokens:</span><br><span class=\"line\">            <span class=\"comment\"># padding, begin of sentence, end of sentence, unknown</span></span><br><span class=\"line\">            self.pad, self.bos, self.eos, self.unk = (<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">3</span>)</span><br><span class=\"line\">            self.idx_to_token += [<span class=\"string\">'pad'</span>, <span class=\"string\">'bos'</span>, <span class=\"string\">'eos'</span>, <span class=\"string\">'unk'</span>]</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.unk = <span class=\"number\">0</span></span><br><span class=\"line\">            self.idx_to_token += [<span class=\"string\">'unk'</span>]</span><br><span class=\"line\">        self.idx_to_token += [token <span class=\"keyword\">for</span> token, freq <span class=\"keyword\">in</span> self.token_freqs</span><br><span class=\"line\">                        <span class=\"keyword\">if</span> freq &gt;= min_freq <span class=\"keyword\">and</span> token <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> self.idx_to_token]</span><br><span class=\"line\">        self.token_to_idx = dict()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> idx, token <span class=\"keyword\">in</span> enumerate(self.idx_to_token):</span><br><span class=\"line\">            self.token_to_idx[token] = idx</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__len__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> len(self.idx_to_token)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, tokens)</span>:</span>\t<span class=\"comment\">#给定词返回索引</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> isinstance(tokens, (list, tuple)):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.token_to_idx.get(tokens, self.unk)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [self.__getitem__(token) <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> tokens]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">to_tokens</span><span class=\"params\">(self, indices)</span>:</span>\t<span class=\"comment\">#给定索引返回词</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> isinstance(indices, (list, tuple)):</span><br><span class=\"line\">            <span class=\"keyword\">return</span> self.idx_to_token[indices]</span><br><span class=\"line\">        <span class=\"keyword\">return</span> [self.idx_to_token[index] <span class=\"keyword\">for</span> index <span class=\"keyword\">in</span> indices]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">count_corpus</span><span class=\"params\">(sentences)</span>:</span></span><br><span class=\"line\">    tokens = [tk <span class=\"keyword\">for</span> st <span class=\"keyword\">in</span> sentences <span class=\"keyword\">for</span> tk <span class=\"keyword\">in</span> st]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> collections.Counter(tokens)  <span class=\"comment\"># 返回一个字典，记录每个词的出现次数</span></span><br></pre></td></tr></table></figure>\n\n<ul><li>定义<code>count_corpus()</code>函数，<code>collections.Counter(tokens)</code>自动实现去重和记录单词出现次数。</li><li><code>if use_special_tokens</code>：判断是否要使用特殊token。</li><li><code>pad</code>表示在短句后面加若干特殊的token，使得与最长的句子一样长；<code>bos</code>和<code>eos</code>是句子首尾的token；<code>unk</code>是测试中输入的新token不在语料库中。</li><li><code>idx_to_token</code>:这个列表本身就是索引到token的映射。</li></ul><p>看一个例子，这里我们尝试用Time Machine作为语料构建字典</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vocab = Vocab(tokens)</span><br><span class=\"line\">print(list(vocab.token_to_idx.items())[<span class=\"number\">0</span>:<span class=\"number\">10</span>])\t<span class=\"comment\">#看前十个键值对</span></span><br></pre></td></tr></table></figure>\n\n<p>输出：</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[(&#39;unk&#39;, 0), (&#39;the&#39;, 1), (&#39;time&#39;, 2), (&#39;machine&#39;, 3), (&#39;by&#39;, 4), (&#39;h&#39;, 5), (&#39;g&#39;, 6), (&#39;wells&#39;, 7), (&#39;&#39;, 8), (&#39;i&#39;, 9)]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"4-用spacy和nltk进行分词\">4. 用<a href=\"https://spacy.io/\" target=\"_blank\">spaCy</a>和<a href=\"https://www.nltk.org/\" target=\"_blank\">NLTK</a>进行分词<a href=\"#4-用spacy和nltk进行分词\" title=\"4. 用spaCy和NLTK进行分词\"></a></h3><p>我们前面介绍的分词方式非常简单，它至少有以下几个缺点:</p>\n<ol><li>标点符号通常可以提供语义信息，但是我们的方法直接将其丢弃了</li><li>类似“shouldn&#39;t&quot;, &quot;doesn&#39;t&quot;这样的词会被错误地处理</li><li>类似&quot;Mr.&quot;, &quot;Dr.&quot;这样的词会被错误地处理</li></ol><p>下面是一个简单的例子：</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">text = <span class=\"string\">\"Mr. Chen doesn't agree with my suggestion.\"</span></span><br></pre></td></tr></table></figure>\n\n<p>spaCy:</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> spacy</span><br><span class=\"line\">nlp = spacy.load(<span class=\"string\">'en_core_web_sm'</span>)</span><br><span class=\"line\">doc = nlp(text)</span><br><span class=\"line\">print([token.text <span class=\"keyword\">for</span> token <span class=\"keyword\">in</span> doc])</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&#39;Mr.&#39;, &#39;Chen&#39;, &#39;does&#39;, &quot;n&#39;t&quot;, &#39;agree&#39;, &#39;with&#39;, &#39;my&#39;, &#39;suggestion&#39;, &#39;.&#39;]</span><br></pre></td></tr></table></figure>\n\n<p>NLTK:</p>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> nltk.tokenize <span class=\"keyword\">import</span> word_tokenize</span><br><span class=\"line\"><span class=\"keyword\">from</span> nltk <span class=\"keyword\">import</span> data</span><br><span class=\"line\">data.path.append(<span class=\"string\">'/home/kesci/input/nltk_data3784/nltk_data'</span>)</span><br><span class=\"line\">print(word_tokenize(text))</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[&#39;Mr.&#39;, &#39;Chen&#39;, &#39;does&#39;, &quot;n&#39;t&quot;, &#39;agree&#39;, &#39;with&#39;, &#39;my&#39;, &#39;suggestion&#39;, &#39;.&#39;]</span><br></pre></td></tr></table></figure>","prev":{"title":"pytorch笔记六：循环神经网络基础","link":"2020/02/17/pytorch笔记六：循环神经网络基础"},"next":{"title":"pytorch笔记四：过拟合欠拟合及其解决方案","link":"2020/02/14/pytorch笔记四：过拟合欠拟合及其解决方案"},"plink":"https://yuyuoo.github.io/2020/02/16/pytorch笔记五：文本预处理/","toc":[{"id":"1-读入文本","title":"1. 读入文本","index":"1"},{"id":"2-分词","title":"2. 分词","index":"2"},{"id":"3-建立字典","title":"3. 建立字典","index":"3"},{"id":"4-用spacy和nltk进行分词","title":"4. 用spaCy和NLTK进行分词","index":"4"}],"copyright":{"license":"Attribution-NonCommercial-NoDerivatives 4.0 International","published":"February 16, 2020","updated":"March 7, 2020","author":"YuYuoo"}}